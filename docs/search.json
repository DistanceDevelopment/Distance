[{"path":"/articles/covariates-distill.html","id":"exploratory-data-analysis","dir":"Articles","previous_headings":"","what":"Exploratory data analysis","title":"Incorporating covariates in the detection function","text":"important gain understanding data prior fitting detection functions. mind, preliminary analysis distance sampling data involves: assessing shape collected data, considering level truncation distances, exploring patterns potential covariates. begin assessing distribution distances decide truncation distance (Figure 1). Figure 1: Distribution radial distances amakihi see differences distribution distances recorded different observers hour sunrise, boxplots can used. Note ~ symbol used define discrete groupings (.e. observer hour) (Figure 2). Figure 2: Visual assessment effect observer hour since sunrise upon detection. components boxplot : thick black line indicates median lower limit box first quartile (25th percentile) upper limit third quartile (75th percentile) height box interquartile range (75th - 25th quartiles) whiskers extend extreme points 1.5 times interquartile range. dots indicate ‘outliers’ , .e. points beyond range whiskers. minutes sunrise (continuous variable), create scatterplot MAS (\\(x\\)-axis) distances (\\(y\\)-axis). plotting symbol (character) selected argument pch (Figure 3) Figure 3: Visualisation detectability function minutes since sunrise. Clearly room right truncation figure radial distance distribution. Subsequent detection function fitting use truncation argument ds() exclude largest 15% detection distances. may also want think potential collinearity (linear relationship) covariates - collinear variables included detection function, explaining variation distances reduce importance potential covariate. might investigate relationship MAS? plots, infer whether covariates useful explaining distribution detection distances.","code":"hist(amakihi$distance, main=\"Radial distances\", xlab=\"Distance (m)\") boxplot(amakihi$distance~amakihi$OBs, xlab=\"Observer\", ylab=\"Distance (m)\") boxplot(amakihi$distance~amakihi$HAS, xlab=\"Hour\", ylab=\"Distance (m)\") scatter.smooth(amakihi$MAS, amakihi$distance, family = \"gaussian\", pch=20, cex=.9, lpars=list(lwd=3),                xlab=\"Minutes after sunrise\",ylab=\"Distance (m)\")"},{"path":"/articles/covariates-distill.html","id":"adjusting-the-raw-covariates","dir":"Articles","previous_headings":"","what":"Adjusting the raw covariates","title":"Incorporating covariates in the detection function","text":"like treat OBs factor variables original analysis; OBs , default, treated factor variable consists characters rather numbers. , hand, consists numbers default treated continuous variable (.e. non-factor). fine want effect monotonic (.e. detectability either increases decreases function ). want non-linear effect detectability, need indicate R treat factor shown . One , subtle adjustment, transformation continuous covariate MAS. considering three possible covariates detection function: OBs, MAS. first two variables, OBs , factor variables, , essentially, can think taking values 1 3 case OBS, 1 6 case . However, MAS can take values -18 (detections sunrise) >300 disparity scales measure MAS candidate covariates can lead difficulties performance optimizer fitting detection functions R. solution difficulty scale MAS scale (approx. 1 5) comparable covariates.","code":"amakihi$HAS <- factor(amakihi$HAS)"},{"path":"/articles/covariates-distill.html","id":"candidate-models","dir":"Articles","previous_headings":"","what":"Candidate models","title":"Incorporating covariates in the detection function","text":"three potential covariates, 8 possible models detection function: covariates OBs MAS OBs + OBs + MAS + MAS OBs + + MAS Even without considering covariates also several possible key function/adjustment term combinations available: key function/covariate combinations considered number potential models large. Note covariates allowed uniform key function chosen covariate terms included, adjustment terms allowed. Even restrictions, best practice take scatter gun approach detection function model fitting. Buckland et al. (2015) considered 13 combinations key function/covariates. , look subset . Fit hazard rate model covariates adjustment terms make note AIC. Note, 15% largest distances truncated - may decided different truncation distance. Now fit hazard rate model OBs covariate detection function make note AIC. AIC reduced including covariate? Fit hazard rate model OBs MAS detection function: Try fitting possible formula decide model best terms AIC. quickly compare AIC values different models, use AIC command follows (note models truncation distance can compared): Another useful function summarize_ds_models - advantage ordering models AIC (smallest largest). Table 1: Model selection table Hawaiian amakihi. Examine shape preferred detection function (including covariates observer minutes sunrise) (Figure 4). Figure 4: PDF best fitting model, including effects observer minutes sunrise.","code":"conversion.factor <- convert_units(\"meter\", NULL, \"hectare\") amak.hr <- ds(amakihi, transect=\"point\", key=\"hr\", truncation=\"15%\",               adjustment=NULL, convert_units = conversion.factor) amak.hr.obs <- ds(amakihi, transect=\"point\", key=\"hr\", formula=~OBs,                   truncation=\"15%\", convert_units = conversion.factor) amak.hr.obs.mas <- ds(amakihi, transect=\"point\", key=\"hr\", formula=~OBs+MAS,                       truncation=\"15%\", convert_units = conversion.factor) AIC(amak.hr, amak.hr.obs, amak.hr.obs.mas) ##                 df      AIC ## amak.hr          2 11400.47 ## amak.hr.obs      4 11368.20 ## amak.hr.obs.mas  5 11365.96 knitr::kable(summarize_ds_models(amak.hr, amak.hr.obs, amak.hr.obs.mas), digits=3,              caption=\"Model selection table for Hawaiian amakihi.\") plot(amak.hr.obs.mas, pdf=TRUE, main=\"Hazard rate with observer and minutes after sunrise.\", showpoints=FALSE) sfzero <- data.frame(OBs=\"SGF\", MAS=0) sf180 <- data.frame(OBs=\"SGF\", MAS=180) t1zero <- data.frame(OBs=\"TJS\", MAS=0) t1180 <- data.frame(OBs=\"TJS\", MAS=180) t2zero <- data.frame(OBs=\"TKP\", MAS=0) t2180 <- data.frame(OBs=\"TKP\", MAS=180) add_df_covar_line(amak.hr.obs.mas, data=sfzero, lty=1, lwd=2,col=\"blue\", pdf=TRUE) add_df_covar_line(amak.hr.obs.mas, data=sf180, lty=2, lwd=2,col=\"blue\", pdf=TRUE) add_df_covar_line(amak.hr.obs.mas, data=t1zero, lty=1,lwd=2,col=\"darkorange\", pdf=TRUE) add_df_covar_line(amak.hr.obs.mas, data=t1180, lty=2, lwd=2,col=\"darkorange\", pdf=TRUE) add_df_covar_line(amak.hr.obs.mas, data=t2zero, lty=1,lwd=2,col=\"violet\", pdf=TRUE) add_df_covar_line(amak.hr.obs.mas, data=t2180, lty=2, lwd=2,col=\"violet\", pdf=TRUE) legend(\"topright\", legend=c(\"SF, minutes=0\",                             \"SF, minutes=180\",                             \"TS, minutes=0\",                             \"TS, minutes=180\",                             \"TP, minutes=0\",                             \"TP, minutes=180\"),        title=\"Covariate combination: observer and minutes\",        lty=rep(c(1,2),times=3), lwd=2, col=rep(c(\"blue\",\"darkorange\",\"violet\"), each=2))"},{"path":"/articles/covariates-distill.html","id":"comments-about-the-chosen-model","dir":"Articles","previous_headings":"","what":"Comments about the chosen model","title":"Incorporating covariates in the detection function","text":"three observers involved survey. One observer made ~80% detections, second observer responsible 15% third observer 5%.","code":""},{"path":[]},{"path":"/articles/lines-distill.html","id":"objectives","dir":"Articles","previous_headings":"","what":"Objectives","title":"Line transect density estimation","text":"Import data file Fit basic detection function using ds function Plot examine detection function Fit different detection function forms.","code":""},{"path":"/articles/lines-distill.html","id":"survey-design","dir":"Articles","previous_headings":"","what":"Survey design","title":"Line transect density estimation","text":"Nineteen line transects walked twice (Figure 1). Figure 1: Montrave study area; diagonal lines indicate line transects walked generate data. fields wren_lt data set : Region.Label - identifier regions: case one region set ‘Montrave’ required field Area - size study region (hectares): 33.2ha Sample.Label - line transect identifier (numbered 1-19) required field Effort - length line transects (km) required field object - unique identifier detected winter wren distance - perpendicular distance (metres) detection required field Study.Area - name study, ‘Montrave 4’","code":""},{"path":"/articles/lines-distill.html","id":"make-the-data-available-for-r-session","dir":"Articles","previous_headings":"","what":"Make the data available for R session","title":"Line transect density estimation","text":"command assumes Distance package installed computer. R workspace wren_lt contains detections winter wrens line transect surveys Buckland (2006). effort, transect length adjusted recognise transect walked twice. Examine first rows wren_lt using function head() object wren_lt dataframe object made rows columns. code determines number detection distances missing. might rows data detection distance missing? Distance recorded missing rows representing transects detections. transect effort need appear data, without detections, perpendicular distance recorded missing (NA).","code":"library(Distance) data(wren_lt) head(wren_lt) ##   Region.Label Area Sample.Label Effort object distance Study.Area ## 1     Montrave 33.2            1  0.416      5       15 Montrave 4 ## 2     Montrave 33.2            1  0.416      6       80 Montrave 4 ## 3     Montrave 33.2            1  0.416      7       35 Montrave 4 ## 4     Montrave 33.2            1  0.416      8       55 Montrave 4 ## 5     Montrave 33.2            1  0.416     12       12 Montrave 4 ## 6     Montrave 33.2            1  0.416     13       75 Montrave 4 sum(!is.na(wren_lt$distance)) ## [1] 156"},{"path":"/articles/lines-distill.html","id":"examine-the-distribution-of-detection-distances","dir":"Articles","previous_headings":"","what":"Examine the distribution of detection distances","title":"Line transect density estimation","text":"Gain familiarity perpendicular distance data using hist() function (Figure 2). Figure 2: Distribution perpendicular distances winter wren (Buckland, 2006). Note appears detections 0 20m, many detections 20m 40m. may evidence evasive movement winter wrens; see discussion .","code":"hist(wren_lt$distance, xlab=\"Distance (m)\", main=\"Winter wren line transects\")"},{"path":"/articles/lines-distill.html","id":"specify-unit-conversions","dir":"Articles","previous_headings":"","what":"Specify unit conversions","title":"Line transect density estimation","text":"guaranteed way produce incorrect results analysis misspecify units distances measured. ds function argument convert.units user provides value report density proper units. Providing incorrect value result estimates orders magnitude. can choose units winter wren density reported, choose square kilometre. transmit information ds function? answer another function convert_units. Arguments function units measure perpendicular/radial distances units measure effort (NULL point transects) units measure study area. Specify correct arguments function winter wren data set. Note: units specified quoted strings, singular rather plural; e.g. “meter” rather “meters”","code":"conversion.factor <- convert_units(\"meter\", \"kilometer\", \"hectare\")"},{"path":"/articles/lines-distill.html","id":"fitting-a-simple-detection-function-model-with-ds","dir":"Articles","previous_headings":"","what":"Fitting a simple detection function model with ds","title":"Line transect density estimation","text":"Detection functions fitted using ds function function requires data frame column called distance. nests data, therefore, can simply supply name data frame function along additional arguments. Details arguments function: fit half-normal key detection function include adjustment terms required , example, perpendicular distances metres line transect lengths kilometer - argument converts perpendicular distance measurements metres kilometer. density estimates reported number birds per hectare. calling ds function, information provided screen reminding user model fitted associated AIC value. information supplied applying summary() function object created ds().","code":"wren.hn <- ds(data=wren_lt, key=\"hn\", adjustment=NULL, convert_units=conversion.factor) summary(wren.hn) ##  ## Summary for distance analysis  ## Number of observations :  156  ## Distance range         :  0  -  100  ##  ## Model       : Half-normal key function  ## AIC         :  1418.188  ## Optimisation:  mrds (nlminb)  ##  ## Detection function parameters ## Scale coefficient(s):   ##             estimate        se ## (Intercept) 4.105816 0.1327744 ##  ##                       Estimate          SE         CV ## Average p             0.685037  0.05678821 0.08289802 ## N in covered region 227.724931 21.47275208 0.09429250 ##  ## Summary statistics: ##     Region Area CoveredArea Effort   n  k       ER    se.ER      cv.ER ## 1 Montrave 33.2       193.2   9.66 156 19 16.14907 1.226096 0.07592366 ##  ## Abundance: ##   Label Estimate       se        cv     lcl     ucl       df ## 1 Total 39.13286 4.399007 0.1124121 31.3023 48.9223 74.24595 ##  ## Density: ##   Label Estimate        se        cv       lcl      ucl       df ## 1 Total   1.1787 0.1325002 0.1124121 0.9428403 1.473563 74.24595"},{"path":"/articles/lines-distill.html","id":"the-summary-function","dir":"Articles","previous_headings":"Fitting a simple detection function model with ds","what":"The summary function","title":"Line transect density estimation","text":"Examining output produced summary(wren.hn) notice number detections used fitting truncation distances AIC score parameters detection function (natural log scale) estimated probability detection within truncation distance estimated number objects area covered survey effort encounter rate variability measures precision strata, estimates provided stratum objects detected groups, estimates abundance groups individuals Visually inspect fitted detection function plot() function, specifying cutpoints histogram argument breaks (Figure 3): Figure 3: Fit half normal detection function wren data. Note large number break points specified small distances. Continue note presence evasive movement plot fit detection function observed data.","code":"cutpoints <- c(0,5,10,15,20,30,40,50,65,80,100) plot(wren.hn, breaks=cutpoints, main=\"Half normal model, wren line transects\")"},{"path":"/articles/lines-distill.html","id":"specifying-different-detection-functions","dir":"Articles","previous_headings":"","what":"Specifying different detection functions","title":"Line transect density estimation","text":"Detection function forms shapes, specified changing key adjustment arguments. options available key detection functions : half normal (key=\"hn\") - default hazard rate (key=\"hr\") uniform (key=\"unif\") options available adjustment terms : adjustment terms (adjustment=NULL) cosine (adjustment=\"cos\") - default Hermite polynomial (adjustment=\"herm\") Simple polynomial (adjustment=\"poly\") fit uniform key function cosine adjustment terms, use command: line code executed, multiple models fitted, successively adding addition adjustment terms. model four adjustment terms fit, error message returned; uniform key 3 cosine adjustments fitted contained returned object. AIC model selection used fit adjustment terms order 5. fit hazard rate key function simple polynomial adjustment terms, use command:","code":"wren.unif.cos <- ds(wren_lt, key=\"unif\", adjustment=\"cos\", convert_units=conversion.factor) ## Warning in check.mono(result, n.pts = control$mono.points): Detection function ## is not strictly monotonic! ## Warning in check.mono(result, n.pts = control$mono.points): Detection function ## is not strictly monotonic! ## Warning in mrds::check.mono(model, n.pts = 20): Detection function is not ## strictly monotonic! wren.hr.poly <- ds(wren_lt, key=\"hr\", adjustment=\"poly\", convert_units=conversion.factor)"},{"path":"/articles/lines-distill.html","id":"model-comparison","dir":"Articles","previous_headings":"","what":"Model comparison","title":"Line transect density estimation","text":"fitted detection function produces different estimate winter wren abundance density. estimate depends upon model chosen. model selection tool distance sampling data AIC. df AIC table indicates number parameters associated model.","code":"AIC(wren.hn, wren.hr.poly, wren.unif.cos) ##               df      AIC ## wren.hn        1 1418.188 ## wren.hr.poly   2 1412.133 ## wren.unif.cos  3 1416.430"},{"path":"/articles/lines-distill.html","id":"absolute-goodness-of-fit","dir":"Articles","previous_headings":"Model comparison","what":"Absolute goodness of fit","title":"Line transect density estimation","text":"addition relative ranking models provided AIC, also important know whether selected model(s) actually fit data. model basis inference, dangerous make inference model fit data. Goodness fit assessed using function gof_ds. function default, reports goodness fit assessed Cramer von-Mises test along quantile-quantile plot showing locations deviations good fit. Optionally, \\(\\chi^2\\) goodness fit test bootstrap version Kolomogorov-Smirnov goodness fit test can performed. Using function defaults, see results Cramer von-Mises test along Q-Q plot (Figure 4). Figure 4: Q-Q plot hazard rate key function fitted ot wren line transect data. Even though may evasive movement, goodness fit statistics still sufficient using detection function models inference.","code":"gof_ds(wren.hr.poly) ##  ## Goodness of fit results for ddf object ##  ## Distance sampling Cramer-von Mises test (unweighted) ## Test statistic = 0.249898 p-value = 0.1885"},{"path":"/articles/lines-distill.html","id":"model-comparison-tables","dir":"Articles","previous_headings":"","what":"Model comparison tables","title":"Line transect density estimation","text":"function summarise_ds_models combines work AIC gof_ds produce table fitted models summary statistics. Table 1: Model comparison table wren line transect data, Montrave.","code":"knitr::kable(summarize_ds_models(wren.hn, wren.hr.poly, wren.unif.cos),digits=3,              caption=\"Model comparison table for wren line transect data, Montrave.\")"},{"path":"/articles/lines-distill.html","id":"model-selection-is-not-a-cookbook","dir":"Articles","previous_headings":"Model comparison tables","what":"Model selection is not a cookbook","title":"Line transect density estimation","text":"AIC model selection tools suggest hazard rate key function preferred model. However, examine shape hazard rate detection function contrast uniform cosine fitted detection function (Figure 5). Figure 5: Possible evidence evasive movement wrens. Note left figure (hazard rate) implausible perfect detectability 70m, precipitous decline. fellow gathered data (Prof Buckland) maintained shape fitted hazard rate detection function plausible. Instead, chose uniform key cosine adjustments making inference (Buckland, 2006, p. 352): Common Chaffinch Winter Wren showed evidence observer avoidance. 2 12 data sets, resulted fitted hazard rate detection function certain detection ∼60 m, implausibly rapid fall-beyond 70 m. two analyses, model slightly higher AIC value plausible fit detection function selected. example moderating objective model selection tools common sense understanding field procedures.","code":"plot(wren.hr.poly, breaks=cutpoints, main=\"Hazard rate\") plot(wren.unif.cos, breaks=cutpoints, main=\"Uniform cosine\")"},{"path":[]},{"path":"/articles/species-covariate-distill.html","id":"background","dir":"Articles","previous_headings":"","what":"Background","title":"Covariate modeling with rare species","text":"Sometimes focal species distance sampling survey quite rare. rare difficult accumulate sufficient detections fit detection function species question. Likewise, also common species detected survey focal species. detections species useful estimating detection function focal species? One approach might consider species serve “strata” proceed analyse data stratified survey. See example stratified survey analysis. However, pooled detection function (one combines data multiple species) fitted, dubious apply pooled detection function data lower level aggregation (species level). Applying pooled detection function lead biased estimate abundance rare species. Instead treating species strata, alternative form analysis treat species covariate modelling detection function (Marques & Buckland, 2003). principle general key function shared across species, scale parameter \\((\\sigma)\\) differs species. way, detections species shared, estimation detection function rare species bolstered information species; yet rare species receives unique detection function bias induced abundance estimation species. demonstrate analysis, Montrave songbird study conducted Buckland (2006) used. species covariate approach analysis snapshot point count version survey described book Buckland et al. (2015, sec. 5.3.2.2). Distance R package (Miller, Rexstad, Thomas, Marshall, & Laake, 2019) used analyse line transect survey Buckland conducted. Results compared estimates presented Buckland (2006). data available online website serves companion Buckland et al. (2015). data set can read R directly URL.","code":"theurl <-\"https://www.creem.st-andrews.ac.uk/files/2023/01/montrave-line_csv.zip\" download.file(theurl, destfile = \"montrave.zip\", mode = \"wb\") unzip(\"montrave.zip\") birds <- read.csv(\"montrave-line.csv\") birds$object <- NA birds$object[!is.na(birds$distance)] <- 1:sum(!is.na(birds$distance))"},{"path":"/articles/species-covariate-distill.html","id":"data-preparation","dir":"Articles","previous_headings":"","what":"Data preparation","title":"Covariate modeling with rare species","text":"one slight modification data needs conducted can analysed. Buckland (2006) made two transits transects, line transect effort needs modified reflect multiple visits.","code":"birds$Effort <- birds$Effort * birds$repeats   # two visits library(Distance) convunit <- convert_units(\"meter\", \"kilometer\", \"hectare\")"},{"path":"/articles/species-covariate-distill.html","id":"detections-by-species","dir":"Articles","previous_headings":"","what":"Detections by species","title":"Covariate modeling with rare species","text":"Buckland’s (2006) line transect survey, three four songbird species (c-chaffinch, g-great tit, r-robin, w-winter wren) detected sufficient quantities sample size issue. However, great tit detected 32 times, making support species open question. Table 1: Table 2: Number detections species Montrave line transect survey. mentioned Background, fit pooled detection function across species species stratification criterion produce species-specific density estimates using pooled detection function conjunction species-specific encounter rates. However using wrong detection function every species. take alternative analysis route incorporate species detection function.","code":""},{"path":"/articles/species-covariate-distill.html","id":"covariate-in-detection-function","dir":"Articles","previous_headings":"","what":"Covariate in detection function","title":"Covariate modeling with rare species","text":"Inclusion species covariate detection function simple using formula= argument ds(). Note species names coded letters, R automatically treat variable containing letters factor covariate. numbers used coding species, .factor need employed. CvM goodness fit test indicates model adequately fits data, W=0.401, P=0.072.","code":"all.birds <- ds(data = birds, key=\"hn\", convert_units = convunit,                 formula=~species, truncation = 95)"},{"path":"/articles/species-covariate-distill.html","id":"visualising-the-detection-functions-for-each-species","dir":"Articles","previous_headings":"","what":"Visualising the detection functions for each species","title":"Covariate modeling with rare species","text":"shape species-specific detection functions can seen using plotting function provided . Figure 1: Species-specific detection functions.","code":"plot(all.birds, showpoints=FALSE, main=\"Montrave line transects\\nspecies as covariate\") add.df.covar.line(all.birds, data=data.frame(species=\"c\"), lwd=3, lty=1, col=\"blue\") add.df.covar.line(all.birds, data=data.frame(species=\"g\"), lwd=3, lty=1, col=\"darkgreen\") add.df.covar.line(all.birds, data=data.frame(species=\"r\"), lwd=3, lty=1, col=\"brown\") add.df.covar.line(all.birds, data=data.frame(species=\"w\"), lwd=3, lty=1, col=\"salmon\") legend(\"topright\", legend=c(\"chaffinch\", \"great tit\", \"robin\", \"winter wren\"),        lwd=3, lty=1, col=c(\"blue\", \"darkgreen\", \"brown\", \"salmon\"))"},{"path":"/articles/species-covariate-distill.html","id":"species-specific-density-estimates","dir":"Articles","previous_headings":"","what":"Species-specific density estimates","title":"Covariate modeling with rare species","text":"Density estimates species can produced using dht2 function contains argument strat_formula used specific levels stratum-specific estimates requested. stratification argument ensures correct measures precision associated species-specific density estimates. value object indicates analysis form post-stratification, rather geographic stratification criterion know prior gathering data. Table 3: Table 4: Species-specific density estimates using detection function species covariate.","code":"bird.ests <- dht2(ddf=all.birds, flatfile=birds,                   strat_formula = ~species, convert_units = convunit,                   stratification = \"object\")"},{"path":"/articles/species-covariate-distill.html","id":"compare-with-published-estimates","dir":"Articles","previous_headings":"","what":"Compare with published estimates","title":"Covariate modeling with rare species","text":"density estimates chaffinch great tits match reported Buckland (S. T. Buckland, 2006) almost exactly. congruence estimates produced analysis reported Buckland less good robins winter wrens. Figure 2: Reproduction Table 2 Buckland (2006).","code":""},{"path":"/articles/species-covariate-distill.html","id":"postscript","dir":"Articles","previous_headings":"","what":"Postscript","title":"Covariate modeling with rare species","text":"described Buckland (S. T. Buckland, 2006), reason believe evasive movement took place part robins winter wrens. Conceivably, accommodated using hazard rate key function two species. lead complex analysis data set divided chaffinch/great tit data set, half normal key species covariate detection function model. portion data set contain robins/winter wrens modelled using hazard rate key function species covariate. Indeed, goodness fit complex analysis (shown) leads better fit “two model” approach: Table 5: Table 6: Goodness fit comparison single model compared HN/HR split.","code":""},{"path":[]},{"path":"/articles/web-only/alt-optimise/mcds-dot-exe.html","id":"objectives","dir":"Articles > Web-only > Alt-optimise","previous_headings":"","what":"Objectives","title":"Alternative optimization engine for fitting detection functions","text":"Download mcds.exe optimization engine Demonstrate use simple line transect example (golf tee dataset) via Distance package Demonstrate example via mrds package Demonstrate use point transect example (wren data) one optimizers work well (gives negative estimated detection probability) Demonstrate use speed analysis camera trap distance sampling data (duiker data) via Distance package Discuss using alternative optimization engine may useful.","code":""},{"path":"/articles/web-only/alt-optimise/mcds-dot-exe.html","id":"introduction","dir":"Articles > Web-only > Alt-optimise","previous_headings":"","what":"Introduction","title":"Alternative optimization engine for fitting detection functions","text":"Distance package designed provide simple way fit detection functions estimate abundance using conventional distance sampling methodology (.e., single observer distance sampling, possibly covariates, described Buckland et al. (2015)). main function ds. Underlying Distance package mrds – function ds called pre-processing calls function ddf mrds package work detection function fitting. mrds uses maximum likelihood fit specified detection function model distance data using built-algorithm written R. alternative method analyzing distance sampling data using Distance Windows software (Thomas et al., 2010). software also uses maximum liklihood fit detection function models, relies software written programming language FORTRAN fitting. filename software MCDS.exe. perfect world, methods produce identical results given data model specification, since likelihood one maximum. However, likelihood surface sometimes complex, especially monotonicity constraints used (ensures estimated detection probability flat decreasing increasing distance adjustment terms used) “overdispersed” “spiked” data (see Figure 2 Thomas et al. (2010)), (rare) cases one piece software fails find maximum. counteract , possible run R-based optimizer MCDS.exe ds function within Distance package ddf function within mrds package. Another motivation using MCDS.exe software within R R-based optimizer sometimes slow converge using MCDS.exe place R-based optimizer can save significant time, particularly nonparametric bootstrap large datasets. vignette demonstrates download use MCDS.exe sofware within Distance mrds packages. information, see MCDS.exe help page within mrds package.","code":""},{"path":"/articles/web-only/alt-optimise/mcds-dot-exe.html","id":"downloading-and-verifying-mcds-exe","dir":"Articles > Web-only > Alt-optimise","previous_headings":"","what":"Downloading and verifying MCDS.exe","title":"Alternative optimization engine for fitting detection functions","text":"program MCDS.exe come automatically Distance mrds packages, avoid violating CRAN rules, must first download distance sampling website. can check whether MCDS.exe installed already loading Distance library: MCDS.exe installed, receive message MCDS.exe detected, single observer analyses run using optimiser mrds R library. See ?MCDS details. case, need download Distancesampling.org web site: Now reload Distance package, MCDS.exe detected message shown: Now software available, R optimizer used default analysis; can also choose use just one , shown .","code":"library(Distance) download.file(\"http://distancesampling.org/R/MCDS.exe\", paste0(system.file(package=\"mrds\"),\"/MCDS.exe\"), mode = \"wb\") detach(\"package:Distance\", unload = TRUE) library(Distance) ##  ## Attaching package: 'Distance' ## The following object is masked from 'package:mrds': ##  ##     create.bins"},{"path":[]},{"path":"/articles/web-only/alt-optimise/mcds-dot-exe.html","id":"both-mcds-exe-and-the-r-based-optimizer","dir":"Articles > Web-only > Alt-optimise","previous_headings":"Example with Golf Tee data","what":"Both MCDS.exe and the R-based optimizer","title":"Alternative optimization engine for fitting detection functions","text":"example (golf tee data, using observer 1) taken R help ds function: (warning cluster sizes coded -1 can ignored.) Assuming MCDS.exe installed, default R-based optimizer run. give result example, happens result R-based optimizer used. can see line summary output: Optimisation:  mrds (nlminb) mrds R package Distance package relies , nlminb R-based optimizer. can see process optimizers used setting debug_level argument ds function value larger default 0 examining output: First half-normal adjustments run; model MCDS.exe sofware run first, followed R-based (mrds) optimizer. converge give nll (negative log-likelihood) 154.5692, giving AIC 311.138. model half-normal cosine adjustment order 2 fitted data, first MCDS.exe optimizer R-based optimizer. give result nll 154.5619 AIC 313.124. higher AIC adjustments half-normal adjustments chosen. case, optimizers produced result, benefit run MCDS.exe.","code":"#Load data data(book.tee.data) tee.data <- subset(book.tee.data$book.tee.dataframe, observer==1) #Fit detection function - default is half-normal with cosine adjustments ds.model <- ds(tee.data, truncation = 4) ## Starting AIC adjustment term selection. ## Fitting half-normal key function ## AIC= 311.138 ## Fitting half-normal key function with cosine(2) adjustments ## AIC= 313.124 ##  ## Half-normal key function selected. ## No survey area information supplied, only estimating detection function. summary(ds.model) ##  ## Summary for distance analysis  ## Number of observations :  124  ## Distance range         :  0  -  4  ##  ## Model       : Half-normal key function  ## AIC         :  311.1385  ## Optimisation:  mrds (nlminb)  ##  ## Detection function parameters ## Scale coefficient(s):   ##              estimate         se ## (Intercept) 0.6632435 0.09981249 ##  ##                        Estimate          SE         CV ## Average p             0.5842744  0.04637627 0.07937412 ## N in covered region 212.2290462 20.85130344 0.09824906 ds.model <- ds(tee.data, truncation = 4, debug_level = 1) ## Starting AIC adjustment term selection. ## Fitting half-normal key function ## DEBUG: initial values = -0.1031529 ## Running MCDS.exe... ## Command file written to C:\\Users\\erexs\\AppData\\Local\\Temp\\Rtmpa0CFjT\\cmdtmp3500288c6ec7.txt ## Stats file written to C:\\Users\\erexs\\AppData\\Local\\Temp\\Rtmpa0CFjT\\stat3500a4c28ca.txt ## DEBUG: initial values = 0.6632378  ##  ## DEBUG: Convergence!  ##        Iteration  0.0  ##        Converge   = 0  ##        nll        = 154.5692  ##        parameters = 0.6632378 ## MCDS.exe log likehood: -154.5697 ## MCDS.exe pars: 1.941067 ## mrds refitted log likehood: -154.5692276 ## mrds refitted pars: 0.6632378 ##  ## DEBUG: Convergence!  ##        Iteration  0.0  ##        Converge   = 0  ##        nll        = 154.5692  ##        parameters = 0.6632435 ## AIC= 311.138 ## Fitting half-normal key function with cosine(2) adjustments ## DEBUG: initial values = -0.1031529 0 ## Running MCDS.exe... ## Command file written to C:\\Users\\erexs\\AppData\\Local\\Temp\\Rtmpa0CFjT\\cmdtmp350011864b0f.txt ## Stats file written to C:\\Users\\erexs\\AppData\\Local\\Temp\\Rtmpa0CFjT\\stat35001a9f5e79.txt ## DEBUG: initial values = 0.6606793 -0.0159333  ##  ## DEBUG: Convergence!  ##        Iteration  0.0  ##        Converge   = 0  ##        nll        = 154.5619  ##        parameters = 0.6606793, -0.0159333 ## MCDS.exe log likehood: -154.5624 ## MCDS.exe pars: 1.936107, -0.0159333 ## mrds refitted log likehood: -154.5619307 ## mrds refitted pars: 0.6606793, -0.0159333 ##  ## Iter: 1 fn: 154.5619  Pars:   0.66068 -0.01591 ## Iter: 2 fn: 154.5619  Pars:   0.66069 -0.01592 ## solnp--> Completed in 2 iterations ##  ## DEBUG: Convergence!  ##        Iteration  0.0  ##        Converge   = 0  ##        nll        = 154.5619  ##        parameters = 0.6606853, -0.0159233 ## AIC= 313.124 ##  ## Half-normal key function selected. ## No survey area information supplied, only estimating detection function."},{"path":"/articles/web-only/alt-optimise/mcds-dot-exe.html","id":"specifying-which-optimzier-to-run","dir":"Articles > Web-only > Alt-optimise","previous_headings":"Example with Golf Tee data","what":"Specifying which optimzier to run","title":"Alternative optimization engine for fitting detection functions","text":"said earlier, default behaviour MCDS.exe downloaded run MCDS.exe R-based optimizer. However, optimizer argument can used specify use – either , R MCDS. example just MCDS.exe optimizer:","code":"ds.model <- ds(tee.data, truncation = 4, optimizer = \"MCDS\") ## Starting AIC adjustment term selection. ## Fitting half-normal key function ## AIC= 311.138 ## Fitting half-normal key function with cosine(2) adjustments ## AIC= 313.124 ##  ## Half-normal key function selected. ## No survey area information supplied, only estimating detection function."},{"path":"/articles/web-only/alt-optimise/mcds-dot-exe.html","id":"demonstration-using-ddf-in-mrds-package","dir":"Articles > Web-only > Alt-optimise","previous_headings":"Example with Golf Tee data","what":"Demonstration using ddf in mrds package","title":"Alternative optimization engine for fitting detection functions","text":"demonstrate using optimizers ddf function, rather via ds. exercise, fit using just MCDS.exe optimizer:","code":"#Half normal detection function ddf.model <- ddf(dsmodel = ~mcds(key = \"hn\", formula = ~1), data = tee.data, method = \"ds\",                  meta.data = list(width = 4)) #Half normal with cos(2) adjustment ddf.model.cos2 <- ddf(dsmodel = ~mcds(key = \"hn\", adj.series = \"cos\", adj.order = 2, formula = ~1),                       data = tee.data, method = \"ds\", meta.data = list(width = 4)) #Compare with AIC AIC(ddf.model, ddf.model.cos2) ##                df      AIC ## ddf.model       1 311.1385 ## ddf.model.cos2  2 313.1239 #Model with no adjustment term has lower AIC; show summary of this model summary(ddf.model) ##  ## Summary for ds object ## Number of observations :  124  ## Distance range         :  0  -  4  ## AIC                    :  311.1385  ## Optimisation           :  mrds (nlminb)  ##  ## Detection function: ##  Half-normal key function  ##  ## Detection function parameters  ## Scale coefficient(s):  ##              estimate         se ## (Intercept) 0.6632435 0.09981249 ##  ##                        Estimate          SE         CV ## Average p             0.5842744  0.04637627 0.07937412 ## N in covered region 212.2290462 20.85130344 0.09824906 ddf.model <- ddf(dsmodel = ~mcds(key = \"hn\", adj.series = \"cos\", adj.order = 2,                                 formula = ~1), data = tee.data, method = \"ds\",                  meta.data = list(width = 4),                  control = list(optimizer = \"MCDS\")) summary(ddf.model) ##  ## Summary for ds object ## Number of observations :  124  ## Distance range         :  0  -  4  ## AIC                    :  313.1239  ## Optimisation           :  MCDS.exe  ##  ## Detection function: ##  Half-normal key function with cosine adjustment term of order 2  ##  ## Detection function parameters  ## Scale coefficient(s):  ##              estimate        se ## (Intercept) 0.6606782 0.1043327 ##  ## Adjustment term coefficient(s):   ##                 estimate        se ## cos, order 2 -0.01593274 0.1351281 ##  ##                        Estimate          SE        CV ## Average p             0.5925856  0.08165144 0.1377884 ## N in covered region 209.2524623 31.22790760 0.1492356"},{"path":"/articles/web-only/alt-optimise/mcds-dot-exe.html","id":"point-transect-example---wren-data","dir":"Articles > Web-only > Alt-optimise","previous_headings":"","what":"Point transect example - wren data","title":"Alternative optimization engine for fitting detection functions","text":"example point transect data bird (wren), Buckland (2006). case one optimizers fails correctly constrain detection function probability detection zero distances, use optimizer inference. load wren 5 minute example dataset define cutpoints distances (collected intervals). following call ds gives several warnings. warnings detection function less zero distances. also warning Hessian (used variance estimation), relates Hermite(4, 6) model (.e., two Hermite adjustment terms order 4 6) chosen using AIC warning can ignored. MCDS.exe optimizer chosen one (see `Optimisation’ line output). warnings persist MCDS.exe optimizer used: Looking plot fitted object (Figure 1), seems evaluated pdf less 0 distances close truncation point (approx. 95m greater): Figure 1: PDF fitted model MCDS optimizer. appears happening failure optimization routine appropriately constrain model parameters detection function valid. happens occasion (routines aren’t perfect!) recommend trying optimization routine. use R-based optimizer: fitted AIC chosen model (half normal one Hermite adjustment order 4) 422.74, higher MCDS.exe optimizer (422.23), explains MCDS.exe optimizer fit chosen allowed ds choose freely. However, detection function fit MCDS.exe invalid, went lower 0 95m, fit R-based optimizer looks valid (Figure 2): Figure 2: PDF fitted model R-based optimizer. Hence case, use R-based optimizer’s fit.","code":"data(\"wren_5min\") bin.cutpoints.100m <- bin.cutpoints <- c(0, 10, 20, 30, 40, 60, 80, 100) wren5min.hn.herm.t100 <- ds(data=wren_5min, key=\"hn\", adjustment=\"herm\",                              transect=\"point\", cutpoints=bin.cutpoints.100m) ## Warning in create_bins(data, cutpoints): Some distances were outside bins and ## have been removed. ## Starting AIC adjustment term selection. ## Fitting half-normal key function ## AIC= 427.471 ## Fitting half-normal key function with Hermite(4) adjustments ## Warning in check.mono(result, n.pts = control$mono.points): Detection function ## is less than 0 at some distances ## Warning in check.mono(result, n.pts = control$mono.points): Detection function ## is less than 0 at some distances ## AIC= 422.228 ## Fitting half-normal key function with Hermite(4,6) adjustments ## Warning: First partial hessian is singular and second-partial hessian is NULL, no hessian ## Warning: Detection function is less than 0 at some distances ## Warning: Detection function is less than 0 at some distances ## AIC= 423.255 ##  ## Half-normal key function with Hermite(4) adjustments selected. ## Warning in mrds::check.mono(model, n.pts = 20): Detection function is less than ## 0 at some distances summary(wren5min.hn.herm.t100) ##  ## Summary for distance analysis  ## Number of observations :  132  ## Distance range         :  0  -  100  ##  ## Model       : Half-normal key function with Hermite polynomial adjustment term of order 4  ##  ## Strict monotonicity constraints were enforced. ## AIC         :  422.2284  ## Optimisation:  MCDS.exe  ##  ## Detection function parameters ## Scale coefficient(s):   ##             estimate    se ## (Intercept) 12.08697 1e+05 ##  ## Adjustment term coefficient(s):   ##                estimate         se ## herm, order 4 0.5723854 0.07889437 ##  ##                        Estimate         SE         CV ## Average p             0.4399177  0.0253497 0.05762374 ## N in covered region 300.0561563 26.0954740 0.08696863 ##  ## Summary statistics: ##     Region Area CoveredArea Effort   n  k     ER     se.ER      cv.ER ## 1 Montrave 33.2     2010619     64 132 32 2.0625 0.1901692 0.09220324 ##  ## Abundance: ##   Label    Estimate         se        cv         lcl         ucl       df ## 1 Total 0.004954625 0.00053871 0.1087287 0.003988055 0.006155458 57.84101 ##  ## Density: ##   Label     Estimate          se        cv          lcl          ucl       df ## 1 Total 0.0001492357 1.62262e-05 0.1087287 0.0001201222 0.0001854054 57.84101 wren5min.hn.herm.t100.mcds <- ds(data=wren_5min, key=\"hn\", adjustment=\"herm\",                              transect=\"point\", cutpoints=bin.cutpoints.100m,                             optimizer = \"MCDS\") ## Warning in create_bins(data, cutpoints): Some distances were outside bins and ## have been removed. ## Starting AIC adjustment term selection. ## Fitting half-normal key function ## AIC= 427.471 ## Fitting half-normal key function with Hermite(4) adjustments ## Warning in check.mono(result, n.pts = control$mono.points): Detection function ## is less than 0 at some distances ## Warning in check.mono(result, n.pts = control$mono.points): Detection function ## is less than 0 at some distances ## AIC= 422.228 ## Fitting half-normal key function with Hermite(4,6) adjustments ## Warning: First partial hessian is singular and second-partial hessian is NULL, no hessian ## Warning: Detection function is less than 0 at some distances ## Warning: Detection function is less than 0 at some distances ## AIC= 423.255 ##  ## Half-normal key function with Hermite(4) adjustments selected. ## Warning in mrds::check.mono(model, n.pts = 20): Detection function is less than ## 0 at some distances plot(wren5min.hn.herm.t100.mcds, pdf = TRUE) wren5min.hn.herm.t100.r <- ds(data=wren_5min, key=\"hn\", adjustment=\"herm\",                              transect=\"point\", cutpoints=bin.cutpoints.100m,                             optimizer = \"R\") ## Warning in create_bins(data, cutpoints): Some distances were outside bins and ## have been removed. ## Starting AIC adjustment term selection. ## Fitting half-normal key function ## AIC= 427.471 ## Fitting half-normal key function with Hermite(4) adjustments ## AIC= 422.743 ## Fitting half-normal key function with Hermite(4,6) adjustments ## AIC= 424.52 ##  ## Half-normal key function with Hermite(4) adjustments selected. plot(wren5min.hn.herm.t100.r, pdf = TRUE)"},{"path":"/articles/web-only/alt-optimise/mcds-dot-exe.html","id":"camera-trap-example","dir":"Articles > Web-only > Alt-optimise","previous_headings":"","what":"Camera trap example","title":"Alternative optimization engine for fitting detection functions","text":"example, helps familiar Analysis camera trapping data vignette distanceexamples web site. first read Duiker data. fit detection function selected camera trap vignette, uniform plus 3 cosine adjustment terms, time long fitting takes: Fitting takes quite ! - 52 secs. try MCDS.exe optimizer: took 9 secs. Hence, datasets, may quicker use MCDS.exe optimizer. makes particularly big difference using nonparametric bootstrap estimate variance.","code":"#Read in data and set up data for analysis DuikerCameraTraps <- read.csv(file=\"https://datadryad.org/stash/downloads/file_stream/73221\",                                header=TRUE, sep=\"\\t\") DuikerCameraTraps$Area <- DuikerCameraTraps$Area / (1000*1000) DuikerCameraTraps$object <- NA DuikerCameraTraps$object[!is.na(DuikerCameraTraps$distance)] <- 1:sum(!is.na(DuikerCameraTraps$distance))  #Specify breakpoints and truncation trunc.list <- list(left=2, right=15) mybreaks <- c(seq(2,8,1), 10, 12, 15) start.time <- Sys.time() uni3.r <- ds(DuikerCameraTraps, transect = \"point\", key=\"unif\", adjustment = \"cos\",            nadj=3, cutpoints = mybreaks, truncation = trunc.list, optimizer = \"R\") ## Warning in create_bins(data, cutpoints): Some distances were outside bins and ## have been removed. ## Fitting uniform key function with cosine(1,2,3) adjustments ## AIC= 44012.394 R.opt.time <- Sys.time() - start.time summary(uni3.r) ##  ## Summary for distance analysis  ## Number of observations :  10284  ## Distance range         :  2  -  15  ##  ## Model       : Uniform key function with cosine adjustment terms of order 1,2,3  ##  ## Strict monotonicity constraints were enforced. ## AIC         :  44012.39  ## Optimisation:  mrds (nlminb)  ##  ## Detection function parameters ## Scale coefficient(s):   ## NULL ##  ## Adjustment term coefficient(s):   ##                estimate         se ## cos, order 1  0.9354124 0.01504250 ## cos, order 2 -0.0530414 0.02437441 ## cos, order 3 -0.0804323 0.01557445 ##  ##                         Estimate           SE         CV ## Average p           3.288267e-01 1.348161e-02 0.04099915 ## N in covered region 3.127483e+04 1.306897e+03 0.04178749 ##  ## Summary statistics: ##   Region  Area CoveredArea   Effort     n  k           ER        se.ER    cv.ER ## 1    Tai 40.37 21858518573 31483179 10284 21 0.0003266506 8.763252e-05 0.268276 ##  ## Abundance: ##   Label     Estimate           se        cv          lcl          ucl      df ## 1 Total 5.776078e-05 1.567574e-05 0.2713908 3.317613e-05 0.0001005635 20.9451 ##  ## Density: ##   Label     Estimate           se        cv          lcl          ucl      df ## 1 Total 1.430785e-06 3.883017e-07 0.2713908 8.218016e-07 2.491045e-06 20.9451 start.time <- Sys.time() uni3.mcds <- ds(DuikerCameraTraps, transect = \"point\", key=\"unif\", adjustment = \"cos\",                 nadj=3, cutpoints = mybreaks, truncation = trunc.list, optimizer = \"MCDS\") ## Warning in create_bins(data, cutpoints): Some distances were outside bins and ## have been removed. ## Fitting uniform key function with cosine(1,2,3) adjustments ## AIC= 44012.211 MCDS.opt.time <- Sys.time() - start.time summary(uni3.mcds) ##  ## Summary for distance analysis  ## Number of observations :  10284  ## Distance range         :  2  -  15  ##  ## Model       : Uniform key function with cosine adjustment terms of order 1,2,3  ##  ## Strict monotonicity constraints were enforced. ## AIC         :  44012.21  ## Optimisation:  MCDS.exe  ##  ## Detection function parameters ## Scale coefficient(s):   ## NULL ##  ## Adjustment term coefficient(s):   ##                 estimate         se ## cos, order 1  0.93518220 0.01504583 ## cos, order 2 -0.05345965 0.02438049 ## cos, order 3 -0.08073799 0.01557817 ##  ##                         Estimate           SE         CV ## Average p           3.290679e-01 1.349917e-02 0.04102246 ## N in covered region 3.125191e+04 1.306645e+03 0.04181008 ##  ## Summary statistics: ##   Region  Area CoveredArea   Effort     n  k           ER        se.ER    cv.ER ## 1    Tai 40.37 21858518573 31483179 10284 21 0.0003266506 8.763252e-05 0.268276 ##  ## Abundance: ##   Label     Estimate           se        cv          lcl          ucl       df ## 1 Total 5.771844e-05 1.566445e-05 0.2713943 3.315164e-05 0.0001004903 20.94619 ##  ## Density: ##   Label     Estimate           se        cv         lcl          ucl       df ## 1 Total 1.429736e-06 3.880222e-07 0.2713943 8.21195e-07 2.489232e-06 20.94619"},{"path":"/articles/web-only/alt-optimise/mcds-dot-exe.html","id":"discussion","dir":"Articles > Web-only > Alt-optimise","previous_headings":"","what":"Discussion","title":"Alternative optimization engine for fitting detection functions","text":"shown fit distance sampling detection functions (single platform data) using either R-based optimizer built ddf function (via calling ddf , likely, calling ds function Distance package) MCDS.exe analysis engine used Distance Windows. vast majority cases fitting methods give result, need use . However, downside fitting takes longer, called turn. downloaded MCDS.exe file want speed things , can use just R-based optimizer specifying optimizer = \"R\" call ds ddf, just MCDS.exe optimizer optimizer = \"MCDS\". situations two may produce different results given . Detection functions close non-monotonic close zero distances. adjustment terms used detection function, constraints required prevent fitted function “bumps” detection probability increases increasing distance also prevent detection probability becoming less zero. former called monotonicity constraints set using monotonicity argument ds meta.data argument ddf; monotonicity set default. practice, monotonicity values less zero monitored finite set distances 0 right truncation point, (historical reasons) set distances different R-based MCDS.exe optimizers. typically makes difference optimization, particularly borderline cases can result different fitted functions. Plotting fitted functions (wren example ) can reveal issue fitted function, occurs associated optimizer used. future plan bring two line use distances checking. Detection functions many adjustment terms. two optimizers use different algorithms optimization: R-based optimizer uses routine called nlminb MCDS.exe uses nonlinear constrained optimizer routine produced IMSL group. cases multiple adjustment terms, hence several parameters estimate (often correlated) likelihood maximization harder, one routine can sometimes fail find maximum. case, choosing routine higher likelihood (.e., lower negative log-likelihod, equivalently lower AIC) right thing , default behaviour software. Detection functions “overdispersed” “spike” detection function close zero distance. Similarly , detection function can hard maximize hence optimizer can fail find maximum. Solution . Overdispersed data common camera trap distance sampling many detections can generated individual crossing front camera. interested seeing comparisons optimizers various datasets, maintain test suite straightforward challenging datasets together test code run compare two optimizers – available MCDS_mrds_compare repository. encounter difficulties using optimizers, one possible troubleshooting step run analysis first choosing one optimizer (e.g., specifing argument optimizer = \"MCDS\") choosing (optimizer = \"R\"). allows clearly see output optimizer (including error messages) facilitates comparison. One criterion favour one optimizer speed, found large datasets MCDS.exe optimizer quicker. One thing note MCDS.exe file get deleted time update mrds package, ’ll need re-download file want continue using MCDS.exe optimizer. shown , requires running one line code. Going forward, plan work making improvements R-based optimizer possible point future confident optimizer uniformly better (terms better fit speed) MCDS.exe one. happens, update vignette also make announcements distance sampling list.","code":""},{"path":[]},{"path":"/articles/web-only/CTDS/camera-distill.html","id":"analysis-of-camera-trapping-data-using-distance-sampling","dir":"Articles > Web-only > CTDS","previous_headings":"","what":"Analysis of camera trapping data using distance sampling","title":"Analysis of camera trapping data","text":"distance sampling approach analysis camera trapping data offers potential advantage individual animal identification required. However, accurate animal--camera detection distances required. requires calibration prior survey images objects taken known distances camera. See details Howe, Buckland, Després-Einspenner, & Kühl (2017) description field work data analysis. present analysis data Howe et al. (2017) using R package Distance (Miller, Rexstad, Thomas, Marshall, & Laake, 2019).","code":""},{"path":"/articles/web-only/CTDS/camera-distill.html","id":"estimating-temporal-availability-for-detection","dir":"Articles > Web-only > CTDS","previous_headings":"Analysis of camera trapping data using distance sampling","what":"Estimating temporal availability for detection","title":"Analysis of camera trapping data","text":"Heat- motion-sensitive camera traps detect moving animals within range sensor field view camera. Animals therefore unavailable detection camera traps stationary, (e.g., semi-arboreal species) (e.g., semi-fossorial species) range sensor camera, regardless distance camera two dimensions. temporally limited availability detection must accounted avoid negative bias estimated densities. data abundant, researchers may choose include data times 100% population can assumed active within vertical range camera traps (Howe et al., 2017). However, rarely-detected species surveys lower effort, might necessary include observations distance. situations, survey duration (\\(T_k\\)) might 12- 24-hours per day, becomes necessary estimate proportion time included \\(T_k\\) animals available detection. Methods estimating proportion directly CT data described (Rowcliffe, Kays, Kranstauber, Carbone, & Jansen, 2014), can included analyses estimate density (Bessone et al., 2020), example another multiplier, potentially associated standard errors.","code":""},{"path":"/articles/web-only/CTDS/camera-distill.html","id":"data-input","dir":"Articles > Web-only > CTDS","previous_headings":"Analysis of camera trapping data using distance sampling","what":"Data input","title":"Analysis of camera trapping data","text":"Times independent camera triggering events period 28 June 21 September 2014 23 cameras recorded file described data repository Howe, Buckland, Després-Einspenner, Kühl, & Buckland (2018). Download file Dryad save local drive, read following code: format trigger.events data frame adjusted create datetime field use activity package Rowcliffe (2021)","code":"trigger.events <- read.table(file=\"VideoStartTimes_FullDays.txt\", header=TRUE) trigger.events$date <- paste(\"2014\",                        sprintf(\"%02i\", trigger.events$month),                         sprintf(\"%02i\", trigger.events$day),                        sep=\"/\") trigger.events$time <- paste(sprintf(\"%02i\", trigger.events$hour),                        sprintf(\"%02i\", trigger.events$minute),                        sep=\":\") trigger.events$datetime <- paste(trigger.events$date, trigger.events$time)"},{"path":"/articles/web-only/CTDS/camera-distill.html","id":"functions-in-the-activity-package","dir":"Articles > Web-only > CTDS","previous_headings":"Analysis of camera trapping data using distance sampling","what":"Functions in the activity package","title":"Analysis of camera trapping data","text":"employ two functions activity package. First, convert time day camera triggering event fraction 24hr cycle event took place, measured radians. words, event occurring midday recorded \\(\\pi\\) event occurring midnight recorded 2\\(\\pi\\). radian conversion camera triggering times, distribution triggering events times smoothed, using kernel smoother function fitact. function estimates proportion time (24hr day) animals active. addition, triggering time data can resampled provide measure uncertainty point estimate activity proportion. plot histogram triggering times (Figure 1), along fitted smooth provided plot function applied object returned fitact. Figure 1: Fitted smooth histogram camera triggering times Maxwell’s duiker data. value computed smooth activity histogram can extracted object created fitact. extraction reaches object look slot called act. uncertainty around point estimate derived resampling takes place within fitact. slot display point estimates, standard error confidence interval bounds. output used adjust density estimates temporal activity cameras operation 24hrs per day. However, study, cameras active 11.5 hours per day (0630-1800).","code":"library(activity) trigger.events$rtime <- gettime(trigger.events$datetime,                                  tryFormats = \"%Y/%m/%d %H:%M\",                                 scale = \"radian\") act_result <- fitact(trigger.events$rtime, sample=\"data\", reps=100) plot(act_result) print(act_result@act) ##        act         se   lcl.2.5%  ucl.97.5%  ## 0.33463831 0.02096859 0.30195769 0.37801207"},{"path":"/articles/web-only/CTDS/camera-distill.html","id":"adjustment-for-temporal-availability","dir":"Articles > Web-only > CTDS","previous_headings":"Analysis of camera trapping data using distance sampling","what":"Adjustment for temporal availability","title":"Analysis of camera trapping data","text":"use temporal availability information create multiplier. multiplier must defined > proportion camera operation time animals available detected equivalent value produced fitact function; value proportion 24hr animals available detected. availability multiplier must adjusted based daily camera operation period. Uncertainty proportion also included computations. point estimate standard error pulled fitact object, adjusted daily camera operation time placed data frame named creation named list, specifically fashion shown. robust way incorporating uncertainty temporal availability estimate described later.","code":"camera.operation.per.day <- 11.5 prop.camera.time <- camera.operation.per.day / 24 avail <- list(creation=data.frame(rate = act_result@act[1]/prop.camera.time,                                   SE   = act_result@act[2]/prop.camera.time))"},{"path":"/articles/web-only/CTDS/camera-distill.html","id":"detection-data-analysis","dir":"Articles > Web-only > CTDS","previous_headings":"","what":"Detection data analysis","title":"Analysis of camera trapping data","text":"Detection distances full daytime data set also available Howe et al. (2018). Download Dryad read code chunk : Data file recorded study area size square meters; second line converts area square kilometers; remaining lines create object field, uniquely identify observation.","code":"DuikerCameraTraps <- read.csv(file=\"DaytimeDistances.txt\", header=TRUE, sep=\"\\t\") DuikerCameraTraps$Area <- DuikerCameraTraps$Area / (1000*1000) DuikerCameraTraps$object <- NA DuikerCameraTraps$object[!is.na(DuikerCameraTraps$distance)] <- 1:sum(!is.na(DuikerCameraTraps$distance))"},{"path":"/articles/web-only/CTDS/camera-distill.html","id":"exploratory-data-analysis","dir":"Articles > Web-only > CTDS","previous_headings":"Detection data analysis","what":"Exploratory Data Analysis","title":"Analysis of camera trapping data","text":"quick summary data set including: many camera stations many detections total. Note, three sampling stations (B1, C5, E4) detections. one record stations distance recorded NA, record important contains effort information.","code":"sum(!is.na(DuikerCameraTraps$distance)) ## [1] 11180 table(DuikerCameraTraps$Sample.Label) ##  ##   A1   A2   A3   A4   B1   B2   B3   B4   C1   C2   C3   C4   C5   C6   D3   D4  ##  388   66  988  420    3 1951   73  208   52  195  767  153   41 2682  342  193  ##   D5   E3   E4   E5   E6  ##  524  518    1  375 1241"},{"path":"/articles/web-only/CTDS/camera-distill.html","id":"distance-recording","dir":"Articles > Web-only > CTDS","previous_headings":"Detection data analysis","what":"Distance recording","title":"Analysis of camera trapping data","text":"examination distribution detection distances; note bespoke cutpoints causing distance bins narrow 8m, increasing width maximum detection distance 21m (Figure 2). Figure 2: Distribution detection distances peak activity period.","code":"breakpoints <- c(seq(0,8,1), 10, 12, 15, 21) hist(DuikerCameraTraps$distance, breaks=breakpoints, main=\"Peak activity data set\",      xlab=\"Radial distance (m)\")"},{"path":"/articles/web-only/CTDS/camera-distill.html","id":"truncation-decisions","dir":"Articles > Web-only > CTDS","previous_headings":"Detection data analysis","what":"Truncation decisions","title":"Analysis of camera trapping data","text":"described Howe et al. (2017): paucity observations 1 2 m 2 3 m, left-truncated 2 m. Fitted detection functions probability density functions heavy-tailed distances >15 m included, right truncated 15 m.","code":""},{"path":"/articles/web-only/CTDS/camera-distill.html","id":"detection-function-fits","dir":"Articles > Web-only > CTDS","previous_headings":"Detection data analysis","what":"Detection function fits","title":"Analysis of camera trapping data","text":"conversion factor must included call ds() call bootdht(). Candidate models considered differ candidate set presented Howe et al. (2017). set includes uniform key 1, 2 3 cosine adjustments, half normal key 0, 1 2 cosine adjustment hazard rate key 0, 1 simple polynomial adjustments. maximum number parameters models within candidate model set 3. present density estimates produced fitted detection function models ) chosen preferred model b) density estimates adjusted viewing angle temporal availability.","code":"library(Distance) trunc.list <- list(left=2, right=15) mybreaks <- c(seq(2,8,1), 10, 12, 15) conversion <- convert_units(\"meter\", NULL, \"square kilometer\") uni1 <- ds(DuikerCameraTraps, transect = \"point\", key=\"unif\", adjustment = \"cos\",            nadj=1, convert_units = conversion,            cutpoints = mybreaks, truncation = trunc.list) ## Warning in create_bins(data, cutpoints): Some distances were outside bins and ## have been removed. uni2 <- ds(DuikerCameraTraps, transect = \"point\", key=\"unif\", adjustment = \"cos\",            nadj=2, convert_units = conversion,            cutpoints = mybreaks, truncation = trunc.list) ## Warning in create_bins(data, cutpoints): Some distances were outside bins and ## have been removed. uni3 <- ds(DuikerCameraTraps, transect = \"point\", key=\"unif\", adjustment = \"cos\",            nadj=3, convert_units = conversion,            cutpoints = mybreaks, truncation = trunc.list) ## Warning in create_bins(data, cutpoints): Some distances were outside bins and ## have been removed. hn0 <- ds(DuikerCameraTraps, transect = \"point\", key=\"hn\", adjustment = NULL,           convert_units = conversion, cutpoints = mybreaks, truncation = trunc.list) ## Warning in create_bins(data, cutpoints): Some distances were outside bins and ## have been removed. hn1 <- ds(DuikerCameraTraps, transect = \"point\", key=\"hn\", adjustment = \"cos\",           nadj=1, convert_units = conversion,           cutpoints = mybreaks, truncation = trunc.list) ## Warning in create_bins(data, cutpoints): Some distances were outside bins and ## have been removed. hn2 <- ds(DuikerCameraTraps, transect = \"point\", key=\"hn\", adjustment = \"cos\",           nadj=2, convert_units = conversion,           cutpoints = mybreaks, truncation = trunc.list) ## Warning in create_bins(data, cutpoints): Some distances were outside bins and ## have been removed. hr0 <- ds(DuikerCameraTraps, transect = \"point\", key=\"hr\", adjustment = NULL,           convert_units = conversion, cutpoints = mybreaks, truncation = trunc.list) ## Warning in create_bins(data, cutpoints): Some distances were outside bins and ## have been removed. hr1 <- ds(DuikerCameraTraps, transect = \"point\", key=\"hr\", adjustment = \"poly\",           nadj=1, convert_units = conversion,           cutpoints = mybreaks, truncation = trunc.list) ## Warning in create_bins(data, cutpoints): Some distances were outside bins and ## have been removed."},{"path":"/articles/web-only/CTDS/camera-distill.html","id":"model-selection-adjustments-from-overdispersion","dir":"Articles > Web-only > CTDS","previous_headings":"Detection data analysis","what":"Model selection adjustments from overdispersion","title":"Analysis of camera trapping data","text":"Overdispersion causes AIC select overly-complex models, analysts specify number/order adjustment terms manually fitting distance sampling models data camera traps, rather allowing automated selection using AIC. Howe, Buckland, Després-Einspenner, & Kühl (2019) describe two methods performing model selection distance sampling models face overdispersion. provide R functions perform first methods. first method Howe et al. (2019) employs two-step process. First, overdisersion factor \\((\\hat{c})\\) computed key function family complex model family. \\(\\hat{c}\\) derived \\(\\chi^2\\) goodness fit test statistic divided degrees freedom. results adjusted AIC score model key function family: \\[QAIC = -2 \\left \\{ \\frac{log(\\mathcal{L}(\\hat{\\theta}))}{\\hat{c}} \\right \\} + 2K\\] Code perform QAIC computation found function QAIC Distance package, produces following results: Tables QAIC values key function family shown (code kable() calls suppressed easier readability results). Table 1: Table 2: QAIC values uniform key models. Table 3: Table 4: QAIC values half normal key models. Table 5: Table 6: QAIC values hazard rate key models. first pass model selection based QAIC values, find model uniform key function preferred QAIC three cosine adjustment terms. preferred model half normal key function family one cosine adjustment term. Finally, preferable model hazard rate key function family adjustment terms. second step model selection ranks models \\(\\hat{c}\\) values. Table 7: Table 8: Compare Table S5 Howe et al. (2018) data set, model chosen algorithm adjusts overdispersion model (uniform key three cosine adjustments) chosen conventional model selection; , model selected Howe et al. (2017) differing candidate model sets.","code":"chats <- chi2_select(uni3, hn1, hr0)$criteria modnames <- unlist(lapply(list(uni3, hn1, hr0), function(x) x$ddf$name.message)) results <- data.frame(modnames, chats) results.sort <- results[order(results$chats),] knitr::kable(results.sort, digits=2, row.names = FALSE,              caption=\"Compare with Table S5 of Howe et al. (2018)\") %>%   kable_paper(full_width = FALSE) %>%   row_spec(1, bold=TRUE,  background = \"#4da6ff\")"},{"path":"/articles/web-only/CTDS/camera-distill.html","id":"sensibility-check-for-detection-parameter-estimates","dir":"Articles > Web-only > CTDS","previous_headings":"Detection data analysis","what":"Sensibility check for detection parameter estimates","title":"Analysis of camera trapping data","text":"check detection function vis--vis Howe et al. (2017), paper reports effective detection radius (\\(\\rho\\)) 9.4m peak activity data set. Howe et al. (2017) employed different candidate model set, resulting unadjusted hazard rate model preferred model. present estimated effective detection radius selected uniform key function three cosine adjustment terms. effective detection radius can derived \\(\\hat{P_a}\\) reported function ds \\[\\hat{\\rho} = \\sqrt{\\hat{P_a} \\cdot w^2}\\] \\(\\hat{P_a}\\) estimated 0.329, resulting estimate \\(\\hat{\\rho}\\) 7.457.","code":"p_a <- uni3$ddf$fitted[1] w <- range(mybreaks)[2] - range(mybreaks)[1] rho <- sqrt(p_a * w^2)"},{"path":"/articles/web-only/CTDS/camera-distill.html","id":"selected-detection-function","dir":"Articles > Web-only > CTDS","previous_headings":"Detection data analysis","what":"Selected detection function","title":"Analysis of camera trapping data","text":"Figure 3 shows detection function probability density function selected model. Figure 3: Detection function probability density function selected detection function model.","code":"plot(uni3, main=\"Daytime activity\", xlab=\"Distance (m)\",      showpoints=FALSE, lwd=3, xlim=c(0, 15)) plot(uni3, main=\"Daytime activity\", xlab=\"Distance (m)\", pdf=TRUE,      showpoints=FALSE, lwd=3, xlim=c(0, 15))"},{"path":"/articles/web-only/CTDS/camera-distill.html","id":"density-estimates","dir":"Articles > Web-only > CTDS","previous_headings":"Detection data analysis","what":"Density estimates","title":"Analysis of camera trapping data","text":"camera traps view entire area around , case simple point transect sampling. portion area sampled needs incorporated estimation abundance. data file contains column multiplier represents proportion circle sampled. Howe et al. (2017) notes camera angle view (AOV) 42\\(^{\\circ}\\). proportion circle viewed value 360\\(^{\\circ}\\). argument dht2 sample_fraction, obvious place include quantity. also add multiplier temporal availability described section temporal availability dht2 function produce analytical measures precision call.","code":"viewangle <- 42 # degrees samfrac <- viewangle / 360 peak.uni.dens <- dht2(uni3, flatfile=DuikerCameraTraps, strat_formula = ~1,                      sample_fraction = samfrac, er_est = \"P2\", multipliers = avail,                      convert_units = conversion) print(peak.uni.dens, report=\"density\") ## Density estimates from distance sampling ## Stratification : geographical  ## Variance       : P2, n/L  ## Multipliers    : creation  ## Sample fraction : 0.1166667  ##  ##  ## Summary statistics: ##  .Label  Area CoveredArea   Effort     n  k ER se.ER cv.ER ##   Total 40.37    2596.317 31483179 10284 21  0     0 0.268 ##  ## Density estimates: ##  .Label Estimate    se    cv    LCI     UCI     df ##   Total  17.2357 4.801 0.279 9.7947 30.3297 23.239 ##  ## Component percentages of variance: ##  .Label Detection    ER Multipliers ##   Total      2.17 92.77        5.06"},{"path":"/articles/web-only/CTDS/camera-distill.html","id":"bootstrap-for-variance-estimation","dir":"Articles > Web-only > CTDS","previous_headings":"","what":"Bootstrap for variance estimation","title":"Analysis of camera trapping data","text":"produce reliable estimate precision point estimate, produce bootstrap estimates using bootdht. user needs create function another named list facilitate use bootstrap: summary function extract information replicate multiplier list describing temporal availability derived.","code":""},{"path":"/articles/web-only/CTDS/camera-distill.html","id":"summary-function","dir":"Articles > Web-only > CTDS","previous_headings":"Bootstrap for variance estimation","what":"Summary function","title":"Analysis of camera trapping data","text":"constructed, mysummary keep density estimate produced bootstrap replicate stratum () estimate pertains.","code":"mysummary <- function(ests, fit){   return(data.frame(Label = ests$individuals$D$Label,                     Dhat = ests$individuals$D$Estimate)) }"},{"path":"/articles/web-only/CTDS/camera-distill.html","id":"multiplier-function","dir":"Articles > Web-only > CTDS","previous_headings":"Bootstrap for variance estimation","what":"Multiplier function","title":"Analysis of camera trapping data","text":"rather complex list makes use make_activity_fn exists Distance package used call fitact function activity package. user, responsibility provide three arguments function: vector containing detection times radians (computed earlier section), manner precision temporal availability estimate produced number hours per day cameras operation","code":"mult <- list(availability= make_activity_fn(trigger.events$rtime, sample=\"data\",                                             detector_daily_duration=camera.operation.per.day))"},{"path":"/articles/web-only/CTDS/camera-distill.html","id":"speeding-up-the-bootstrap","dir":"Articles > Web-only > CTDS","previous_headings":"Bootstrap for variance estimation","what":"Speeding up the bootstrap","title":"Analysis of camera trapping data","text":"’ve tried running example code R might noticed detection function fitting quite slow. general, camera traps produce large amount distance sampling data, addition data tend “overdispersed” meaning (case) lots observations distances. Together, can cause analyses run slowly, can especially true bootstrap analyses variance estimation. One way speed bootstrap run multiple analyses parallel, using multiple cores computer. can achieve using cores argument bootdht - fastest results set number cores machine minus 1 (best leave 1 free things). can find number cores calling parallel::detectCores() code . second, available Microsoft Windows users, use alternative optimization engine MCDS.exe fit detection functions. find , see online example Alternative optimization engine. using Windows machine, can download MCDS.exe required directory executing following lines (note, need , although future update Distance package ’ll need re-download ): make use engine re-fitting selected detection function model, uni3, using engine, setting ds argument optimizer=\"MCDS\". using Windows machine doanloaded MCDS.exe engine, execute line, bootstrap take longer execute.","code":"download.file(\"http://distancesampling.org/R/MCDS.exe\",                paste0(system.file(package=\"mrds\"),\"/MCDS.exe\"), mode = \"wb\") #Detach and reload the Distance package to make use of it detach(\"package:Distance\", unload = TRUE) library(Distance) uni3 <- ds(DuikerCameraTraps, transect = \"point\", key=\"unif\", adjustment = \"cos\",            nadj=3, convert_units = conversion,            cutpoints = mybreaks, truncation = trunc.list,            optimizer = \"MCDS\") ## Warning in create_bins(data, cutpoints): Some distances were outside bins and ## have been removed."},{"path":"/articles/web-only/CTDS/camera-distill.html","id":"remaining-arguments-to-bootdht","dir":"Articles > Web-only > CTDS","previous_headings":"Bootstrap for variance estimation","what":"Remaining arguments to bootdht","title":"Analysis of camera trapping data","text":"Just dht2 arguments model, flatfile, sample_fraction, convert.units multipliers (although bootdht multipliers uses function rather single value). novel arguments dht2 resample_transects indicating camera stations resampled replacement, nboot number bootstrap replicates.","code":"n.cores <- parallel::detectCores() daytime.boot.uni <- bootdht(model=uni3, flatfile=DuikerCameraTraps,                           resample_transects = TRUE, nboot=500,                            cores = n.cores - 1,                           summary_fun=mysummary, sample_fraction = samfrac,                           convert_units = conversion, multipliers=mult)"},{"path":"/articles/web-only/CTDS/camera-distill.html","id":"confidence-limits-computed-via-the-percentile-method-of-the-bootstrap-","dir":"Articles > Web-only > CTDS","previous_headings":"Bootstrap for variance estimation","what":"Confidence limits computed via the percentile method of the bootstrap.","title":"Analysis of camera trapping data","text":"Figure 4: Distribution density estimates bootstrap replicates. confidence interval derived bootstrap considerably wider confidence interval derived analytical methods (Figure 4).","code":"print(summary(daytime.boot.uni)) ## Bootstrap results ##  ## Boostraps          : 500  ## Successes          : 499  ## Failures           : 1  ##  ##      median  mean   se  lcl   ucl  cv ## Dhat  18.29 19.21 7.36 8.22 36.49 0.4 hist(daytime.boot.uni$Dhat, breaks = 20,       xlab=\"Estimated density\", main=\"D-hat estimates bootstraps\") abline(v=quantile(daytime.boot.uni$Dhat, probs = c(0.025,0.975), na.rm=TRUE), lwd=2, lty=3)"},{"path":"/articles/web-only/CTDS/camera-distill.html","id":"an-esoteric-note-on-starting-values-and-bootstrapping","dir":"Articles > Web-only > CTDS","previous_headings":"Bootstrap for variance estimation","what":"An esoteric note on starting values and bootstrapping","title":"Analysis of camera trapping data","text":"Feel free skip unless ’re fairly advanced user! cases, may necessary set starting values detection function optimization, help converge. can achieved using initial_values arguemnt ds function. example, say want use fitted values uniform + 2 cosine function uni2 starting values first two parameters uniform + 3 cosine function fitting (0 third parameter). following code : comes bootstrapping variance esitmation. can pass model boot.dht problems, long don’t set ncores 1. set ncores 1 won’t work, returning 0 successful bootstraps. ? uni2$ddf$par passed along parallel cores. fix hard-code starting values. , example, see values use work fine bootdht. final tip setting starting values can sometimes speed bootstrap (optimization faster starts good initial spot), might want pass starting values uni3 bootstrap routine - something like following, using MCDS optimizer: (Note - code set run examples file - just show might use).","code":"uni3.with.startvals <- ds(DuikerCameraTraps, transect = \"point\", key=\"unif\", adjustment = \"cos\",            nadj=3,            cutpoints = mybreaks, truncation = trunc.list,             initial_values = list(adjustment = c(as.numeric(uni2$ddf$par), 0))) ## Warning in create_bins(data, cutpoints): Some distances were outside bins and ## have been removed. print(uni2$ddf$par) ## [1] 0.97178178 0.03541633 uni3.with.startvals <- ds(DuikerCameraTraps, transect = \"point\", key=\"unif\", adjustment = \"cos\",            nadj=3,            cutpoints = mybreaks, truncation = trunc.list,             initial_values = list(adjustment = c(0.97178178, 0.03541633, 0))) ## Warning in create_bins(data, cutpoints): Some distances were outside bins and ## have been removed. print(uni3$ddf$par) uni3.with.startvals <- ds(DuikerCameraTraps, transect = \"point\", key=\"unif\", adjustment = \"cos\",            nadj=3,            cutpoints = mybreaks, truncation = trunc.list,             optimizer = \"MCDS\",            initial_values = list(adjustment = c(0.93518220, -0.05345965, -0.08073799))) daytime.boot.uni <- bootdht(model=uni3.with.startvals, flatfile=DuikerCameraTraps,                           resample_transects = TRUE, nboot=500,                            cores = n.cores - 1,                           summary_fun=mysummary, sample_fraction = samfrac,                           convert_units = conversion, multipliers=mult)"},{"path":[]},{"path":"/articles/web-only/cues/cuecounts-distill.html","id":"objectives","dir":"Articles > Web-only > Cues","previous_headings":"","what":"Objectives","title":"Analysis of cue count surveys","text":"Estimate density cues point transect data Convert cue density animal density using rate song production","code":""},{"path":"/articles/web-only/cues/cuecounts-distill.html","id":"survey-design","dir":"Articles > Web-only > Cues","previous_headings":"","what":"Survey design","title":"Analysis of cue count surveys","text":"32 point count stations visited twice. visit, observer recorded distances songs detected 5-minute sampling period (Figure 1). Figure 1: Montrave study area; white circles point count stations. addition, 43 male winter wrens observed rate song production measured. mean cue rate, along standard error (individuals) calculated included data set serve multiplier. fields wren_cuecount data set : Region.Label - identifier regions: case one region set ‘Montrave’ Area - size study region (hectares): 33.2ha Sample.Label - point transect identifier (numbered 1-32) Cue.rate - production cues (per minute) Cue.rate.SE - standard error cue production rate (individuals) object - unique identifier detected winter wren distance - radial distance (metres) detection Search.time - Duration listening station (minutes) Study.Area - name study, ‘Montrave 3’","code":""},{"path":"/articles/web-only/cues/cuecounts-distill.html","id":"accessing-the-distance-package-and-cue-count-data","dir":"Articles > Web-only > Cues","previous_headings":"","what":"Accessing the Distance package and cue count data","title":"Analysis of cue count surveys","text":"command assumes dsdata package installed computer. R workspace wren_cuecount contains detections winter wrens line transect surveys Buckland (2006). Examine first rows wren_cuecount using function head() Note field data indicate sampling effort. line transects, lengths transect provided measure effort. point transects, number visits station specified. data set, specified Search.time length time station sampled. Note, station visited twice sampling 5 minutes length visit. Hence Search.time recorded 10. Note also units measure Search.time must consistent units measure cue rate.","code":"library(Distance) data(wren_cuecount) head(wren_cuecount) ##   Region.Label Area Sample.Label Cue.rate Cue.rate.SE object distance ## 1     Montrave 33.2            1   1.4558      0.2428     38       50 ## 2     Montrave 33.2            1   1.4558      0.2428     39       55 ## 3     Montrave 33.2            1   1.4558      0.2428     40       55 ## 4     Montrave 33.2            1   1.4558      0.2428     41       55 ## 5     Montrave 33.2            1   1.4558      0.2428     46       50 ## 6     Montrave 33.2            1   1.4558      0.2428     47       50 ##   Study.Area Search.time ## 1 montrave 3          10 ## 2 montrave 3          10 ## 3 montrave 3          10 ## 4 montrave 3          10 ## 5 montrave 3          10 ## 6 montrave 3          10"},{"path":"/articles/web-only/cues/cuecounts-distill.html","id":"examine-the-distribution-of-detection-distances","dir":"Articles > Web-only > Cues","previous_headings":"","what":"Examine the distribution of detection distances","title":"Analysis of cue count surveys","text":"Gain familiarity perpendicular distance data using hist() function (Figure 2). Figure 2: Radial detection distances winter wren song bursts. Note long right tail cut truncation argument ds().","code":"hist(wren_cuecount$distance, xlab=\"Distance (m)\", main=\"Song detection distances\")"},{"path":"/articles/web-only/cues/cuecounts-distill.html","id":"fitting-a-simple-detection-function-model-with-ds","dir":"Articles > Web-only > Cues","previous_headings":"","what":"Fitting a simple detection function model with ds","title":"Analysis of cue count surveys","text":"noted , Effort missing data. cue count surveys, effort measured time rather length number visits. Therefore define new field Effort set equal Search.time field. Note: converstion.factor specified call ds() detection function interest step analysis, nothing density abundance. Visually inspect fitted detection function plot() function, specifying cutpoints histogram argument breaks (Figure 3). Figure 3: Fit hazard rate detection function winter wren song detection distances.","code":"conversion.factor <- convert_units(\"meter\", NULL, \"hectare\") wren_cuecount$Effort <- wren_cuecount$Search.time wrensong.hr <- ds(wren_cuecount, transect=\"point\", key=\"hr\", adjustment=NULL,                    truncation=100) cutpoints <- c(0,5,10,15,20,30,40,50,65,80,100) plot(wrensong.hr, breaks=cutpoints, pdf=TRUE, main=\"Hazard rate function fit to winter wren song counts.\")"},{"path":"/articles/web-only/cues/cuecounts-distill.html","id":"caution","dir":"Articles > Web-only > Cues","previous_headings":"Fitting a simple detection function model with ds","what":"Caution","title":"Analysis of cue count surveys","text":"examine abundance density estimates produced summary(wrensong.hr) results contains nonsense. summary values properly recognise unit effort time rather visits point count survey. additional component analysis provided next step.","code":""},{"path":"/articles/web-only/cues/cuecounts-distill.html","id":"introducing-a-new-function-dht2","dir":"Articles > Web-only > Cues","previous_headings":"","what":"Introducing a new function dht2","title":"Analysis of cue count surveys","text":"function dht2 provides additional capacity providing density abundance estimates novel situations cue counts multipliers need incorporated. argument multipliers dht2 provides mechanism whereby cue production rate uncertainty incorporated analysis. properly perform calculations responsible converting song density bird density, enlist aide function dht2. additional information cue rates variability provided list. multiplier list required name creation contains cue rate point estimate associated measure precision. Additional arguments also passed dht2. flatfile name data set strat_formula contains information stratification might exist survey design. Montrave study stratification, inference 33 hectare woodland, strat_formula simply constant ~1. Results overall winter wren density estimate provided print method, specifying report=\"density\". alternative report argument report=\"abundance\".","code":"cuerate <- unique(wren_cuecount[ , c(\"Cue.rate\",\"Cue.rate.SE\")]) names(cuerate) <- c(\"rate\", \"SE\") (mult <- list(creation=cuerate)) ## $creation ##     rate     SE ## 1 1.4558 0.2428 wren.estimate <- dht2(wrensong.hr, flatfile=wren_cuecount, strat_formula=~1,                  multipliers=mult, convert_units=conversion.factor) print(wren.estimate, report=\"density\") ## Density estimates from distance sampling ## Stratification : geographical  ## Variance       : P2, n/L  ## Multipliers    : creation  ## Sample fraction : 1  ##  ##  ## Summary statistics: ##  .Label Area CoveredArea Effort   n  k    ER se.ER cv.ER ##   Total 33.2     1005.31    320 771 32 2.409 0.236 0.098 ##  ## Density estimates: ##  .Label Estimate    se    cv    LCI    UCI      df ##   Total   1.2018 0.238 0.198 0.8172 1.7674 520.679 ##  ## Component percentages of variance: ##  .Label Detection    ER Multipliers ##   Total      4.83 24.38       70.79"},{"path":"/articles/web-only/cues/cuecounts-distill.html","id":"absolute-goodness-of-fit","dir":"Articles > Web-only > Cues","previous_headings":"Introducing a new function dht2","what":"Absolute goodness of fit","title":"Analysis of cue count surveys","text":"assess goodness fit hazard rate model winter wren cue count data (Figure 4). Figure 4: Q-Q plot hazard rate model winter wren radial detection distances. Note distinct lack fit song data. many detections identical distances birds stationary singing. induces phenomenon known dispersion.","code":"gof_ds(wrensong.hr) ##  ## Goodness of fit results for ddf object ##  ## Distance sampling Cramer-von Mises test (unweighted) ## Test statistic = 1.69439 p-value = 6.24759e-05"},{"path":"/articles/web-only/cues/cuecounts-distill.html","id":"notes-regarding-the-cue-count-estimates-of-montrave-winter-wrens","dir":"Articles > Web-only > Cues","previous_headings":"","what":"Notes regarding the cue count estimates of Montrave winter wrens","title":"Analysis of cue count surveys","text":"vignette uses function dht2 function knows incorporate multipliers cue rates propogate uncertainty cue rate overall uncertainty density abundance. uncertainty coming encounter rate variability uncertainty detection function parameters, also cue rate variability, relative contribution source uncertainty tablated. last table produced printing wren.estimate object. Montrave winter wren data, 4% uncertainty density estimate attributable detection function, 24% attributable encounter rate variability 71% attributable -individual variability call rate. insight suggests survey repeated, exerting effort measuring -individual variation call rate likely yield benefits tightening precision density estimates. Also note poor fit model data; P-value Cramer von-Mises test <<0.05. caused -dispersion distribution detected call distances. single individual may sit tree branch emit many song bursts, leading jagged distribution call distances well fitted smooth detection function. -dispersion bias density estimates.","code":""},{"path":[]},{"path":[]},{"path":"/articles/web-only/groupsize/Remedy-size-bias-for-dolphin-surveys.html","id":"exploratory-data-analysis","dir":"Articles > Web-only > Groupsize","previous_headings":"","what":"Exploratory data analysis","title":"Solving the size bias problem","text":"described, number potential covariates might influence dolphin detectability. Rather throw covariates detection function models, examine distribution detection distances (y-axis figure ) function plausible factor covariates. Figure 1: Exploratory data analysis using violin plots. Prepared using vioplot package. Number detections show plots. Fig. 1 several decisions made concerning remaining analysis: discernible effect month sea state upon distribution detection distances data set. covariates feature subsequent modelling. distribution detection distances cue type appears differ splashes floating objects. However, number detections associated splash (n=25) float objects (n=22) cues small, accounting ~4% total number detections. choose ignore variability detection probability associated cue type. proper way handle situation remove helicopter sightings detection function modelling. Detectability assumed perfect truncation distance, hence treat helicopter portion survey strip transect. number pods detected helicopters added estimated number pods within covered area. remove detections helicopter remainder analysis. number detections radar small unlikely exert much influence upon detection function modelling.","code":""},{"path":"/articles/web-only/groupsize/Remedy-size-bias-for-dolphin-surveys.html","id":"evidence-for-size-bias","dir":"Articles > Web-only > Groupsize","previous_headings":"Exploratory data analysis","what":"Evidence for size bias","title":"Solving the size bias problem","text":"Size bias (Buckland et al., 2001) can examined plotting distribution group size function detection distances. Figure 2: Box plot observed group sizes perpendicular distance band. Outliers shown; notches indicate discernable difference mean group size 2nm. Fig. 2 indicates difference observed mean group size 2nm; average group size distinctly larger distances greater 2nm. Hence, average group size sample overestimate average group size population. modelling detection function need counteract bias including group size detection function.","code":""},{"path":"/articles/web-only/groupsize/Remedy-size-bias-for-dolphin-surveys.html","id":"stage-one-of-detection-function-modelling","dir":"Articles > Web-only > Groupsize","previous_headings":"","what":"Stage one of detection function modelling","title":"Solving the size bias problem","text":"creating host candidate models, address question appropriate key function data. Recall including sightings made helicopter platform analyses. Fitting models half normal key function without adjustments without Search.method Figure 3: Q-Q goodness fit plots half normal key function without adjustments also including search method covariate. indicates lack fit half normal key function models. rounding trackline, detection function maintains shoulder falling away quite rapidly. Even taking consideration idea sample size large (n=961), making goodness fit test quite powerful, doubt half normal key function appropriate data. remove half normal modelling, hazard rate serve purposes, hazard rate without adjustments covariates, adequately fit data.","code":"hn <- ds(nochopper, key=\"hn\", adjustment = NULL) hn.method <- ds(nochopper, key=\"hn\", formula = ~factor(Search.method)) par(mfrow=c(1,2)) gof_ds(hn, main=\"HN key, no adj\", cex=0.5) ##  ## Goodness of fit results for ddf object ##  ## Distance sampling Cramer-von Mises test (unweighted) ## Test statistic = 0.656421 p-value = 0.0162635 gof_ds(hn.method, main=\"HN key + method\", cex=0.5) ##  ## Goodness of fit results for ddf object ##  ## Distance sampling Cramer-von Mises test (unweighted) ## Test statistic = 0.672219 p-value = 0.0148816 par(mfrow=c(1,2)) hr <- ds(nochopper, key=\"hr\") ## Starting AIC adjustment term selection. ## Fitting hazard-rate key function ## AIC= 2920.797 ## Fitting hazard-rate key function with cosine(2) adjustments ## AIC= 2922.8 ##  ## Hazard-rate key function selected. gof_ds(hr, plot=FALSE) ##  ## Goodness of fit results for ddf object ##  ## Distance sampling Cramer-von Mises test (unweighted) ## Test statistic = 0.130299 p-value = 0.455606"},{"path":"/articles/web-only/groupsize/Remedy-size-bias-for-dolphin-surveys.html","id":"counteracting-size-bias","dir":"Articles > Web-only > Groupsize","previous_headings":"Stage one of detection function modelling","what":"Counteracting size bias","title":"Solving the size bias problem","text":"Conducting modeling using hazard rate key function, turn attention incorporating group size detection function. way counteract effect size bias include group size detection function. disappointment learn model including group size covariate fails converge. numerical difficulties associated covariate spans three orders magnitude. fitting issues covariates, consult covariate example amakihi. distribution group sizes strongly skewed right, long right tail. transformation natural logs reduce range log(size) one order magnitude shift centre distribution covariate (Fig. 4). Figure 4: Effect log transformation upon distribution observed group sizes. convergence problems associated using size covariate detection function alleviated result transformation. successfully incorporated group size detection function, proceed examine consequence using Search.method covariate model incorporating covariates. Table 7: Table 8: Models hazard rate key function fitted tuna fishing vessel sightings dolphins. Sightings helicopter included modelling.","code":"hr.size <- ds(nochopper, key=\"hr\", formula = ~size) ## Model contains covariate term(s): no adjustment terms will be included. ## Fitting hazard-rate key function ## AIC= 2919.357 hr.clus <- ds(nochopper, key=\"hr\", formula = ~log(size)) ## Model contains covariate term(s): no adjustment terms will be included. ## Fitting hazard-rate key function ## AIC= 2904.307 hr.method <- ds(nochopper, key=\"hr\", formula = ~factor(Search.method)) hr.clus.method <- ds(nochopper, key=\"hr\", formula = ~log(size) + factor(Search.method))"},{"path":"/articles/web-only/groupsize/Remedy-size-bias-for-dolphin-surveys.html","id":"interpretation-of-findings","dir":"Articles > Web-only > Groupsize","previous_headings":"","what":"Interpretation of findings","title":"Solving the size bias problem","text":"fitted models using hazard rate key function fit data. addition, note estimates \\(\\widehat{P_a}\\) four models. Inclusion covariates negligible effect upon estimated detection probability. Despite \\(\\Delta\\)AIC value > 15, model without covariates produces virtually identical estimate detection probability. another example remarkable property pooling robustness distance sampling estimators (Burnham et al., 2004). discuss estimates group individual density data set. However, data set accurately reflect survey effort. Effort column filled 1 single transect labelled data. Hence, density estimates reflect biological reality; nevertheless comparisons models legitimate. Variability transects also properly incorporated analysis, won’t present measures precision associated following point estimates. slight variation \\(\\widehat{P_a}\\) among hazard rate candidate models reflected equally similar estimates dolphin pod density among competing models. model largest \\(\\widehat{P_a}\\) produces lowest estimate \\(\\widehat{D_s}\\) (170.5); model smallest \\(\\widehat{P_a}\\) produces largest estimate \\(\\widehat{D_s}\\) (175.8). However, important consideration analysis data set proper treatment size bias. hazard rate models without group size detection function, estimate average group size population 515 whereas model incorporating group size detection function estimates average group size population 408. Based evidence presented Fig. 2, reason believe estimates average group size without incorporating group size detection function results positively biased estimate group size population. group size estimates two models, appears magnitude positive size bias data set 26.2. difference estimated average group size magnified estimates individual density \\(\\widehat{D_I}\\). model without covariates estimates \\(\\widehat{D_I}\\) = 87805 model group size covariate estimates \\(\\widehat{D_I}\\) 71150.","code":""},{"path":"/articles/web-only/groupsize/Remedy-size-bias-for-dolphin-surveys.html","id":"summary","dir":"Articles > Web-only > Groupsize","previous_headings":"","what":"Summary","title":"Solving the size bias problem","text":"Take home points: incorporating covariates detection function, thorough exploratory data analysis lots plots. Make least preliminary decision regarding key functions consider building extensive candidate model set. data set, little difference fit detection functions inclusion covariates (pooling robustness). However, exploratory data analysis suggested small dolphin groups missed large distances, resulting size bias estimate average group size population. Incorporating group size covariate detection function reduced estimate group size population 26.2%. reduction estimated group size compensated size bias induced detection process.","code":""},{"path":[]},{"path":"/articles/web-only/multipliers/multipliers-distill.html","id":"objectives","dir":"Articles > Web-only > Multipliers","previous_headings":"","what":"Objectives","title":"Multipliers and indirect surveys","text":"objectives exercise Fit detection functions cues Obtain relevant multipliers Use multipliers dht2 function obtain animal abundances.","code":""},{"path":"/articles/web-only/multipliers/multipliers-distill.html","id":"dung-survey-of-deer","dir":"Articles > Web-only > Multipliers","previous_headings":"","what":"Dung survey of deer","title":"Multipliers and indirect surveys","text":"question estimate density sika deer number woodlands Scottish Borders (Marques et al., 2001). animals shy aware presence observer observer detects , making surveys species challenging. consequence, indirect estimation methods applied problem. manner, estimate density produced sign generated deer (case, faecal dung pellets) estimate transformed density deer (\\(D_{\\textrm{deer}}\\)) \\[ \\hat D_{\\textrm{deer}} = \\frac{\\textrm{dung deposited daily}}{\\textrm{dung production rate (per animal)}} \\] dung deposited daily given \\[ \\textrm{dung deposited daily} = \\frac{\\hat D_{\\textrm{pellet groups}}}{\\textrm{mean time decay}} \\] Hence, use distance sampling produce pellet group density estimate, adjust accordingly account production decay processes operating time data acquired. also take uncertainty dung production decay rates account final estimate deer density. Data 9 woodlands (labelled -H J) collected according survey design (Figure 1) note data block D included exercise. Figure 1: Location sika deer survey southern Scotland survey design ((Marques et al., 2001)). Note differing amounts effort different woodlands based information derived pilot surveys. addition data, also require estimates production rate. literature search, learn sika deer produce 25 pellet groups daily source provide measure variability estimate. course surveys also followed fate marked pellet groups estimate decay (disappearance) rates pellet group. thorough discussion methods useful estimating decay rates associated measures precision can found Laing et al. (2003). many factors might influence production decay rates, purposes exercise make simplifying assumption decay rate homogeneous across woodlands; mean time decay 163 days standard error 13 days. (conduct survey , want investigate assumption thoroughly.)","code":""},{"path":"/articles/web-only/multipliers/multipliers-distill.html","id":"getting-started","dir":"Articles > Web-only > Multipliers","previous_headings":"Dung survey of deer","what":"Getting started","title":"Multipliers and indirect surveys","text":"data (called sikadeer) available Distance package. Detection deer dung takes place small spatial scales; perpendicular distances measured centimeters. transects long; measured kilometers deer densities customarily reported numbers kilometer-2.","code":"library(Distance) data(sikadeer) conversion.factor <- convert_units(\"centimeter\", \"kilometer\", \"square kilometer\")"},{"path":"/articles/web-only/multipliers/multipliers-distill.html","id":"fit-detection-function-to-dung-pellets","dir":"Articles > Web-only > Multipliers","previous_headings":"Dung survey of deer","what":"Fit detection function to dung pellets","title":"Multipliers and indirect surveys","text":"Fit usual series models (.e. half normal, hazard rate, uniform) models distances pellet groups decide detection function. detection function (Figure 2) used obtain \\(\\hat D_{\\textrm{pellet groups}}\\). Figure 2: Simple detection function deer pellet line transect data. look Summary statistics model - note woodlands single transect effort allocated.","code":"deer.df <- ds(sikadeer, key=\"hn\", truncation=\"10%\", convert_units = conversion.factor) plot(deer.df, main=\"Half normal detection function\") print(deer.df$dht$individuals$summary) ##   Region Area CoveredArea Effort    n  k        ER      se.ER     cv.ER ## 1      A 13.9    0.005950   1.70 1217 13 715.88234 119.918872 0.1675120 ## 2      B 10.3    0.003850   1.10  396 10 359.99999  86.859289 0.2412758 ## 3      C  8.6    0.001575   0.45   17  3  37.77778   8.521202 0.2255612 ## 4      E  8.0    0.002975   0.85   30  5  35.29412  16.568939 0.4694533 ## 5      F 14.0    0.000700   0.20   29  1 145.00000   0.000000 0.0000000 ## 6      G 15.2    0.001400   0.40   32  3  80.00000  39.686269 0.4960784 ## 7      H 11.3    0.000700   0.20    3  1  15.00000   0.000000 0.0000000 ## 8      J  9.6    0.000350   0.10    7  1  70.00000   0.000000 0.0000000 ## 9  Total 90.9    0.017500   5.00 1731 37 201.90876   0.000000 0.0000000"},{"path":"/articles/web-only/multipliers/multipliers-distill.html","id":"multipliers","dir":"Articles > Web-only > Multipliers","previous_headings":"Dung survey of deer","what":"Multipliers","title":"Multipliers and indirect surveys","text":"next step create object contains multipliers wish use. already estimates dung production rates need similar information dung decay (persistence) rate. Analysis based upon methods presented Laing et al. (2003). Data calculate dung persistence collected file dung_persistence.csv. Following code (Meredith, 2017). Figure 3: Logistic curve fitted pellet persistence survey data. Vertical line represents day 50% pellets decayed non-detectable. Running command produced plot dung persistence versus days since produced fitted logistic regression (like simple linear regression restricts response taking values 0 1). Note points can reality take values 0 1 purposes plotting ‘jittered’ avoid -plotting. estimate mean persistence time measure variability also provided - make note required . Dotted vertical line indicates time estimated probability persistence 0.5. stated , want object contains information dung production rate (standard error) dung decay rate (standard error). following command creates list containing two data frames: creation contains estimates dung production rate associated standard error decay contains dung decay rate associated standard error XX YY estimates obtained dung decay rate analysis. final step use multipliers convert \\(\\hat D_{\\textrm{pellet groups}}\\) \\(\\hat D_{\\textrm{deer}}\\) (equations ) - need employ dht2 function. command multipliers= argument allows us specify rates standard errors. couple function arguments need explanation: strat_formula=~Region.Label specified take account design (.e. different woodlands blocks). stratification=\"geographical\" specified want produce overall estimate density mean woodland specific densities weighted area block. deer.df detection function fitted.","code":"MIKE.persistence <- function(DATA) {    #  Purpose: calculate mean persistence time (mean time to decay) for dung/nest data  #  Input: data frame with at least two columns: #         DAYS - calendar day on which dung status was observed #         STATE - dung status: 1-intact, 0-decayed #  Output: point estimate, standard error and CV of mean persistence time # #  Attribution: code from Mike Meredith website:  #      http://www.mikemeredith.net/blog/2017/Sign_persistence.htm #   Citing: CITES elephant protocol #      https://cites.org/sites/default/files/common/prog/mike/survey/dung_standards.pdf      ##   Fit logistic regression model to STATE on DAYS, extract coefficients   dung.glm <- glm(STATE ~ DAYS, data=DATA, family=binomial(link = \"logit\"))   betas <- coefficients(dung.glm)   ##   Calculate mean persistence time   mean.decay <- -(1+exp(-betas[1])) * log(1+exp(betas[1])) / betas[2]   ## Calculate the variance of the estimate   vcovar <- vcov(dung.glm)   var0 <- vcovar[1,1]  # variance of beta0   var1 <- vcovar[2,2]  # variance of beta1   covar <- vcovar[2,1] # covariance   deriv0 <- -(1-exp(-betas[1]) * log(1+exp(betas[1])))/betas[2]   deriv1 <- -mean.decay/betas[2]   var.mean <- var0*deriv0^2 + 2*covar*deriv0*deriv1 + var1*deriv1^2   ## Calculate the SE and CV and return   se.mean <- sqrt(var.mean)   cv.mean <- se.mean/mean.decay   out <- c(mean.decay, se.mean, 100*cv.mean)   names(out) <- c(\"Mean persistence time\", \"SE\", \"%CV\")   plot(decay$DAYS, jitter(decay$STATE, amount=0.10), xlab=\"Days since initiation\",        ylab=\"Dung persists (yes=1)\",        main=\"Eight dung piles revisited over time\")   curve(predict(dung.glm, data.frame(DAYS=x), type=\"resp\"), add=TRUE)   abline(v=mean.decay, lwd=2, lty=3)   return(out) } decay <- read.csv(\"dung_persistence.csv\") persistence.time <- MIKE.persistence(decay) print(persistence.time) ## Mean persistence time                    SE                   %CV  ##            163.396748             14.226998              8.707026 # Create list of multipliers mult <- list(creation = data.frame(rate=25, SE=0),              decay    = data.frame(rate=163, SE=14.2)) print(mult) ## $creation ##   rate SE ## 1   25  0 ##  ## $decay ##   rate   SE ## 1  163 14.2 deer.ests <- dht2(deer.df, flatfile=sikadeer, strat_formula=~Region.Label,                  convert_units=conversion.factor, multipliers=mult,                   stratification=\"geographical\") ## Warning in dht2(deer.df, flatfile = sikadeer, strat_formula = ~Region.Label, : ## One or more strata have only one transect, cannot calculate empirical encounter ## rate variance print(deer.ests, report=\"density\") ## Density estimates from distance sampling ## Stratification : geographical  ## Variance       : R2, n/L  ## Multipliers    : creation, decay  ## Sample fraction : 1  ##  ##  ## Summary statistics: ##  Region.Label Area CoveredArea Effort    n  k      ER   se.ER cv.ER ##             A 13.9    0.005950   1.70 1217 13 715.882 119.919 0.168 ##             B 10.3    0.003850   1.10  396 10 360.000  86.859 0.241 ##             C  8.6    0.001575   0.45   17  3  37.778   8.521 0.226 ##             E  8.0    0.002975   0.85   30  5  35.294  16.569 0.469 ##             F 14.0    0.000700   0.20   29  1 145.000   0.000 0.000 ##             G 15.2    0.001400   0.40   32  3  80.000  39.686 0.496 ##             H 11.3    0.000700   0.20    3  1  15.000   0.000 0.000 ##             J  9.6    0.000350   0.10    7  1  70.000   0.000 0.000 ##         Total 90.9    0.017500   5.00 1731 37 346.200  68.158 0.197 ##  ## Density estimates: ##  Region.Label Estimate     se    cv     LCI      UCI        df ##             A  73.9165 14.248 0.193 49.6888 109.9573    21.037 ##             B  37.1708  9.643 0.259 21.3190  64.8091    12.031 ##             C   3.9006  0.955 0.245  1.7460   8.7141     2.779 ##             E   3.6442  1.746 0.479  1.0713  12.3958     4.337 ##             F  14.9716  1.428 0.095 12.4246  18.0407 63232.099 ##             G   8.2602  4.173 0.505  1.2114  56.3217     2.151 ##             H   1.5488  0.148 0.095  1.2853   1.8663 63232.099 ##             J   7.2277  0.689 0.095  5.9981   8.7093 63232.099 ##         Total  20.8475  3.011 0.144 15.5122  28.0179    25.610 ##  ## Component percentages of variance: ##  Region.Label Detection    ER Multipliers ##             A      4.05 75.53       20.43 ##             B      2.23 86.49       11.28 ##             C      2.51 84.84       12.65 ##             E      0.66 96.04        3.31 ##             F     16.54  0.00       83.46 ##             G      0.59 96.44        2.97 ##             H     16.54  0.00       83.46 ##             J     16.54  0.00       83.46 ##         Total      3.73 96.27        0.00"},{"path":"/articles/web-only/multipliers/multipliers-distill.html","id":"other-stratification-choices-with-dht2","dir":"Articles > Web-only > Multipliers","previous_headings":"","what":"Other stratification choices with dht2","title":"Multipliers and indirect surveys","text":"example Sika deer different hunting estates uses geographical stratification. also option using option replicate stratification argument. useful repeated surveys geographic area; average abundance computed variance variability surveys. Alternatively effort_sum used replicate surveys, replicates reporting average variance. Finally, specification stratification=\"object\" can used detections made different species, sexes ages animals. option produce species-specific abundance estimates well abundance estimate species, properly calculating variance total abundance. information available diagramatic comparison well help file ?dht2. function dht2 also provides information components variance. Make note (contribution detection function, encounter rate, decay rate happened production rate component?) strata.","code":""},{"path":"/articles/web-only/multipliers/multipliers-distill.html","id":"notes-regarding-this-dung-survey","dir":"Articles > Web-only > Multipliers","previous_headings":"","what":"Notes regarding this dung survey","title":"Multipliers and indirect surveys","text":"effort took place woodland deer density high. Therefore, overall estimate estimated density woodland lower densities woodlands. now uncertainty associated encounter rate, detection function decay rate (note uncertainty associated production rate) components variation three components provided. woodland , 13 transects 1,200 pellet groups detected: uncertainty estimated density (measured CV) 19% variance components apportioned detection probability 4%, encounter rate 76% multipliers 20%. woodland E, 5 transects 30 pellet groups resulting coefficient variation (CV) 48%: variance components apportioned detection probability 0.7%, encounter rate 96% multipliers 3%. CV abundance estimates blocks F, H J identical (9%) pooled detection function used across blocks dung deposition decay rates block-specific. element computation remaining block-specific encounter rate; three blocks single transect per block, meaning encounter rate variance computed set zero. estimated abundance across blocks CV 14%. far away, greatest contribution uncertainty encounter rate variance–differences pellet encounters transects. context distance sampling, uncertainty parameter estimates detection function accounts <1% total estimate deer abundance across blocks.","code":""},{"path":[]},{"path":"/articles/web-only/points/pointtransects-distill.html","id":"objectives","dir":"Articles > Web-only > Points","previous_headings":"","what":"Objectives","title":"Point transect density estimation","text":"Import data file Fit basic detection function using ds function Plot examine detection function Fit different detection function forms.","code":""},{"path":"/articles/web-only/points/pointtransects-distill.html","id":"survey-design","dir":"Articles > Web-only > Points","previous_headings":"","what":"Survey design","title":"Point transect density estimation","text":"total 373 point transects placed three pastures Arapaho National Wildlife Refuge Colorado (Figure 1). Elevation pastures ~2500m. deal pasture-level analysis data vignette alter data remove strata designations. Figure 1: Summer grazed pastures along Illinois River Arapaho National Wildlife Refuge, Colorado. Figure (Knopf et al., 1988). fields Savannah_sparrow_1980 data set : Region.Label - three pastures constituted sections study area. However, vignette going make labels identical. treat data detected pasture. matter stratification taken another vignette. Area - size study region. place holder, pasture sizes known. Estimates density abundance equivalent. Sample.Label - point transect identifier (total 373 points) Effort - number visits point object - unique identifier detected savanna sparrow distance - radial distance (metres) detection Study.Area - data savanna sparrow (SASP) included data set","code":""},{"path":"/articles/web-only/points/pointtransects-distill.html","id":"make-the-data-available-for-r-session","dir":"Articles > Web-only > Points","previous_headings":"","what":"Make the data available for R session","title":"Point transect density estimation","text":"command assumes dsdata package installed computer. R workspace Savannah_sparrow_1980 contains detections savanna sparrows point transect surveys Knopf et al. (1988). code overwrites strata designations original data make appear data derived single stratum. makes analysis simpler perform. examples analysis stratified data another vignette. Examine first rows Savannah_sparrow_1980 using function head() object Savannah_sparrow_1980 dataframe object made rows columns. contrast Montrave winter wren line transect data used previous vignette, savannah sparrows detected point transects. Radial distances receive value NA transects detections. determine number detections data set, total number values distance field NA","code":"library(Distance) data(Savannah_sparrow_1980) #  remove pasture-level identifier in Region.Label Savannah_sparrow_1980$Region.Label <- \"Single_stratum\" head(Savannah_sparrow_1980) ##     Region.Label Area Sample.Label Effort object distance Study.Area ## 1 Single_stratum    1    POINT   1      1     NA       NA  SASP 1980 ## 2 Single_stratum    1    POINT   2      1     NA       NA  SASP 1980 ## 3 Single_stratum    1    POINT   3      1     NA       NA  SASP 1980 ## 4 Single_stratum    1    POINT   4      1     NA       NA  SASP 1980 ## 5 Single_stratum    1    POINT   5      1     NA       NA  SASP 1980 ## 6 Single_stratum    1    POINT   6      1     NA       NA  SASP 1980 sum(!is.na(Savannah_sparrow_1980$distance)) ## [1] 276"},{"path":"/articles/web-only/points/pointtransects-distill.html","id":"examine-the-distribution-of-detection-distances","dir":"Articles > Web-only > Points","previous_headings":"","what":"Examine the distribution of detection distances","title":"Point transect density estimation","text":"Gain familiarity radial distance data using hist() function (Figure 2). Figure 2: Histogram radial distances savannah sparrows across pastures. Note shape radial distance histogram resemble shape perpendicular distances gathered line transect sampling (Buckland, Rexstad, Marques, & Oedekoven, 2015, sec. 1.3).","code":"hist(Savannah_sparrow_1980$distance, xlab=\"Distance (m)\",       main=\"Savannah sparrow point transects\")"},{"path":"/articles/web-only/points/pointtransects-distill.html","id":"specify-unit-conversions","dir":"Articles > Web-only > Points","previous_headings":"","what":"Specify unit conversions","title":"Point transect density estimation","text":"point transects, units measure associated size study area radial distance measures, effort measured number visits, rather distance. units measure radial distances units measure effort (NULL point transects) units measure study area. Recall data set set size study area 1, resulting abundance density equal.","code":"conversion.factor <- convert_units(\"meter\", NULL, \"hectare\")"},{"path":"/articles/web-only/points/pointtransects-distill.html","id":"fitting-a-simple-detection-function-model-with-ds","dir":"Articles > Web-only > Points","previous_headings":"","what":"Fitting a simple detection function model with ds","title":"Point transect density estimation","text":"Detection functions fitted using ds function function requires data frame column called distance. nests data, therefore, can simply supply name data frame function along additional arguments. Details arguments function: fit half-normal key detection function include adjustment terms necessary indicate point transect data required , example, radial distances metres . density estimates reported number birds per hectare. right truncation (described ) customary, right truncation employed remove 5% observations distant transects, detections distances contain little information shape fitted probability density function near point. calling ds function, information provided screen reminding user model fitted associated AIC value. information supplied applying summary() function object created ds(). Visually inspect fitted detection function plot() function, specifying cutpoints histogram argument breaks. Add argument pdf plot shows probability densiy function rather detection function. probability density function preferred assessing model fit PDF incorporates information availability animals detected. animals available detected small distances, therefore lack fit small distances consequential points lines (Figure 3). Figure 3: Fit half normal detection function savannah sparrow data.","code":"sasp.hn <- ds(data=Savannah_sparrow_1980, key=\"hn\", adjustment=NULL,               transect=\"point\", convert_units=conversion.factor, truncation=\"5%\") summary(sasp.hn) ##  ## Summary for distance analysis  ## Number of observations :  262  ## Distance range         :  0  -  51.025  ##  ## Model       : Half-normal key function  ## AIC         :  2021.776  ## Optimisation:  mrds (nlminb)  ##  ## Detection function parameters ## Scale coefficient(s):   ##             estimate         se ## (Intercept) 3.044624 0.04270318 ##  ##                       Estimate          SE         CV ## Average p             0.321125  0.02296165 0.07150378 ## N in covered region 815.881752 71.61153776 0.08777196 ##  ## Summary statistics: ##           Region Area CoveredArea Effort   n   k        ER      se.ER ## 1 Single_stratum    1    305.0877    373 262 373 0.7024129 0.04726421 ##        cv.ER ## 1 0.06728836 ##  ## Abundance: ##   Label Estimate        se         cv      lcl      ucl       df ## 1 Total 2.674253 0.2625745 0.09818612 2.206266 3.241509 598.5905 ##  ## Density: ##   Label Estimate        se         cv      lcl      ucl       df ## 1 Total 2.674253 0.2625745 0.09818612 2.206266 3.241509 598.5905 cutpoints <- c(0,5,10,15,20,30,40,max(Savannah_sparrow_1980$distance, na.rm=TRUE)) plot(sasp.hn, breaks=cutpoints, pdf=TRUE, main=\"Savannah sparrow point transect data.\")"},{"path":"/articles/web-only/points/pointtransects-distill.html","id":"specifying-different-detection-functions","dir":"Articles > Web-only > Points","previous_headings":"","what":"Specifying different detection functions","title":"Point transect density estimation","text":"Detection function forms shapes, specified changing key adjustment arguments. options available key adjustment elements detection functions : half normal (key=\"hn\") - default hazard rate (key=\"hr\") uniform (key=\"unif\") adjustment terms (adjustment=NULL) cosine (adjustment=\"cos\") - default Hermite polynomial (adjustment=\"herm\") Simple polynomial (adjustment=\"poly\") fit uniform key function cosine adjustment terms, use command: fit hazard rate key function simple polynomial adjustment terms, use command:","code":"sasp.unif.cos <- ds(Savannah_sparrow_1980, key=\"unif\", adjustment=\"cos\",                     transect=\"point\", convert_units=conversion.factor, truncation=\"5%\") sasp.hr.poly <- ds(Savannah_sparrow_1980, key=\"hr\", adjustment=\"poly\",                     transect=\"point\", convert_units=conversion.factor, truncation=\"5%\") ## Warning in ddf.ds(dsmodel = dsmodel, data = data, meta.data = meta.data, : ## Estimated hazard-rate scale parameter close to 0 (on log scale). Possible ## problem in data (e.g., spike near zero distance). ## Warning in ddf.ds(dsmodel = dsmodel, data = data, meta.data = meta.data, : ## Estimated hazard-rate scale parameter close to 0 (on log scale). Possible ## problem in data (e.g., spike near zero distance)."},{"path":"/articles/web-only/points/pointtransects-distill.html","id":"model-comparison","dir":"Articles > Web-only > Points","previous_headings":"","what":"Model comparison","title":"Point transect density estimation","text":"fitted detection function produces different estimate Savannah sparrow abundance density. estimate depends upon model chosen. model selection tool distance sampling data AIC.","code":"AIC(sasp.hn, sasp.hr.poly, sasp.unif.cos) ##               df      AIC ## sasp.hn        1 2021.776 ## sasp.hr.poly   3 2024.785 ## sasp.unif.cos  1 2023.178"},{"path":"/articles/web-only/points/pointtransects-distill.html","id":"absolute-goodness-of-fit","dir":"Articles > Web-only > Points","previous_headings":"Model comparison","what":"Absolute goodness of fit","title":"Point transect density estimation","text":"addition relative ranking models provided AIC, also important know whether selected model(s) actually fit data. model basis inference, dangerous make inference model fit data. Goodness fit assessed using function gof_ds (Figure 4). Figure 4: Q-Q plot half normal detection function savannah sparrow data.","code":"gof_ds(sasp.hn) ##  ## Goodness of fit results for ddf object ##  ## Distance sampling Cramer-von Mises test (unweighted) ## Test statistic = 0.0835959 p-value = 0.671325"},{"path":"/articles/web-only/points/pointtransects-distill.html","id":"model-comparison-tables","dir":"Articles > Web-only > Points","previous_headings":"","what":"Model comparison tables","title":"Point transect density estimation","text":"function summarise_ds_models combines work AIC gof_ds produce table fitted models summary statistics. Table 1: Model selection summary savannah sparrow point transect data.","code":"knitr::kable(summarize_ds_models(sasp.hn, sasp.hr.poly, sasp.unif.cos),digits=3,              caption=\"Model selection summary of savannah sparrow point transect data.\")"},{"path":"/articles/web-only/points/pointtransects-distill.html","id":"conclusions","dir":"Articles > Web-only > Points","previous_headings":"","what":"Conclusions","title":"Point transect density estimation","text":"Key differences analysis line transect data point transect data argument transect ds() must set \"point\", histogram radial detection distances characteristically “humped” individuals available detected near points, hump shape (Figure 2), plotting assess fit data detection distribution usually assessed via pdf=TRUE argument added plot() function, Arapaho National Refuge Savannah sparrow data, three candidate models provide adequeate fit data produce comparable estimates \\(P_a\\).","code":""},{"path":[]},{"path":"/articles/web-only/pointtransects-distill.html","id":"objectives","dir":"Articles > Web-only","previous_headings":"","what":"Objectives","title":"Point transect density estimation","text":"Import data file Fit basic detection function using ds function Plot examine detection function Fit different detection function forms.","code":""},{"path":"/articles/web-only/pointtransects-distill.html","id":"survey-design","dir":"Articles > Web-only","previous_headings":"","what":"Survey design","title":"Point transect density estimation","text":"total 373 point transects placed three pastures Arapaho National Wildlife Refuge Colorado (Figure 1). Elevation pastures ~2500m. deal pasture-level analysis data vignette alter data remove strata designations. Figure 1: Summer grazed pastures along Illinois River Arapaho National Wildlife Refuge, Colorado. Figure (Knopf et al., 1988). fields Savannah_sparrow_1980 data set : Region.Label - three pastures constituted sections study area. However, vignette going make labels identical. treat data detected pasture. matter stratification taken another vignette. Area - size study region. place holder, pasture sizes known. Estimates density abundance equivalent. Sample.Label - point transect identifier (total 373 points) Effort - number visits point object - unique identifier detected savanna sparrow distance - radial distance (metres) detection Study.Area - data savanna sparrow (SASP) included data set","code":""},{"path":"/articles/web-only/pointtransects-distill.html","id":"make-the-data-available-for-r-session","dir":"Articles > Web-only","previous_headings":"","what":"Make the data available for R session","title":"Point transect density estimation","text":"command assumes dsdata package installed computer. R workspace Savannah_sparrow_1980 contains detections savanna sparrows point transect surveys Knopf et al. (1988). code overwrites strata designations original data make appear data derived single stratum. makes analysis simpler perform. examples analysis stratified data another vignette. Examine first rows Savannah_sparrow_1980 using function head() object Savannah_sparrow_1980 dataframe object made rows columns. contrast Montrave winter wren line transect data used previous vignette, savannah sparrows detected point transects. Radial distances receive value NA transects detections. determine number detections data set, total number values distance field NA","code":"library(Distance) data(Savannah_sparrow_1980) #  remove pasture-level identifier in Region.Label Savannah_sparrow_1980$Region.Label <- \"Single_stratum\" head(Savannah_sparrow_1980) ##     Region.Label Area Sample.Label Effort object distance Study.Area ## 1 Single_stratum    1    POINT   1      1     NA       NA  SASP 1980 ## 2 Single_stratum    1    POINT   2      1     NA       NA  SASP 1980 ## 3 Single_stratum    1    POINT   3      1     NA       NA  SASP 1980 ## 4 Single_stratum    1    POINT   4      1     NA       NA  SASP 1980 ## 5 Single_stratum    1    POINT   5      1     NA       NA  SASP 1980 ## 6 Single_stratum    1    POINT   6      1     NA       NA  SASP 1980 sum(!is.na(Savannah_sparrow_1980$distance)) ## [1] 276"},{"path":"/articles/web-only/pointtransects-distill.html","id":"examine-the-distribution-of-detection-distances","dir":"Articles > Web-only","previous_headings":"","what":"Examine the distribution of detection distances","title":"Point transect density estimation","text":"Gain familiarity radial distance data using hist() function (Figure 2). Figure 2: Histogram radial distances savannah sparrows across pastures. Note shape radial distance histogram resemble shape perpendicular distances gathered line transect sampling (Buckland, Rexstad, Marques, & Oedekoven, 2015, sec. 1.3).","code":"hist(Savannah_sparrow_1980$distance, xlab=\"Distance (m)\",       main=\"Savannah sparrow point transects\")"},{"path":"/articles/web-only/pointtransects-distill.html","id":"specify-unit-conversions","dir":"Articles > Web-only","previous_headings":"","what":"Specify unit conversions","title":"Point transect density estimation","text":"point transects, units measure associated size study area radial distance measures, effort measured number visits, rather distance. units measure radial distances units measure effort (NULL point transects) units measure study area. Recall data set set size study area 1, resulting abundance density equal.","code":"conversion.factor <- convert_units(\"meter\", NULL, \"hectare\")"},{"path":"/articles/web-only/pointtransects-distill.html","id":"fitting-a-simple-detection-function-model-with-ds","dir":"Articles > Web-only","previous_headings":"","what":"Fitting a simple detection function model with ds","title":"Point transect density estimation","text":"Detection functions fitted using ds function function requires data frame column called distance. nests data, therefore, can simply supply name data frame function along additional arguments. Details arguments function: fit half-normal key detection function include adjustment terms necessary indicate point transect data required , example, radial distances metres . density estimates reported number birds per hectare. right truncation (described ) customary, right truncation employed remove 5% observations distant transects, detections distances contain little information shape fitted probability density function near point. calling ds function, information provided screen reminding user model fitted associated AIC value. information supplied applying summary() function object created ds(). Visually inspect fitted detection function plot() function, specifying cutpoints histogram argument breaks. Add argument pdf plot shows probability densiy function rather detection function. probability density function preferred assessing model fit PDF incorporates information availability animals detected. animals available detected small distances, therefore lack fit small distances consequential points lines (Figure 3). Figure 3: Fit half normal detection function savannah sparrow data.","code":"sasp.hn <- ds(data=Savannah_sparrow_1980, key=\"hn\", adjustment=NULL,               transect=\"point\", convert_units=conversion.factor, truncation=\"5%\") summary(sasp.hn) ##  ## Summary for distance analysis  ## Number of observations :  262  ## Distance range         :  0  -  51.025  ##  ## Model       : Half-normal key function  ## AIC         :  2021.776  ## Optimisation:  mrds (nlminb)  ##  ## Detection function parameters ## Scale coefficient(s):   ##             estimate         se ## (Intercept) 3.044624 0.04270318 ##  ##                       Estimate          SE         CV ## Average p             0.321125  0.02296165 0.07150378 ## N in covered region 815.881752 71.61153776 0.08777196 ##  ## Summary statistics: ##           Region Area CoveredArea Effort   n   k        ER      se.ER ## 1 Single_stratum    1    305.0877    373 262 373 0.7024129 0.04726421 ##        cv.ER ## 1 0.06728836 ##  ## Abundance: ##   Label Estimate        se         cv      lcl      ucl       df ## 1 Total 2.674253 0.2625745 0.09818612 2.206266 3.241509 598.5905 ##  ## Density: ##   Label Estimate        se         cv      lcl      ucl       df ## 1 Total 2.674253 0.2625745 0.09818612 2.206266 3.241509 598.5905 cutpoints <- c(0,5,10,15,20,30,40,max(Savannah_sparrow_1980$distance, na.rm=TRUE)) plot(sasp.hn, breaks=cutpoints, pdf=TRUE, main=\"Savannah sparrow point transect data.\")"},{"path":"/articles/web-only/pointtransects-distill.html","id":"specifying-different-detection-functions","dir":"Articles > Web-only","previous_headings":"","what":"Specifying different detection functions","title":"Point transect density estimation","text":"Detection function forms shapes, specified changing key adjustment arguments. options available key adjustment elements detection functions : half normal (key=\"hn\") - default hazard rate (key=\"hr\") uniform (key=\"unif\") adjustment terms (adjustment=NULL) cosine (adjustment=\"cos\") - default Hermite polynomial (adjustment=\"herm\") Simple polynomial (adjustment=\"poly\") fit uniform key function cosine adjustment terms, use command: fit hazard rate key function simple polynomial adjustment terms, use command:","code":"sasp.unif.cos <- ds(Savannah_sparrow_1980, key=\"unif\", adjustment=\"cos\",                     transect=\"point\", convert_units=conversion.factor, truncation=\"5%\") sasp.hr.poly <- ds(Savannah_sparrow_1980, key=\"hr\", adjustment=\"poly\",                     transect=\"point\", convert_units=conversion.factor, truncation=\"5%\")"},{"path":"/articles/web-only/pointtransects-distill.html","id":"model-comparison","dir":"Articles > Web-only","previous_headings":"","what":"Model comparison","title":"Point transect density estimation","text":"fitted detection function produces different estimate Savannah sparrow abundance density. estimate depends upon model chosen. model selection tool distance sampling data AIC.","code":"AIC(sasp.hn, sasp.hr.poly, sasp.unif.cos) ##               df      AIC ## sasp.hn        1 2021.776 ## sasp.hr.poly   3 2024.785 ## sasp.unif.cos  1 2023.178"},{"path":"/articles/web-only/pointtransects-distill.html","id":"absolute-goodness-of-fit","dir":"Articles > Web-only","previous_headings":"Model comparison","what":"Absolute goodness of fit","title":"Point transect density estimation","text":"addition relative ranking models provided AIC, also important know whether selected model(s) actually fit data. model basis inference, dangerous make inference model fit data. Goodness fit assessed using function gof_ds (Figure 4). Figure 4: Q-Q plot half normal detection function savannah sparrow data.","code":"gof_ds(sasp.hn) ##  ## Goodness of fit results for ddf object ##  ## Distance sampling Cramer-von Mises test (unweighted) ## Test statistic = 0.0835959 p-value = 0.671325"},{"path":"/articles/web-only/pointtransects-distill.html","id":"model-comparison-tables","dir":"Articles > Web-only","previous_headings":"","what":"Model comparison tables","title":"Point transect density estimation","text":"function summarise_ds_models combines work AIC gof_ds produce table fitted models summary statistics. Table 1: Model selection summary savannah sparrow point transect data.","code":"knitr::kable(summarize_ds_models(sasp.hn, sasp.hr.poly, sasp.unif.cos),digits=3,              caption=\"Model selection summary of savannah sparrow point transect data.\")"},{"path":"/articles/web-only/pointtransects-distill.html","id":"conclusions","dir":"Articles > Web-only","previous_headings":"","what":"Conclusions","title":"Point transect density estimation","text":"Key differences analysis line transect data point transect data argument transect ds() must set \"point\", histogram radial detection distances characteristically “humped” individuals available detected near points, hump shape (Figure 2), plotting assess fit data detection distribution usually assessed via pdf=TRUE argument added plot() function, Arapaho National Refuge Savannah sparrow data, three candidate models provide adequeate fit data produce comparable estimates \\(P_a\\).","code":""},{"path":"/articles/web-only/strata/strata-distill.html","id":"objectives","dir":"Articles > Web-only > Strata","previous_headings":"","what":"Objectives","title":"Analysis of stratified survey designs","text":"Fit detection function pooling data across pastures, Fit pasture-specific detection functions, Choose appropriate analysis using model selection.","code":""},{"path":"/articles/web-only/strata/strata-distill.html","id":"survey-design","dir":"Articles > Web-only > Strata","previous_headings":"","what":"Survey design","title":"Analysis of stratified survey designs","text":"total 373 point transects placed three pastures Arapaho National Wildlife Refuge Colorado (Figure 1). Elevation pastures ~2500m. example, perform pasture-level analysis data. Figure 1: Summer grazed pastures along Illinois River Arapaho National Wildlife Refuge, Colorado. Figure (Knopf et al., 1988). fields Savannah_sparrow_1980 data set : Region.Label - three pastures constituted sections study area. Area - size study region. place holder, pasture sizes known. Estimates density abundance equivalent. Sample.Label - point transect identifier (total 273) Effort - number visits point object - unique identifier detected savanna sparrow distance - radial distance (metres) detection Study.Area - data savanna sparrow (SASP) included data set","code":""},{"path":"/articles/web-only/strata/strata-distill.html","id":"make-the-data-available-for-r-session","dir":"Articles > Web-only > Strata","previous_headings":"","what":"Make the data available for R session","title":"Analysis of stratified survey designs","text":"command assumes dsdata package installed computer. R workspace Savannah_sparrow_1980 contains detections savanna sparrows point transect surveys Knopf et al. (1988).","code":"library(Distance) data(Savannah_sparrow_1980) conversion.factor <- convert_units(\"meter\", NULL, \"hectare\")"},{"path":"/articles/web-only/strata/strata-distill.html","id":"separate-data-into-pasture-specific-data-sets","dir":"Articles > Web-only > Strata","previous_headings":"","what":"Separate data into pasture-specific data sets","title":"Analysis of stratified survey designs","text":"simplest way fit pasture-specific detection functions subset data. done time ds() function called, perform step data preparation step.","code":"sasp.past1 <- subset(Savannah_sparrow_1980, Region.Label == \"PASTURE 1\") sasp.past2 <- subset(Savannah_sparrow_1980, Region.Label == \"PASTURE 2\") sasp.past3 <- subset(Savannah_sparrow_1980, Region.Label == \"PASTURE 3\")"},{"path":"/articles/web-only/strata/strata-distill.html","id":"pasture-stratum-specific-detection-functions","dir":"Articles > Web-only > Strata","previous_headings":"","what":"Pasture (stratum)-specific detection functions","title":"Analysis of stratified survey designs","text":"Fit half-normal key functions without adjustments pasture separately performing 5% right truncation. total AIC model fits separate detection functions pasture sum AICs individual pastures.","code":"past1.hn <- ds(data=sasp.past1, key=\"hn\", adjustment=NULL,               transect=\"point\", convert_units=conversion.factor, truncation=\"5%\") past2.hn <- ds(data=sasp.past2, key=\"hn\", adjustment=NULL,               transect=\"point\", convert_units=conversion.factor, truncation=\"5%\") past3.hn <- ds(data=sasp.past3, key=\"hn\", adjustment=NULL,               transect=\"point\", convert_units=conversion.factor, truncation=\"5%\") model.separate.AIC <- sum(AIC(past1.hn, past2.hn, past3.hn)$AIC)"},{"path":"/articles/web-only/strata/strata-distill.html","id":"common-detection-function-across-pastures","dir":"Articles > Web-only > Strata","previous_headings":"","what":"Common detection function across pastures","title":"Analysis of stratified survey designs","text":"model much simpler fit single call ds() using original data.","code":"model.pooled <- ds(data=Savannah_sparrow_1980, key=\"hn\", adjustment=NULL,                    transect=\"point\", convert_units = conversion.factor, truncation = \"5%\") model.pooled.AIC <- AIC(model.pooled)"},{"path":"/articles/web-only/strata/strata-distill.html","id":"comparison-of-aic-scores","dir":"Articles > Web-only > Strata","previous_headings":"","what":"Comparison of AIC scores","title":"Analysis of stratified survey designs","text":"AIC model stratum-specific detection functions (2007) less AIC model pooled detection function (2022), base inference upon stratum-specific detection function model (depicted Figure 2). Figure 2: Pasture-specific detection functions based upon half-normal key function.","code":"cat(paste(\"Stratum-specific detection AIC\", round(model.separate.AIC),       \"\\nCommon detection function AIC\", round(model.pooled.AIC$AIC)), sep=\" \") ## Stratum-specific detection AIC 2007  ## Common detection function AIC 2022 cutpoints <- c(0,5,10,15,20,30,40,53) par(mfrow=c(1,3)) plot(past1.hn, breaks=cutpoints, pdf=TRUE, main=\"Pasture 1\") plot(past2.hn, breaks=cutpoints, pdf=TRUE, main=\"Pasture 2\") plot(past3.hn, breaks=cutpoints, pdf=TRUE, main=\"Pasture 3\")"},{"path":"/articles/web-only/strata/strata-distill.html","id":"absolute-goodness-of-fit","dir":"Articles > Web-only > Strata","previous_headings":"Comparison of AIC scores","what":"Absolute goodness of fit","title":"Analysis of stratified survey designs","text":"Always best check fit preferred model data. exploration analyses involving stratification can found example dung survey analysis.","code":"gof_ds(past1.hn, plot = FALSE) gof_ds(past2.hn, plot = FALSE) gof_ds(past3.hn, plot = FALSE) ##  ## Goodness of fit results for ddf object ##  ## Distance sampling Cramer-von Mises test (unweighted) ## Test statistic = 0.0939637 p-value = 0.615284 ##  ## Goodness of fit results for ddf object ##  ## Distance sampling Cramer-von Mises test (unweighted) ## Test statistic = 0.0478577 p-value = 0.889162 ##  ## Goodness of fit results for ddf object ##  ## Distance sampling Cramer-von Mises test (unweighted) ## Test statistic = 0.0402974 p-value = 0.931609"},{"path":"/articles/web-only/strata/strata-distill.html","id":"comments","dir":"Articles > Web-only > Strata","previous_headings":"","what":"Comments","title":"Analysis of stratified survey designs","text":"Note difference 14 AIC units model using stratum-specific detection functions model using pooled detection function, stratum-specific detection function model preferrable. thorough, absolute goodness fit three stratum-specific detection functions checked, models fit data adequately. vignette focuses upon use stratum-specific detection functions model selection exercise. Consequently, vignette examine stratum-specific abundance density estimates. output included example analysis, can easily produced continuing analysis begun example.","code":""},{"path":[]},{"path":"/articles/web-only/variance/variance-distill.html","id":"objectives","dir":"Articles > Web-only > Variance","previous_headings":"","what":"Objectives","title":"Variance estimation","text":"Estimate precision standard manner Use bootstrap estimate precision Incorporate model uncertainty estimates precision","code":""},{"path":"/articles/web-only/variance/variance-distill.html","id":"survey-data","dir":"Articles > Web-only > Variance","previous_headings":"","what":"Survey data","title":"Variance estimation","text":"R workspace wren_lt contains detections winter wrens line transect surveys S. T. Buckland (2006). function names() allows see names columns data frame wren_lt. Definitions fields provided line transect vignette. effort, transect length adjusted recognise transect walked twice.","code":"library(Distance) data(wren_lt) conversion.factor <- convert_units(\"meter\", \"kilometer\", \"hectare\")"},{"path":"/articles/web-only/variance/variance-distill.html","id":"fitting-a-suitable-detection-function","dir":"Articles > Web-only > Variance","previous_headings":"","what":"Fitting a suitable detection function","title":"Variance estimation","text":"Rather refitting models used line transect vignette, move directly model selected S. T. Buckland (2006). Based upon experience field, uniform cosine model used inference.","code":"wren.unif.cos <- ds(wren_lt, key=\"unif\", adjustment=\"cos\",                   convert_units=conversion.factor) ## Warning in check.mono(result, n.pts = control$mono.points): Detection function ## is not strictly monotonic! ## Warning in check.mono(result, n.pts = control$mono.points): Detection function ## is not strictly monotonic! ## Warning in mrds::check.mono(model, n.pts = 20): Detection function is not ## strictly monotonic!"},{"path":"/articles/web-only/variance/variance-distill.html","id":"estimation-of-precision","dir":"Articles > Web-only > Variance","previous_headings":"","what":"Estimation of precision","title":"Variance estimation","text":"Looking density estimates uniform cosine model coefficient variation (CV) 0.2, confidence interval bounds (0.72 - 1.57) birds per hectare. coefficient variation based upon delta-method approximation uncertainty parameters detection function variability encounter rates transects. \\[[CV(\\hat{D})]^2 = [CV(\\frac{n}{L})]^2 + [CV(P_a)]^2\\] \\(n\\) number detections \\(L\\) total effort \\(P_a\\) probability detection given bird within covered region. confidence interval bounds assume sampling distribution \\(\\hat{D}\\) log-normal (S. Buckland, Rexstad, Marques, & Oedekoven, 2015, sec. 6.2.1).","code":"print(wren.unif.cos$dht$individuals$D) ##   Label Estimate       se       cv       lcl     ucl       df ## 1 Total 1.066094 0.212691 0.199505 0.7217919 1.57463 168.2046"},{"path":"/articles/web-only/variance/variance-distill.html","id":"bootstrap-estimates-of-precision","dir":"Articles > Web-only > Variance","previous_headings":"Estimation of precision","what":"Bootstrap estimates of precision","title":"Variance estimation","text":"Rather relying upon delta-method approximation assumes independence uncertainty detection function variability encounter rate, bootstrap procedure can employed. Resampling replacement transects produces replicate samples sampling distribution \\(\\hat{D}\\) approximated. sampling distribution, percentile method used produce confidence interval bounds respecting shape sampling distribution (S. Buckland et al., 2015, sec. 6.3.1.2). function bootdht_Nhat_summarize included Distance package. used extract information object created bootdht. modify slightly extract density estimates rather abundance estimates. summary function defined, bootstrap procedure can performed. Arguments name fitted object, object containing data, conversion factor number bootstrap replicates. , use cores= argument use multiple cores process bootstraps parallel. many cores computer, need reduce/remove argument. object est.boot contains data frame two columns consisting \\(\\hat{D}\\) specified bootdht_Dhat_summarize. data frame can processed produce histogram (Fig. 1) representing sampling distribution estimated parameters well percentile confidence interval bounds. Figure 1: Sampling distribution \\(\\hat{D}\\) approximated bootstrap.","code":"bootdht_Dhat_summarize <- function(ests, fit) {   return(data.frame(D=ests$individuals$D$Estimate)) } nboots <- 300 est.boot <- bootdht(model=wren.unif.cos, flatfile=wren_lt,                     summary_fun=bootdht_Dhat_summarize,                     convert_units=conversion.factor, nboot=nboots, cores=10) alpha <- 0.05 (bootci <- quantile(est.boot$D, probs = c(alpha/2, 1-alpha/2), na.rm=TRUE)) ##      2.5%     97.5%  ## 0.7940937 1.4088653 hist(est.boot$D, nc=30,      main=\"Distribution of bootstrap estimates\\nwithout model uncertainty\",      xlab=\"Estimated density\") abline(v=bootci, lwd=2, lty=2)"},{"path":"/articles/web-only/variance/variance-distill.html","id":"incorporating-model-uncertainty-in-precision-estimates","dir":"Articles > Web-only > Variance","previous_headings":"","what":"Incorporating model uncertainty in precision estimates","title":"Variance estimation","text":"argument model bootdht can single model shown , can consist list models. later instance, models list fitted bootstrap replicate model selection based AIC performed replicate. consequence model uncertainty incorporated resulting estimate precision (Fig. 2). Figure 2: Sampling distribution \\(\\hat{D}\\) approximated bootstrap including model uncertainty.","code":"wren.hn <- ds(wren_lt, key=\"hn\", adjustment=\"cos\",                   convert_units=conversion.factor) ## Warning in check.mono(result, n.pts = control$mono.points): Detection function ## is not strictly monotonic! ## Warning in check.mono(result, n.pts = control$mono.points): Detection function ## is not strictly monotonic! wren.hr.poly <- ds(wren_lt, key=\"hr\", adjustment=\"poly\",                   convert_units=conversion.factor) est.boot.uncert <- bootdht(model=list(wren.hn, wren.hr.poly, wren.unif.cos),                             flatfile=wren_lt,                            summary_fun=bootdht_Dhat_summarize,                            convert_units=conversion.factor, nboot=nboots, cores=10) (modselci <- quantile(est.boot.uncert$D, probs = c(alpha/2, 1-alpha/2), na.rm=TRUE)) ##      2.5%     97.5%  ## 0.7994786 1.3560532 hist(est.boot.uncert$D, nc=30,       main=\"Distribution of bootstrap estimates\\nincluding model uncertainty\",      xlab=\"Estimated density\") abline(v=modselci, lwd=2, lty=2)"},{"path":"/articles/web-only/variance/variance-distill.html","id":"comments","dir":"Articles > Web-only > Variance","previous_headings":"","what":"Comments","title":"Variance estimation","text":"Recognise producing bootstrap estimates precision computer-intensive. example created 300 bootstrap replicates interest computation time. inference wish draw, likely increase number bootstrap replicates 999. data set, bootstrap estimate precision greater delta-method approximation precision (based confidence interval width). addition, incorporating model uncertainty estimate precision density changes precision estimate little. confidence interval width without incorporating model uncertainty 0.615 confidence interval including model uncertainty 0.557. represents change -9% due uncertainty regarding best model data.","code":""},{"path":[]},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"David Laurence Miller. Author. T.J. Clark-Wolf. Author. Laura Marshall. Maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Miller DL, Rexstad E, Thomas L, Marshall L, Laake JL (2019). “Distance Sampling R.” Journal Statistical Software, 89(1), 1–28. doi:10.18637/jss.v089.i01.","code":"@Article{,   title = {Distance Sampling in {R}},   author = {David L. Miller and Eric Rexstad and Len Thomas and Laura Marshall and Jeffrey L. Laake},   journal = {Journal of Statistical Software},   year = {2019},   volume = {89},   number = {1},   pages = {1--28},   doi = {10.18637/jss.v089.i01}, }"},{"path":[]},{"path":"/index.html","id":"distance-r-package-preferred-citation","dir":"","previous_headings":"","what":"Distance R package preferred citation","title":"Distance Sampling Detection Function and Abundance Estimation","text":"Miller, D. L., Rexstad, E., Thomas, L., Marshall, L., & Laake, J. L. (2019). Distance Sampling R. Journal Statistical Software, 89(1), 1–28. DOI: 10.18637/jss.v089.i01 also maintain set example analyses examples.distancesampling.org.","code":""},{"path":"/index.html","id":"getting-distance","dir":"","previous_headings":"","what":"Getting Distance","title":"Distance Sampling Detection Function and Abundance Estimation","text":"easiest way ensure latest version Distance, install devtools: {r} install.packages(\"devtools\") install Distance Github: {r} library(devtools) install_github(\"DistanceDevelopment/Distance\")","code":""},{"path":"/reference/add_df_covar_line.html","id":null,"dir":"Reference","previous_headings":"","what":"Add covariate levels detection function plots — add_df_covar_line","title":"Add covariate levels detection function plots — add_df_covar_line","text":"Add line lines plot detection function correspond given covariate combination. can particularly useful small number factor levels quantiles continuous covariate specified.","code":""},{"path":"/reference/add_df_covar_line.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add covariate levels detection function plots — add_df_covar_line","text":"ddf fitted detection function object. data data.frame covariate combination want plot. ... extra arguments give lines (e.g., lty, lwd, col). ndist number distances evaluate detection function. pdf line drawn probability density scale; ignored line transects breaks required ensure PDF lines right size, match supplied original plot command. Defaults \"Sturges\" breaks, hist. used pdf=TRUE","code":""},{"path":"/reference/add_df_covar_line.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add covariate levels detection function plots — add_df_covar_line","text":"invisibly, values detectability truncation range.","code":""},{"path":"/reference/add_df_covar_line.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add covariate levels detection function plots — add_df_covar_line","text":"covariates must specified data. Plots can become quite busy approach used. may useful fix covariates median level plot set values covariate interest. example setting weather (e.g., Beaufort) median plotting levels observer, creating second plot fixed observer levels weather. Arguments lines supplied ... aesthetics like line type (lty), line width (lwd) colour (col) recycled. default lty used distinguish lines. may useful add legend plot (lines plotted order data).","code":""},{"path":"/reference/add_df_covar_line.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Add covariate levels detection function plots — add_df_covar_line","text":"function located mrds package documentation provided easy access.","code":""},{"path":"/reference/add_df_covar_line.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Add covariate levels detection function plots — add_df_covar_line","text":"David L Miller","code":""},{"path":"/reference/add_df_covar_line.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add covariate levels detection function plots — add_df_covar_line","text":"","code":"# example using a model for the minke data data(minke) # fit a model result <- ds(minke, formula=~Region.Label) #> Model contains covariate term(s): no adjustment terms will be included. #> Fitting half-normal key function #> AIC= 57.005  # make a base plot, showpoints=FALSE makes the plot less busy plot(result, showpoints=FALSE)  # add lines for sex one at a time add_df_covar_line(result, data.frame(Region.Label=\"South\"), lty=2) add_df_covar_line(result, data.frame(Region.Label=\"North\"), lty=3)  # add a legend legend(1.5, 1, c(\"Average\", \"South\", \"North\"), lty=1:3)   # point transect example data(amakihi) result <- ds(amakihi, truncation=150, transect=\"point\", formula=~OBs) #> Model contains covariate term(s): no adjustment terms will be included. #> Fitting half-normal key function #> AIC= 13870.198 plot(result, showpoints=FALSE, pdf=TRUE) add_df_covar_line(result,                   data.frame(OBs=na.omit(unique(amakihi$OBs))), pdf=TRUE)"},{"path":"/reference/AIC.dsmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Akaike's An Information Criterion for detection functions — AIC.dsmodel","title":"Akaike's An Information Criterion for detection functions — AIC.dsmodel","text":"Extract AIC fitted detection function.","code":""},{"path":"/reference/AIC.dsmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Akaike's An Information Criterion for detection functions — AIC.dsmodel","text":"","code":"# S3 method for dsmodel AIC(object, ..., k = 2)"},{"path":"/reference/AIC.dsmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Akaike's An Information Criterion for detection functions — AIC.dsmodel","text":"object fitted detection function object ... optionally fitted model objects. k penalty per parameter used; default k = 2 \"classical\" AIC","code":""},{"path":"/reference/AIC.dsmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Akaike's An Information Criterion for detection functions — AIC.dsmodel","text":"David L Miller","code":""},{"path":"/reference/AIC.dsmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Akaike's An Information Criterion for detection functions — AIC.dsmodel","text":"","code":"if (FALSE) { library(Distance) data(minke) model <- ds(minke, truncation=4) model_hr <- ds(minke, truncation=4, key=\"hr\") # extract the AIC for 2 models AIC(model, model_hr) }"},{"path":"/reference/amakihi.html","id":null,"dir":"Reference","previous_headings":"","what":"Hawaiian amakihi point transect data — amakihi","title":"Hawaiian amakihi point transect data — amakihi","text":"Also known Common 'Amakihi, type Hawaiian honeycreeper","code":""},{"path":"/reference/amakihi.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Hawaiian amakihi point transect data — amakihi","text":"data.frame 1487 rows 12 variables Region.Label strata names (seven strata) Area size study area (set 0) Sample.Label transect ID Effort number visits point object object ID distance radial distance (m) Month month survey conducted (used) OBs observer ID (note capitalisation variable name) Sp species code (COAM) detections MAS Time sunrise (min) Time sunrise (hours) Study.Area name study area","code":""},{"path":"/reference/amakihi.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Hawaiian amakihi point transect data — amakihi","text":"Example investigating covariates detection function.  Note high colinearity two measures time since sunrise.  Convergence problems can result models several factor covariates.","code":""},{"path":"/reference/amakihi.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hawaiian amakihi point transect data — amakihi","text":"Marques, T.., L. Thomas, S.G. Fancy S.T. Buckland. (2007) Improving estimates bird density using multiple-covariate distance sampling.  Auk 124 (4): 1229–1243. doi:10.1642/0004-8038(2007)124[1229:IEOBDU]2.0.CO;2","code":""},{"path":"/reference/bootdht.html","id":null,"dir":"Reference","previous_headings":"","what":"Bootstrap uncertainty estimation for distance sampling models — bootdht","title":"Bootstrap uncertainty estimation for distance sampling models — bootdht","text":"Performs bootstrap simple distance sampling models using data structures dht. Note geographical stratification supported dht allowed.","code":""},{"path":"/reference/bootdht.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bootstrap uncertainty estimation for distance sampling models — bootdht","text":"","code":"bootdht(   model,   flatfile,   resample_strata = FALSE,   resample_obs = FALSE,   resample_transects = TRUE,   nboot = 100,   summary_fun = bootdht_Nhat_summarize,   convert_units = 1,   select_adjustments = FALSE,   sample_fraction = 1,   multipliers = NULL,   progress_bar = \"base\",   cores = 1,   convert.units = NULL )"},{"path":"/reference/bootdht.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bootstrap uncertainty estimation for distance sampling models — bootdht","text":"model model fitted ds list models flatfile Data provided flatfile format. See flatfile details. Please note, current limitation bootdht Sample.Label identifiers must unique across strata, .e.transect ids must re-used one strata another. easy way achieve paste together stratum names transect ids. resample_strata resampling happen stratum (Region.Label) level? (Default FALSE) resample_obs resampling happen observation (object) level? (Default FALSE) resample_transects resampling happen transect (Sample.Label) level? (Default TRUE) nboot number bootstrap replicates summary_fun function used obtain summary statistics bootstrap, see Summary Functions . default bootdht_Nhat_summarize used, just extracts abundance estimates. convert_units conversion units abundance estimation, see \"Units\", . (Defaults 1, implying units \"correct\" already.) takes precedence unit conversion stored model. select_adjustments select number adjustments bootstrap, FALSE exact detection function specified model fitted replicate. Setting option TRUE can significantly increase runtime bootstrap. Note work model must fitted adjustment!=NULL. sample_fraction proportion transects covered (e.g., 0.5 one-sided line transects). multipliers list multipliers. See \"Multipliers\" . progress_bar progress bar used? Default \"base\" uses txtProgressBar, \"none\" suppresses output, \"progress\" uses progress package, installed. cores number CPU cores use compute estimates. See \"Parallelization\" . convert.units deprecated, see argument underscore, .","code":""},{"path":"/reference/bootdht.html","id":"summary-functions","dir":"Reference","previous_headings":"","what":"Summary Functions","title":"Bootstrap uncertainty estimation for distance sampling models — bootdht","text":"function summary_fun allows user specify summary statistics recorded bootstrap. function take two arguments, ests fit. former output dht2, giving tables estimates. latter fitted detection function object. function called fitting estimation performed return data.frame. data.frames concatenated using rbind. One can make functions return information within objects, example abundance density estimates AIC model. See Examples .","code":""},{"path":"/reference/bootdht.html","id":"multipliers","dir":"Reference","previous_headings":"","what":"Multipliers","title":"Bootstrap uncertainty estimation for distance sampling models — bootdht","text":"often case measure distances individuals groups directly, instead need estimate distances something produce (e.g., whales, blows; elephants dung) -- referred indirect sampling. may need use estimates production rate decay rate estimates (case dung nests) just production rates (case songbird calls whale blows). refer conversions \"number cues\" \"number animals\" \"multipliers\". multipliers argument list, 3 possible elements (creation decay). element either: data.frame must least column named rate, abundance estimates divided (term \"multiplier\" misnomer, kept compatibility Distance Windows). Additional columns can added give standard error degrees freedom rate known SE df, respectively. can use multirow data.frame different rates different geographical areas (example). case rows need column (columns) merge data (example Region.Label). function return single estimate relevant multiplier. See make_activity_fn helper function use activity package.","code":""},{"path":"/reference/bootdht.html","id":"model-selection","dir":"Reference","previous_headings":"","what":"Model selection","title":"Bootstrap uncertainty estimation for distance sampling models — bootdht","text":"Model selection can performed per-replicate basis within bootstrap. three variations: select_adjustments TRUE adjustment terms selected AIC within bootstrap replicate (provided model order adjustment options set non-NULL. model list fitted detection functions, fitted replicate results generated one lowest AIC. select_adjustments TRUE model list fitted detection functions, model fitted replicate number adjustments selected via AIC. last option can extremely time consuming.","code":""},{"path":"/reference/bootdht.html","id":"parallelization","dir":"Reference","previous_headings":"","what":"Parallelization","title":"Bootstrap uncertainty estimation for distance sampling models — bootdht","text":"cores>1 parallel/doParallel/foreach/doRNG packages used run computation multiple cores computer. use component need install packages using: install.packages(c(\"foreach\", \"doParallel\", \"doRNG\")) advised set cores greater one less number cores machine. doRNG package required make analyses reproducible (set.seed can used ensure answers). also hard debug issues summary_fun best run small number bootstraps first parallel check things work. Windows systems summary_fun access global environment running parallel, computations must made using ests fit arguments (.e., can use R objects elsewhere function, even available console). Another consequence global environment unavailable inside parallel bootstraps starting values model object passed bootdht must hard coded (otherwise get back 0 successful bootstraps). worked example showing , see camera trap distance sampling online example https://examples.distancesampling.org/Distance-cameratraps/camera-distill.html.","code":""},{"path":[]},{"path":"/reference/bootdht.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bootstrap uncertainty estimation for distance sampling models — bootdht","text":"","code":"if (FALSE) { # fit a model to the minke data data(minke) mod1 <- ds(minke)  # summary function to save the abundance estimate Nhat_summarize <- function(ests, fit) {   return(data.frame(Nhat=ests$individuals$N$Estimate)) }  # perform 5 bootstraps bootout <- bootdht(mod1, flatfile=minke, summary_fun=Nhat_summarize, nboot=5)  # obtain basic summary information summary(bootout) }"},{"path":"/reference/bootdht_Dhat_summarize.html","id":null,"dir":"Reference","previous_headings":"","what":"Simple summary of density results for bootstrap model — bootdht_Dhat_summarize","title":"Simple summary of density results for bootstrap model — bootdht_Dhat_summarize","text":"using bootdht one needs use summary function extract results resulting models per replicate. function simplest possible example function, just extracts estimated density (stratum labels).","code":""},{"path":"/reference/bootdht_Dhat_summarize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simple summary of density results for bootstrap model — bootdht_Dhat_summarize","text":"","code":"bootdht_Dhat_summarize(ests, fit)"},{"path":"/reference/bootdht_Dhat_summarize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simple summary of density results for bootstrap model — bootdht_Dhat_summarize","text":"ests output dht2. fit fitted detection function object (unused).","code":""},{"path":"/reference/bootdht_Dhat_summarize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simple summary of density results for bootstrap model — bootdht_Dhat_summarize","text":"data.frame two columns (\"Dhat\" \"Label\"), giving estimate(s) density individuals per stratum bootstrap replicate. data.frame can examined example, quantile compute confidence intervals.","code":""},{"path":"/reference/bootdht_Dhat_summarize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simple summary of density results for bootstrap model — bootdht_Dhat_summarize","text":"examples functions can found http://examples.distancesampling.org.","code":""},{"path":[]},{"path":"/reference/bootdht_Nhat_summarize.html","id":null,"dir":"Reference","previous_headings":"","what":"Simple summary of abundance results for bootstrap model — bootdht_Nhat_summarize","title":"Simple summary of abundance results for bootstrap model — bootdht_Nhat_summarize","text":"using bootdht one needs use summary function extract results resulting models per replicate. function simplest possible example function, just extracts estimated abundance (stratum labels).","code":""},{"path":"/reference/bootdht_Nhat_summarize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simple summary of abundance results for bootstrap model — bootdht_Nhat_summarize","text":"","code":"bootdht_Nhat_summarize(ests, fit)"},{"path":"/reference/bootdht_Nhat_summarize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simple summary of abundance results for bootstrap model — bootdht_Nhat_summarize","text":"ests output dht2. fit fitted detection function object (unused).","code":""},{"path":"/reference/bootdht_Nhat_summarize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simple summary of abundance results for bootstrap model — bootdht_Nhat_summarize","text":"data.frame two columns (\"Nhat\" \"Label\"), giving estimate(s) abundance individuals per stratum bootstrap replicate. data.frame can examined example, quantile compute confidence intervals.","code":""},{"path":"/reference/bootdht_Nhat_summarize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simple summary of abundance results for bootstrap model — bootdht_Nhat_summarize","text":"examples functions can found http://examples.distancesampling.org.","code":""},{"path":[]},{"path":"/reference/capercaillie.html","id":null,"dir":"Reference","previous_headings":"","what":"Capercaillie in Monaughty Forest — capercaillie","title":"Capercaillie in Monaughty Forest — capercaillie","text":"Data line transect survey capercaillie Monaughty Forest, Moray, Scotland.","code":""},{"path":"/reference/capercaillie.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Capercaillie in Monaughty Forest — capercaillie","text":"data.frame 112 observations following 9 variables. Sample.Label name single transect Effort transect length (km) distance perpendicular distance (m) object object ID size individual birds detected detected whether detected observer single observer data Region.Label stratum name Area size Monaughty Forest (ha)","code":""},{"path":"/reference/checkdata.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that the data supplied to ds is correct — checkdata","title":"Check that the data supplied to ds is correct — checkdata","text":"internal function checks data.frames supplied ds \"correct\".","code":""},{"path":"/reference/checkdata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that the data supplied to ds is correct — checkdata","text":"","code":"checkdata(   data,   region.table = NULL,   sample.table = NULL,   obs.table = NULL,   formula = ~1 )"},{"path":"/reference/checkdata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check that the data supplied to ds is correct — checkdata","text":"data ds region.table ds sample.table ds obs.table ds formula formula covariates","code":""},{"path":"/reference/checkdata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check that the data supplied to ds is correct — checkdata","text":"Throws error something goes wrong, otherwise returns data.frame.","code":""},{"path":"/reference/checkdata.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check that the data supplied to ds is correct — checkdata","text":"David L. Miller","code":""},{"path":"/reference/ClusterExercise.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated minke whale data with cluster size — ClusterExercise","title":"Simulated minke whale data with cluster size — ClusterExercise","text":"Data simulated models fitted 1992/1993 Southern Hemisphere minke whale data collected International Whaling Commission. See Branch Butterworth (2001) survey details (survey design shown figure 1(e)). Data simulated David Borchers.","code":""},{"path":"/reference/ClusterExercise.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated minke whale data with cluster size — ClusterExercise","text":"data.frame 99 observations 9 variables: Region.Label stratum label (\"North\" \"South\") Area stratum area  (square nautical mile) Sample.Label transect identifier Effort transect length  (nautical mile) object unique object ID distance observed distance  (nautical mile) Cluster.strat strata based cluster size: 1, 2 3+ size cluster size Study.Area name study area","code":""},{"path":"/reference/ClusterExercise.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulated minke whale data with cluster size — ClusterExercise","text":"Branch, T.. D.S. Butterworth. (2001) Southern Hemisphere minke whales: standardised abundance estimates 1978/79 1997/98 IDCR-SOWER surveys. Journal Cetacean Research Management 3(2): 143-174 Hedley, S.L., S.T. Buckland. (2004) Spatial models line transect sampling. Journal Agricultural, Biological, Environmental Statistics 9: 181-199. doi:10.1198/1085711043578 .","code":""},{"path":"/reference/convert_units.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert units for abundance estimation — convert_units","title":"Convert units for abundance estimation — convert_units","text":"often case effort, distances prediction area collected different units field. Functions Distance allow argument convert provide answer makes sense. function calculates conversion factor, given knowledge units quantities used.","code":""},{"path":"/reference/convert_units.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert units for abundance estimation — convert_units","text":"","code":"convert_units(distance_units, effort_units, area_units)"},{"path":"/reference/convert_units.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert units for abundance estimation — convert_units","text":"distance_units units distances measured . effort_units units effort measured . Set NULL point transects. area_units units prediction area.","code":""},{"path":"/reference/convert_units.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert units for abundance estimation — convert_units","text":"convert_units expects particular names inputs -- singular names unit (e.g., \"metre\" rather \"metres\"). can view possible options units_table. UK US spellings acceptable, case matter. density estimation, area must still provided (\"objects per square ???\"). Note cue counts (multiplier-based methods) one still ensure rates correct units survey.","code":""},{"path":"/reference/convert_units.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert units for abundance estimation — convert_units","text":"David L Miller","code":""},{"path":"/reference/convert_units.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert units for abundance estimation — convert_units","text":"","code":"# distances measured in metres, effort in kilometres and # abundance over an area measured in hectares: convert_units(\"Metre\", \"Kilometre\", \"Hectare\") #> [1] 0.1  # all SI units, so the result is 1 convert_units(\"Metre\", \"metre\", \"square metre\") #> [1] 1  # for points ignore effort convert_units(\"Metre\", NULL, \"Hectare\") #> [1] 0.01"},{"path":"/reference/create.bins.html","id":null,"dir":"Reference","previous_headings":"","what":"Create bins from a set of binned distances and a set of cutpoints. — create.bins","title":"Create bins from a set of binned distances and a set of cutpoints. — create.bins","text":"create.bins now deprecated, please use create_bins","code":""},{"path":"/reference/create.bins.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create bins from a set of binned distances and a set of cutpoints. — create.bins","text":"","code":"create.bins(data, cutpoints)"},{"path":"/reference/create.bins.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create bins from a set of binned distances and a set of cutpoints. — create.bins","text":"data data.frame least column distance. cutpoints vector cutpoints bins","code":""},{"path":"/reference/create.bins.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create bins from a set of binned distances and a set of cutpoints. — create.bins","text":"argument data two extra columns distbegin distend.","code":""},{"path":"/reference/create.bins.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create bins from a set of binned distances and a set of cutpoints. — create.bins","text":"David L. Miller","code":""},{"path":"/reference/create_bins.html","id":null,"dir":"Reference","previous_headings":"","what":"Create bins from a set of binned distances and a set of cutpoints. — create_bins","title":"Create bins from a set of binned distances and a set of cutpoints. — create_bins","text":"internal routine necessary normal analyses.","code":""},{"path":"/reference/create_bins.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create bins from a set of binned distances and a set of cutpoints. — create_bins","text":"","code":"create_bins(data, cutpoints)"},{"path":"/reference/create_bins.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create bins from a set of binned distances and a set of cutpoints. — create_bins","text":"data data.frame least column distance. cutpoints vector cutpoints bins","code":""},{"path":"/reference/create_bins.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create bins from a set of binned distances and a set of cutpoints. — create_bins","text":"argument data two extra columns distbegin distend.","code":""},{"path":"/reference/create_bins.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create bins from a set of binned distances and a set of cutpoints. — create_bins","text":"David L. Miller","code":""},{"path":"/reference/create_bins.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create bins from a set of binned distances and a set of cutpoints. — create_bins","text":"","code":"if (FALSE) { library(Distance) data(minke)  # put the minke data into bins 0-1, 1-2, 2-3 km minke_cuts <- create_bins(minke[!is.na(minke$distance),], c(0,1,2,3)) }"},{"path":"/reference/CueCountingExample.html","id":null,"dir":"Reference","previous_headings":"","what":"Cue counts of whale blows — CueCountingExample","title":"Cue counts of whale blows — CueCountingExample","text":"Cues treated indirect count, requiring use multipliers.","code":""},{"path":"/reference/CueCountingExample.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Cue counts of whale blows — CueCountingExample","text":"data.frame 109 rows 15 variables. `Region.Label stratum labels Area size (km^2) stratum Sample.Label transect labels Cue.rate rate blows per animal per hour Cue.rate.SE variability cue rate Cue.rate.df degrees freedom (number animals sampled cues) object object ID distance perpendicular distance (km) Sample.Fraction proportion full circle scanned (radians) Sample.Fraction.SE variability sampling fraction (0) Search.time Duration scanning effort (hr) bss Beaufort sea state sp Species detected (observations W data) size Number animals group (1 data) Study.Area study area name","code":""},{"path":"/reference/CueCountingExample.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cue counts of whale blows — CueCountingExample","text":"whale blows disappear instantaneously, need measure decay rate. However cue production rate (blows per individual per unit time) required, measure variability rate.","code":""},{"path":"/reference/CueCountingExample.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Cue counts of whale blows — CueCountingExample","text":"two nuances survey.  Even though survey taking place moving ship, effort measured amount time scanning blows.  instances, possible observer scan sea around view may restricted ship's superstructure.  sampling fraction multiplier employed deal restricted vision.  Units measure cue.rate Search.time must equal.","code":""},{"path":"/reference/dht2.html","id":null,"dir":"Reference","previous_headings":"","what":"Abundance estimation for distance sampling models — dht2","title":"Abundance estimation for distance sampling models — dht2","text":"detection function fitted data, function can used compute abundance estimates required areas. function also allows stratification variance estimation via various schemes (see ).","code":""},{"path":"/reference/dht2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Abundance estimation for distance sampling models — dht2","text":"","code":"dht2(   ddf,   observations = NULL,   transects = NULL,   geo_strat = NULL,   flatfile = NULL,   strat_formula,   convert_units = 1,   er_est = c(\"R2\", \"P2\"),   multipliers = NULL,   sample_fraction = 1,   ci_width = 0.95,   innes = FALSE,   stratification = \"geographical\",   total_area = NULL,   binomial_var = FALSE )"},{"path":"/reference/dht2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Abundance estimation for distance sampling models — dht2","text":"ddf model fitted ds ddf. Multiple detection functions can supplied list. observations data.frame link detection function data (indexed object column IDs) transects (indexed Sample.Label column IDs). See \"Data\" . transects data.frame information samples (points line transects). See \"Data\" . geo_strat data.frame information geographical stratification. See \"Data\" . flatfile data flatfile format, see flatfile. Note object column (uniquely identifying observations) required. strat_formula formula giving stratification structure (see \"Stratification\" ). Currently one level stratification supported. convert_units conversion factor units distances, effort area. See \"Units\" . Can supply one per detection function ddf. er_est encounter rate variance estimator used. See \"Variance\" varn. Can supply one per detection function ddf. multipliers list data.frames. See \"Multipliers\" . sample_fraction proportion transect covered (e.g., 0.5 one-sided line transects). May specified either single number data.frame 2 columns Sample.Label fraction (fractions different transect). ci_width use confidence interval calculation (defined 1-alpha, default 95 give 95% confidence interval). innes logical flag computing encounter rate variance using either method Innes et al (2002) estimated abundance per transect divided effort used encounter rate, vs. (innes=FALSE) using number observations divided effort (Buckland et al., 2001) stratification strata represent, see \"Stratification\" . total_area options stratification=\"effort_sum\" stratification=\"replicate\" area use total combined, weighted final estimates. binomial_var wish estimate abundance covered area (.e., study area = surveyed area) must set TRUE use binomial variance estimator Borchers et al. (1998). valid objects clustered. (situation rare.)","code":""},{"path":"/reference/dht2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Abundance estimation for distance sampling models — dht2","text":"data.frame (class dht_result pretty printing) estimates attributes containing additional information, see \"Outputs\" information column names.","code":""},{"path":"/reference/dht2.html","id":"data","dir":"Reference","previous_headings":"","what":"Data","title":"Abundance estimation for distance sampling models — dht2","text":"data format allows complex stratification schemes set-. Three objects always required: ddf detection function (see ds ddf information format inputs). observations one row per observation links observations transects. Required columns: object (unique ID observation, must match data detection function) Sample.Label (unique ID transect). Additional columns strata included detection function required (stratification covariates included detection function need included ). important case group size, must column name size (need detection function). transects one row per sample (point line transect). least one row required. Required columns: Sample.Label (unique ID transect), Effort (line length line transects, number visits point transects), one geographical stratum. three arguments, abundance can calculated covered area. Including additional information area wish extrapolate (.e., study area), can obtain abundance estimates: geo_strat one row stratum wish estimate abundance . abundance study area, least one row required. Required columns: Area (area stratum). >1 row, additional columns, named strat_formula.` Note Area column set 0, density estimates returned.","code":""},{"path":"/reference/dht2.html","id":"multipliers","dir":"Reference","previous_headings":"","what":"Multipliers","title":"Abundance estimation for distance sampling models — dht2","text":"often case measure distances individuals groups directly, instead need estimate distances something produce (e.g., whales, blows; elephants dung) -- referred indirect sampling. may need use estimates production rate decay rate estimates (case dung nests) just production rates (case songbird calls whale blows). refer conversions \"number cues\" \"number animals\" \"multipliers\". multipliers argument list, 2 possible elements (creation decay). element data.frame must least column named rate, abundance estimates divided (term \"multiplier\" misnomer, kept compatibility Distance Windows). Additional columns can added give standard error degrees freedom rate known SE df, respectively. can use multirow data.frame different rates different geographical areas (example). case rows need column (columns) merge data (example Region.Label).","code":""},{"path":"/reference/dht2.html","id":"stratification","dir":"Reference","previous_headings":"","what":"Stratification","title":"Abundance estimation for distance sampling models — dht2","text":"strat_formula argument used specify column use stratify results, using form ~column.name column.name column name wish use. stratification argument used specify four types stratification intended: \"geographical\" stratum represents different geographical areas want total areas \"effort_sum\" strata fact replicate surveys (perhaps using different designs) many replicates /want estimate \"average variance\" \"replicate\" replicate surveys many , calculates average abundance variance many surveys (think population surveys) \"object\" stratification really type object observed, example sex, species life stage want total number individuals across classes objects. example, stratified sex males females, also want total number animals, use option. simple example using stratification=\"geographical\" given . examples can found http://examples.distancesampling.org/ (see, e.g., deer pellet survey).","code":""},{"path":"/reference/dht2.html","id":"variance","dir":"Reference","previous_headings":"","what":"Variance","title":"Abundance estimation for distance sampling models — dht2","text":"Variance estimated abundance comes multiple sources. Depending data used fit model estimate abundance, different components included estimated variances. simplest case, detection function encounter rate variance need combined. group size varies, must included. Finally, multipliers used corresponding standard errors given, also included. Variances combined assuming independence measures adding variances. brief summary component calculated given , though see references details. detection function: variance detection function parameters transformed variance abundance via sandwich estimator (see e.g., Appendix C Borchers et al (2002)). encounter rate: strata >1 transect , encounter rate estimators given Fewster et al (2009) can specified via er_est argument. argument innes=TRUE calculations use estimated number individuals transect (rather observed), give Innes et al (2002) superior estimator. one transect stratum, Poisson variance assumed. Information Fewster encounter rate variance estimators given varn group size: objects occur groups (sometimes \"clusters\"), empirical variance group sizes added total variance. multipliers: multipliers standard errors given, corresponding variances added. standard errors supplied, contribution variance assumed 0.","code":""},{"path":"/reference/dht2.html","id":"units","dir":"Reference","previous_headings":"","what":"Units","title":"Abundance estimation for distance sampling models — dht2","text":"often case distances recorded one convenient set units, whereas study area effort recorded units. ensure results function expected units, use convert_units argument supply single number convert units covered area study/stratification area (results always returned units study area). line transects, covered area calculated 2 * width * length width effective (half)width transect (often referred w literature) length line length (referred L). width length measured kilometres study area square kilometres, fine convert_units 1 (can ignored). , example, line length distances measured metres, instead need convert kilometres, dividing 1000 distance length, hence convert_units=1e-6. point transects, slightly easier radius study area consider, conversion just units truncation radius square root study area units.","code":""},{"path":"/reference/dht2.html","id":"output","dir":"Reference","previous_headings":"","what":"Output","title":"Abundance estimation for distance sampling models — dht2","text":"printing output call dht2, three tables produced. guide output columns names, per table. Summary statistics table Region.Label Stratum name (first column name depends formula supplied) Area Size stratum CoveredArea Surveyed area stratum (2 x w x L) Effort Transect length number point visits per stratum n Number detections k Number replicate transects ER Encounter rate se.ER Standard error encounter rate cv.ER Coefficient variation encounter rate Abundance density estimates table: Region.Label Estimate Point estimate abundance density se Standard error cv Coefficient variation LCI Lower confidence bound UCI Upper confidence bound df Degrees freedom used confidence interval computation Components percentage variance: Region.Label Detection Percent variance abundance/density associated detection function uncertainty ER Percent variance abundance/density associated variability encounter rate Multipliers Percent variance abundance/density associated uncertainty multipliers","code":""},{"path":"/reference/dht2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Abundance estimation for distance sampling models — dht2","text":"Borchers, D.L., S.T. Buckland, P.W. Goedhart, E.D. Clarke, S.L. Hedley. 1998. Horvitz-Thompson estimators double-platform line transect surveys. Biometrics 54: 1221-1237. Borchers, D.L., S.T. Buckland, W. Zucchini. 2002 Estimating Animal Abundance: Closed Populations. Statistics Biology Health. Springer London. Buckland, S.T., E.. Rexstad, T.. Marques, C.S. Oedekoven. 2015 Distance Sampling: Methods Applications. Methods Statistical Ecology. Springer International Publishing. Buckland, S.T., D.R. Anderson, K. Burnham, J.L. Laake, D.L. Borchers, L. Thomas. 2001 Introduction Distance Sampling: Estimating Abundance Biological Populations. Oxford University Press. Innes, S., M. P. Heide-Jorgensen, J.L. Laake, K.L. Laidre, H.J. Cleator, P. Richard, R.E.. Stewart. 2002 Surveys belugas narwhals Canadian high arctic 1996. NAMMCO Scientific Publications 4, 169-190.","code":""},{"path":"/reference/dht2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Abundance estimation for distance sampling models — dht2","text":"","code":"if (FALSE) { # example of simple geographical stratification # minke whale data, with 2 strata: North and South data(minke) # first fitting the detection function minke_df <- ds(minke, truncation=1.5, adjustment=NULL) # now estimate abundance using dht2 # stratum labels are in the Region.Label column minke_dht2 <- dht2(minke_df, flatfile=minke, stratification=\"geographical\",                    strat_formula=~Region.Label) # could compare this to minke_df$dht and see the same results minke_dht2 # can alternatively report density print(minke_dht2, report=\"density\") }"},{"path":"/reference/Distance-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Distance sampling — Distance-package","title":"Distance sampling — Distance-package","text":"Distance simple way fit detection functions estimate abundance using distance sampling methodology.","code":""},{"path":"/reference/Distance-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Distance sampling — Distance-package","text":"Underlying Distance package mrds, advanced analyses (involving double observer surveys) one may find necessary use mrds. Examples distance sampling analyses available http://examples.distancesampling.org/. help distance sampling package, Google Group https://groups.google.com/forum/#!forum/distance-sampling.","code":""},{"path":"/reference/Distance-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Distance sampling — Distance-package","text":"Key References: Miller D.L., E. Rexstad, L. Thomas, L. Marshall J.L. Laake. 2019. Distance Sampling R. Journal Statistical Software, 89(1), 1-28. doi:10.18637/jss.v089.i01 Background References: Laake, J.L. D.L. Borchers. 2004. Methods incomplete detection distance zero. : Advanced Distance Sampling, eds. S.T. Buckland, D.R.Anderson, K.P. Burnham, J.L. Laake, D.L. Borchers, L. Thomas. Oxford University Press. Marques, F.F.C. S.T. Buckland. 2004. Covariate models detection function. : Advanced Distance Sampling, eds. S.T. Buckland, D.R.Anderson, K.P. Burnham, J.L. Laake, D.L. Borchers, L. Thomas. Oxford University Press.","code":""},{"path":"/reference/Distance-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Distance sampling — Distance-package","text":"David L. Miller dave@ninepointeightone.net","code":""},{"path":"/reference/ds.gof.html","id":null,"dir":"Reference","previous_headings":"","what":"Goodness of fit tests for distance sampling models — ds.gof","title":"Goodness of fit tests for distance sampling models — ds.gof","text":"function deprecated, please see gof_ds.","code":""},{"path":"/reference/ds.gof.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Goodness of fit tests for distance sampling models — ds.gof","text":"","code":"ds.gof(model, breaks = NULL, nc = NULL, qq = TRUE, ks = FALSE, ...)"},{"path":"/reference/ds.gof.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Goodness of fit tests for distance sampling models — ds.gof","text":"model deprecated. breaks deprecated. nc deprecated. qq deprecated. ks deprecated. ... deprecated.","code":""},{"path":"/reference/ds.gof.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Goodness of fit tests for distance sampling models — ds.gof","text":"Nothing, deprecated.","code":""},{"path":[]},{"path":"/reference/ds.gof.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Goodness of fit tests for distance sampling models — ds.gof","text":"David L Miller","code":""},{"path":"/reference/ds.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit detection functions and calculate abundance from line or point transect data — ds","title":"Fit detection functions and calculate abundance from line or point transect data — ds","text":"function fits detection functions line point transect data (provided survey information supplied) calculates abundance density estimates. examples illustrate basic types analysis using ds().","code":""},{"path":"/reference/ds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit detection functions and calculate abundance from line or point transect data — ds","text":"","code":"ds(   data,   truncation = ifelse(is.null(cutpoints), ifelse(is.null(data$distend),     max(data$distance), max(data$distend)), max(cutpoints)),   transect = \"line\",   formula = ~1,   key = c(\"hn\", \"hr\", \"unif\"),   adjustment = c(\"cos\", \"herm\", \"poly\"),   nadj = NULL,   order = NULL,   scale = c(\"width\", \"scale\"),   cutpoints = NULL,   dht_group = FALSE,   monotonicity = ifelse(formula == ~1, \"strict\", \"none\"),   region_table = NULL,   sample_table = NULL,   obs_table = NULL,   convert_units = 1,   er_var = ifelse(transect == \"line\", \"R2\", \"P2\"),   method = \"nlminb\",   quiet = FALSE,   debug_level = 0,   initial_values = NULL,   max_adjustments = 5,   er_method = 2,   dht_se = TRUE,   optimizer = \"both\",   winebin = NULL,   dht.group,   region.table,   sample.table,   obs.table,   convert.units,   er.var,   debug.level,   initial.values,   max.adjustments )"},{"path":"/reference/ds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit detection functions and calculate abundance from line or point transect data — ds","text":"data data.frame containing least column called distance numeric vector containing distances.  NOTE!  column called size data interpreted group/cluster size, see section \"Clusters/groups\", . One can supply data \"flat file\" supply region_table, sample_table obs_table, see \"Data format\", flatfile. truncation either truncation distance (numeric, e.g. 5) percentage (string, e.g. \"15%\"). Can supplied list elements left right left truncation required (e.g.  list(left=1,right=20) list(left=\"1%\",right=\"15%\") even list(left=\"1\",right=\"15%\")).  default exact distances maximum observed distance used right truncation. data binned, right truncation largest bin end point. Default left truncation set zero. transect indicates transect type \"line\" (default) \"point\". formula formula scale parameter. CDS analysis leave default ~1. key key function use; \"hn\" gives half-normal (default), \"hr\" gives hazard-rate \"unif\" gives uniform. Note uniform key used, covariates included model. adjustment adjustment terms use; \"cos\" gives cosine (default), \"herm\" gives Hermite polynomial \"poly\" gives simple polynomial. value NULL indicates adjustments fitted. nadj number adjustment terms fit. absence covariates formula, default value (NULL) select via AIC (using sequential forward selection algorithm) max.adjustment adjustments (unless order specified). covariates present model formula, default value NULL results adjustment terms fitted model. non-negative integer value cause specified number adjustments fitted. Supplying integer value allow use adjustment terms addition specifying covariates model. order adjustment terms used depend keyand adjustment. key=\"unif\", adjustments order 1, 2, 3, ... fitted adjustment = \"cos\" order 2, 4, 6, ... otherwise. key=\"hn\" \"hr\" adjustments order 2, 3, 4, ... fitted adjustment = \"cos\" order 4, 6, 8, ... otherwise. See Buckland et al. (2001, p. 47) details. order order adjustment terms fit. default value (NULL) results ds choosing orders use - see nadj. Otherwise scalar positive integer value can used fit single adjustment term specified order, vector positive integers fit multiple adjustment terms specified orders. simple Hermite polynomial adjustments, even orders allowed. number adjustment terms specified must match nadj (nadj can default NULL value). scale scale distances adjustment terms divided. Defaults \"width\", scaling truncation distance. key uniform \"width\" used. option \"scale\": scale parameter detection cutpoints data binned, vector gives cutpoints bins. Supplying distance column data specifying cutpoints recommended approach standard binned analyses. Ensure first element 0 (left truncation distance) last distance end furthest bin. (Default NULL, binning.) provided distbegin distend columns data (note used cutpoints constant across data, e.g. planes flying differing altitudes) specify cutpoints argument cause distbegin distend columns data overwritten. dht_group density abundance estimates consider groups size 1 (abundance groups) dht_group=TRUE abundance individuals (group size taken account), dht_group=FALSE. Default FALSE (abundance individuals calculated). monotonicity detection function constrained monotonicity weakly (\"weak\"), strictly (\"strict\") (\"none\" FALSE). See Monotonicity, . (Default \"strict\"). default models without covariates detection function, covariates present. region_table data_frame two columns: Region.Label label region Area area region region_table one row stratum. stratification region_table one entry Area corresponding total survey area. Area omitted density estimates produced. sample_table data.frame mapping regions samples (.e. transects). three columns: Sample.Label label sample Region.Label label region sample belongs . Effort effort expended sample (e.g. transect length). obs_table data.frame mapping individual observations (objects) regions samples. three columns: object unique numeric identifier observation Region.Label label region sample belongs Sample.Label label sample convert_units conversion units abundance estimation, see \"Units\", . (Defaults 1, implying units \"correct\" already.) er_var encounter rate variance estimator use abundance estimates required. Defaults \"R2\" line transects \"P2\" point transects (>= 1.0.9, earlier versions <= 1.0.8 used \"P3\" estimator default points). See dht2 information complex options required. method optimization method use (method usable optim optimx). Defaults \"nlminb\". quiet suppress non-essential messages (useful bootstraps etc). Default value FALSE. debug_level print debugging output. 0=none, 1-3 increasing levels debugging output. initial_values list named starting values, see mrds_opt. allowed AIC term selection used. max_adjustments maximum number adjustments try (default 5) used order=NULL. er_method encounter rate variance calculation: default = 2 gives method Innes et al, using expected counts encounter rate. Setting 1 gives observed counts (matches Distance Windows) 0 uses binomial variance (useful rare situation study area = surveyed area). See dht.se details. dht_se uncertainty calculated using dht? Safe leave TRUE, used bootdht. optimizer default set ''. case R optimizer used present MCDS optimizer also used. result best likelihood value selected. run specified optimizer set value either 'R' 'MCDS'. See mcds_dot_exe setup instructions. winebin trying use MCDS.exe optimizer non-windows system may need specify winebin. Please see mcds_dot_exe details. dht.group deprecated, see argument underscore, . region.table deprecated, see argument underscore, . sample.table deprecated, see argument underscore, . obs.table deprecated, see argument underscore, . convert.units deprecated, see argument underscore, . er.var deprecated, see argument underscore, . debug.level deprecated, see argument underscore, . initial.values deprecated, see argument underscore, . max.adjustments deprecated, see argument underscore, .","code":""},{"path":"/reference/ds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit detection functions and calculate abundance from line or point transect data — ds","text":"list elements: ddf detection function model object. dht abundance/density information (survey region data supplied, else NULL)","code":""},{"path":"/reference/ds.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit detection functions and calculate abundance from line or point transect data — ds","text":"abundance estimates required data.frames region_table sample_table must supplied. data contain columns Region.Label Sample.Label data.frame obs_table must also supplied. Note stratification applies abundance estimates detection function level. Density abundance estimates, corresponding estimates variance confidence intervals, calculated using methods described Buckland et al. (2001) sections 3.6.1 3.7.1 (details can found documentation dht). advanced abundance/density estimation please see dht dht2 functions. Examples distance sampling analyses available http://examples.distancesampling.org/. Hints tips fitting (particularly optimisation issues) mrds_opt manual page.","code":""},{"path":"/reference/ds.html","id":"clusters-groups","dir":"Reference","previous_headings":"","what":"Clusters/groups","title":"Fit detection functions and calculate abundance from line or point transect data — ds","text":"Note data contains column named size, cluster size estimated density/abundance based clustered analysis data. Setting column NULL perform non-clustered analysis (example \"size\" means something else dataset).","code":""},{"path":"/reference/ds.html","id":"truncation","dir":"Reference","previous_headings":"","what":"Truncation","title":"Fit detection functions and calculate abundance from line or point transect data — ds","text":"right truncation point default set largest observed distance bin end point. default appropriate data can often cause model convergence failures. recommended one plots histogram observed distances prior model fitting get feel appropriate truncation distance. (Similar arguments go left truncation, appropriate). Buckland et al (2001) provide guidelines truncation. specified percentage, largest right smallest left percent distances discarded. Percentages supplied using binned data. left truncation, two options: (1) fit detection function truncated data (happens set left).  assume g(x)=1 truncation point. (2) manually remove data distances less left truncation distance -- effectively move centre line truncation distance (needs done calling ds). assumes detection certain left truncation distance. former strategy weaker assumption, give higher variance detection function close line data tell fit -- relying data left truncation point assumed shape detection function. latter appropriate case aerial surveys, area plane visible observers, probability detection certain smallest distance.","code":""},{"path":"/reference/ds.html","id":"binning","dir":"Reference","previous_headings":"","what":"Binning","title":"Fit detection functions and calculate abundance from line or point transect data — ds","text":"Note binning performed bin 1 distances greater equal cutpoint 1 (>=0 left truncation distance) less cutpoint 2. Bin 2 distances greater equal cutpoint 2 less cutpoint 3 .","code":""},{"path":"/reference/ds.html","id":"monotonicity","dir":"Reference","previous_headings":"","what":"Monotonicity","title":"Fit detection functions and calculate abundance from line or point transect data — ds","text":"adjustment terms used, possible detection function always decrease increasing distance. unrealistic can lead bias. avoid , detection function can constrained monotonicity (default detection functions without covariates). Monotonicity constraints supported similar way described Buckland et al (2001). 20 equally spaced points range detection function (left right truncation) evaluated round optimisation function constrained either always less value zero (\"weak\") value less equal previous point (monotonically decreasing; \"strict\"). See also check.mono. Even monotonicity constraints, checks still made detection function monotonic, see check.mono.","code":""},{"path":"/reference/ds.html","id":"units","dir":"Reference","previous_headings":"","what":"Units","title":"Fit detection functions and calculate abundance from line or point transect data — ds","text":"extrapolating entire survey region important unit measurements consistent converted consistency. conversion factor can specified convert_units argument. values Area region_table, must made consistent units Effort sample_table units distance data.frame analyzed. easiest units Area square units Effort necessary convert units distance units Effort. example, Effort entered kilometres Area square kilometres distance metres using convert_units=0.001 convert metres kilometres, density expressed square kilometres consistent units Area. However, can different units long appropriate composite value convert_units chosen. Abundance survey region can expressed : *N/Area survey region, N abundance covered (sampled) region, area sampled region units Effort * distance. sampled region multiplied convert_units, chosen result units Area.  example, Effort entered kilometres, Area hectares (100m x 100m) distance metres, using convert_units=10 convert units hectares (100 convert metres 100 metres distance .1 convert km 100m units).","code":""},{"path":"/reference/ds.html","id":"data-format","dir":"Reference","previous_headings":"","what":"Data format","title":"Fit detection functions and calculate abundance from line or point transect data — ds","text":"One can supply data simply fit detection function. However, abundance/density estimates necessary information required. Either region_table, sample_table obs_table data.frames can supplied data can supplied \"flat file\" data argument. format row data additional information ordinarily tables. usually means additional columns named: Sample.Label, Region.Label, Effort Area observation. See flatfile example.","code":""},{"path":"/reference/ds.html","id":"density-estimation","dir":"Reference","previous_headings":"","what":"Density estimation","title":"Fit detection functions and calculate abundance from line or point transect data — ds","text":"column Area omitted, density estimate generated note degrees freedom/standard errors/confidence intervals match density estimates made Area column present.","code":""},{"path":"/reference/ds.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit detection functions and calculate abundance from line or point transect data — ds","text":"Buckland, S.T., Anderson, D.R., Burnham, K.P., Laake, J.L., Borchers, D.L., Thomas, L. (2001). Distance Sampling. Oxford University Press. Oxford, UK. Buckland, S.T., Anderson, D.R., Burnham, K.P., Laake, J.L., Borchers, D.L., Thomas, L. (2004). Advanced Distance Sampling. Oxford University Press. Oxford, UK.","code":""},{"path":[]},{"path":"/reference/ds.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fit detection functions and calculate abundance from line or point transect data — ds","text":"David L. Miller","code":""},{"path":"/reference/ds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit detection functions and calculate abundance from line or point transect data — ds","text":"","code":"# An example from mrds, the golf tee data. library(Distance) data(book.tee.data) tee.data <- subset(book.tee.data$book.tee.dataframe, observer==1) ds.model <- ds(tee.data, 4) #> Starting AIC adjustment term selection. #> Fitting half-normal key function #> AIC= 311.138 #> Fitting half-normal key function with cosine(2) adjustments #> AIC= 313.124 #>  #> Half-normal key function selected. #> No survey area information supplied, only estimating detection function. summary(ds.model) #>  #> Summary for distance analysis  #> Number of observations :  124  #> Distance range         :  0  -  4  #>  #> Model       : Half-normal key function  #> AIC         :  311.1385  #> Optimisation:  mrds (nlminb)  #>  #> Detection function parameters #> Scale coefficient(s):   #>              estimate         se #> (Intercept) 0.6632435 0.09981249 #>  #>                        Estimate          SE         CV #> Average p             0.5842744  0.04637627 0.07937412 #> N in covered region 212.2290462 20.85130344 0.09824906 plot(ds.model)   # same model, but calculating abundance # need to supply the region, sample and observation tables region <- book.tee.data$book.tee.region samples <- book.tee.data$book.tee.samples obs <- book.tee.data$book.tee.obs  ds.dht.model <- ds(tee.data, 4, region_table=region,                    sample_table=samples, obs_table=obs) #> Starting AIC adjustment term selection. #> Fitting half-normal key function #> AIC= 311.138 #> Fitting half-normal key function with cosine(2) adjustments #> AIC= 313.124 #>  #> Half-normal key function selected. summary(ds.dht.model) #>  #> Summary for distance analysis  #> Number of observations :  124  #> Distance range         :  0  -  4  #>  #> Model       : Half-normal key function  #> AIC         :  311.1385  #> Optimisation:  mrds (nlminb)  #>  #> Detection function parameters #> Scale coefficient(s):   #>              estimate         se #> (Intercept) 0.6632435 0.09981249 #>  #>                        Estimate          SE         CV #> Average p             0.5842744  0.04637627 0.07937412 #> N in covered region 212.2290462 20.85130344 0.09824906 #>  #> Summary for clusters #>  #> Summary statistics: #>   Region Area CoveredArea Effort   n  k        ER      se.ER      cv.ER #> 1      1 1040        1040    130  72  6 0.5538462 0.02926903 0.05284685 #> 2      2  640         640     80  52  5 0.6500000 0.08292740 0.12758061 #> 3  Total 1680        1680    210 124 11 0.5904762 0.03641856 0.06167659 #>  #> Abundance: #>   Label  Estimate       se         cv       lcl      ucl        df #> 1     1 123.22977 11.75088 0.09535744 101.72724 149.2774 43.918771 #> 2     2  88.99928 13.37273 0.15025666  62.88926 125.9495  7.658528 #> 3 Total 212.22905 21.33324 0.10051991 173.30068 259.9019 40.063051 #>  #> Density: #>   Label  Estimate         se         cv        lcl       ucl        df #> 1     1 0.1184902 0.01129892 0.09535744 0.09781465 0.1435359 43.918771 #> 2     2 0.1390614 0.02089490 0.15025666 0.09826447 0.1967961  7.658528 #> 3 Total 0.1263268 0.01269836 0.10051991 0.10315517 0.1547035 40.063051 #>  #> Summary for individuals #>  #> Summary statistics: #>   Region Area CoveredArea Effort   n  k       ER     se.ER      cv.ER mean.size #> 1      1 1040        1040    130 229  6 1.761538 0.1165805 0.06618107  3.180556 #> 2      2  640         640     80 152  5 1.900000 0.3342319 0.17591151  2.923077 #> 3  Total 1680        1680    210 381 11 1.814286 0.1463570 0.08066920  3.072581 #>     se.mean #> 1 0.2086982 #> 2 0.2261991 #> 3 0.1537082 #>  #> Abundance: #>   Label Estimate       se        cv      lcl      ucl        df #> 1     1 391.9391 40.50494 0.1033450 317.2772 484.1706 27.423274 #> 2     2 260.1517 50.20666 0.1929899 162.2494 417.1289  5.786773 #> 3 Total 652.0909 73.79805 0.1131714 516.5938 823.1274 23.815556 #>  #> Density: #>   Label  Estimate         se        cv       lcl       ucl        df #> 1     1 0.3768645 0.03894706 0.1033450 0.3050742 0.4655487 27.423274 #> 2     2 0.4064871 0.07844791 0.1929899 0.2535147 0.6517639  5.786773 #> 3 Total 0.3881493 0.04392741 0.1131714 0.3074963 0.4899568 23.815556 #>  #> Expected cluster size #>   Region Expected.S se.Expected.S cv.Expected.S #> 1      1   3.180556     0.2114629    0.06648615 #> 2      2   2.923077     0.1750319    0.05987935 #> 3  Total   3.072581     0.1391365    0.04528327  # specify order 2 cosine adjustments ds.model.cos2 <- ds(tee.data, 4, adjustment=\"cos\", order=2) #> Fitting half-normal key function with cosine(2) adjustments #> AIC= 313.124 #> No survey area information supplied, only estimating detection function. summary(ds.model.cos2) #>  #> Summary for distance analysis  #> Number of observations :  124  #> Distance range         :  0  -  4  #>  #> Model       : Half-normal key function with cosine adjustment term of order 2  #>  #> Strict monotonicity constraints were enforced. #> AIC         :  313.1239  #> Optimisation:  mrds (nlminb)  #>  #> Detection function parameters #> Scale coefficient(s):   #>              estimate        se #> (Intercept) 0.6606853 0.1043341 #>  #> Adjustment term coefficient(s):   #>                 estimate        se #> cos, order 2 -0.01592331 0.1351282 #>  #>                        Estimate          SE        CV #> Average p             0.5925833  0.08165072 0.1377878 #> N in covered region 209.2532912 31.22791390 0.1492350  # specify order 2 and 3 cosine adjustments, turning monotonicity # constraints off ds.model.cos23 <- ds(tee.data, 4, adjustment=\"cos\", order=c(2, 3),                    monotonicity=FALSE) #> Fitting half-normal key function with cosine(2,3) adjustments #> AIC= 314.26 #> No survey area information supplied, only estimating detection function. # check for non-monotonicity -- actually no problems check.mono(ds.model.cos23$ddf, plot=TRUE, n.pts=100)  #> [1] TRUE  # include both a covariate and adjustment terms in the model ds.model.cos2.sex <- ds(tee.data, 4, adjustment=\"cos\", order=2,                         monotonicity=FALSE, formula=~as.factor(sex)) #> Fitting half-normal key function with cosine(2) adjustments #> Warning: Detection function is not weakly monotonic! #> Warning: Detection function is not strictly monotonic! #> Warning: Detection function is greater than 1 at some distances #> Warning: Detection function is not weakly monotonic! #> Warning: Detection function is not strictly monotonic! #> Warning: Detection function is greater than 1 at some distances #> AIC= 306.019 #> Warning: Detection function is not weakly monotonic! #> Warning: Detection function is not strictly monotonic! #> Warning: Detection function is greater than 1 at some distances #> No survey area information supplied, only estimating detection function. # check for non-monotonicity -- actually no problems check.mono(ds.model.cos2.sex$ddf, plot=TRUE, n.pts=100) #> Warning: Detection function is not weakly monotonic! #> Warning: Detection function is not strictly monotonic! #> Warning: Detection function is greater than 1 at some distances  #> [1] FALSE  # truncate the largest 10% of the data and fit only a hazard-rate # detection function ds.model.hr.trunc <- ds(tee.data, truncation=\"10%\", key=\"hr\",                         adjustment=NULL) #> Fitting hazard-rate key function #> Warning: Estimated hazard-rate scale parameter close to 0 (on log scale). Possible problem in data (e.g., spike near zero distance). #> Warning: Estimated hazard-rate scale parameter close to 0 (on log scale). Possible problem in data (e.g., spike near zero distance). #> AIC= 260.267 #> Warning: Estimated hazard-rate scale parameter close to 0 (on log scale). Possible problem in data (e.g., spike near zero distance). #> No survey area information supplied, only estimating detection function. summary(ds.model.hr.trunc) #>  #> Summary for distance analysis  #> Number of observations :  117  #> Distance range         :  0  -  3.104  #>  #> Model       : Hazard-rate key function  #> AIC         :  260.2669  #> Optimisation:  mrds (nlminb)  #>  #> Detection function parameters #> Scale coefficient(s):   #>              estimate        se #> (Intercept) 0.5240633 0.4245238 #>  #> Shape coefficient(s):   #>             estimate       se #> (Intercept)        0 0.594522 #>  #>                        Estimate         SE        CV #> Average p             0.6969118  0.1182424 0.1696662 #> N in covered region 167.8835155 29.7381876 0.1771358  # compare AICs between these models: AIC(ds.model) #>          df      AIC #> ds.model  1 311.1385 AIC(ds.model.cos2) #>               df      AIC #> ds.model.cos2  2 313.1239 AIC(ds.model.cos23) #>                df      AIC #> ds.model.cos23  3 314.2601"},{"path":"/reference/ducknest.html","id":null,"dir":"Reference","previous_headings":"","what":"Ducknest line transect survey data — ducknest","title":"Ducknest line transect survey data — ducknest","text":"Simulated line transect survey duck nests, designed reproduce data Figure 2 Anderson Pospahala (1970).","code":""},{"path":"/reference/ducknest.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Ducknest line transect survey data — ducknest","text":"data.frame 534 rows 7 variables Region.Label strata names (single stratum instance) Area size refuge (0 case, actual size 60km^2) Sample.Label transect ID Effort length transects (km) object nest ID distance perpendicular distance (m) Study.Area name wildlife refuge","code":""},{"path":"/reference/ducknest.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Ducknest line transect survey data — ducknest","text":"Simulated data, distance sampling introductory course, Centre Research Ecological & Environmental Modelling, University St Andrews.","code":""},{"path":"/reference/ducknest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ducknest line transect survey data — ducknest","text":"Monte Vista National Wildlife Refuge southern Colorado USA altitude roughly 2400m.","code":""},{"path":"/reference/ducknest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Ducknest line transect survey data — ducknest","text":"Anderson, D. R., R. S. Pospahala. 1970. Correction bias belt transect studies immotile objects. Journal Wildlife Management 34 (1): 141–146. doi:10.2307/3799501","code":""},{"path":"/reference/DuikerCameraTraps.html","id":null,"dir":"Reference","previous_headings":"","what":"Duiker camera trap survey — DuikerCameraTraps","title":"Duiker camera trap survey — DuikerCameraTraps","text":"Study took place Tai National Park Cote d'Ivoire 2014.  Filmed Maxwell's duikers (Philantomba maxwellii) assigned distance intervals; recorded distances midpoints intervals. data includes observations recorded times peak activity.","code":""},{"path":"/reference/DuikerCameraTraps.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Duiker camera trap survey — DuikerCameraTraps","text":"data.frame 6277 rows 6 variables Region.Label  strata names (single stratum) Area  size study area (40.37 km^2) multiplier  spatial effort, proportion circle covered angle view camera (42 degrees cameras) Sample.Label  camera station identifier (21 functioning cameras data set) Effort  temporal effort, .e. number 2-second time-steps camera operated object unique object ID distance  radial distance (m) interval midpoint","code":""},{"path":"/reference/DuikerCameraTraps.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Duiker camera trap survey — DuikerCameraTraps","text":"Howe, E.J., Buckland, S.T., Després-Einspenner, M.-L. Kühl, H.S. (2017), Distance sampling camera traps. Methods Ecol Evol, 8: 1558-1565. doi:10.1111/2041-210X.12790 Howe, Eric J. et al. (2018), Data : Distance sampling camera traps, Dryad, Dataset, doi:10.5061/dryad.b4c70","code":""},{"path":"/reference/dummy_ddf.html","id":null,"dir":"Reference","previous_headings":"","what":"Detection function objects when detection is certain — dummy_ddf","title":"Detection function objects when detection is certain — dummy_ddf","text":"Create detection function object strip/plot surveys use dht2.","code":""},{"path":"/reference/dummy_ddf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detection function objects when detection is certain — dummy_ddf","text":"","code":"dummy_ddf(data, width, left = 0, transect = \"line\")"},{"path":"/reference/dummy_ddf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detection function objects when detection is certain — dummy_ddf","text":"data specified ds ddf (including size column) width right truncation left left truncation (default 0, left truncation) transect \"line\" \"point\" transect","code":""},{"path":"/reference/dummy_ddf.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Detection function objects when detection is certain — dummy_ddf","text":"David L Miller","code":""},{"path":"/reference/ETP_Dolphin.html","id":null,"dir":"Reference","previous_headings":"","what":"Eastern Tropical Pacific spotted dolphin survey — ETP_Dolphin","title":"Eastern Tropical Pacific spotted dolphin survey — ETP_Dolphin","text":"Observers aboard tuna vessels detecting dolphin schools along number possibly useful covariates modelling detection function.","code":""},{"path":"/reference/ETP_Dolphin.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Eastern Tropical Pacific spotted dolphin survey — ETP_Dolphin","text":"data.frame 1090 rows 13 variables: Region.Label stratum labels (one) Area size (nmi) stratum Sample.Label transect labels Effort transect length (nmi) object object ID distance perpendicular distance (nmi) LnCluster natural log cluster size Month month detection Beauf.class Beaufort sea state Cue.type initial cue triggering detection Search.method observer method making detection size cluster size Study.Area study area name","code":""},{"path":"/reference/ETP_Dolphin.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Eastern Tropical Pacific spotted dolphin survey — ETP_Dolphin","text":"Inter-American Tropical Tuna Commission","code":""},{"path":"/reference/ETP_Dolphin.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Eastern Tropical Pacific spotted dolphin survey — ETP_Dolphin","text":"Several different search methods included data 0 binoculars crows nest 2 binoculars elsewhere ship 3 helicopter searching ahead ship 5 radar detects seabirds dolphin schools Several cue types also recorded observers. 1 seabirds school 2 water splashes 3 unspecified 4 floating objects logs","code":""},{"path":"/reference/flatfile.html","id":null,"dir":"Reference","previous_headings":"","what":"The flatfile data format — flatfile","title":"The flatfile data format — flatfile","text":"Distance allows loading data \"flat file\" analyse data (obtain abundance estimates) straight away, provided format flat file correct. One can provide file , example, Excel spreadsheet using readxl::read_xls CSV using read.csv.","code":""},{"path":"/reference/flatfile.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The flatfile data format — flatfile","text":"row data table corresponds either: (1) observation (2) sample (transect) without observations. either case following columns must present: distance observed distance object object unique identifier observation (required using dht2) Sample.Label identifier sample (transect id) Effort effort transect (e.g. line transect length number times point transect visited) Region.Label label given stratum (see ) Area area strataWhen row represents transect without observations,distanceand observation-specific covariates (includingsizeand detection function covariates) take valueNA`. Note simplest case (one area surveyed ) one Region.Label single corresponding Area duplicated observation. example given provided Eric Rexstad. Additional examples can found  http://examples.distancesampling.org/.","code":""},{"path":"/reference/flatfile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The flatfile data format — flatfile","text":"","code":"if (FALSE) { library(Distance) # Need to have the readxl package installed from CRAN require(readxl)  # Need to get the file path first minke.filepath <- system.file(\"minke.xlsx\", package=\"Distance\")  # Load the Excel file, note that col_names=FALSE and we add column names after minke <- read_xlsx(minke.filepath, col_names=FALSE) names(minke) <- c(\"Region.Label\", \"Area\", \"Sample.Label\", \"Effort\",                   \"distance\") # One may want to call edit(minke) or head(minke) at this point # to examine the data format  ## perform an analysis using the exact distances pooled.exact <- ds(minke, truncation=1.5, key=\"hr\", order=0) summary(pooled.exact)   ## Try a binned analysis # first define the bins dist.bins <- c(0,.214, .428,.643,.857,1.071,1.286,1.5) pooled.binned <- ds(minke, truncation=1.5, cutpoints=dist.bins, key=\"hr\",                     order=0)  # binned with stratum as a covariate minke$stratum <- ifelse(minke$Region.Label==\"North\", \"N\", \"S\") strat.covar.binned <- ds(minke, truncation=1.5, key=\"hr\",                          formula=~as.factor(stratum), cutpoints=dist.bins)  # Stratified by North/South full.strat.binned.North <- ds(minke[minke$Region.Label==\"North\",],                   truncation=1.5, key=\"hr\", order=0, cutpoints=dist.bins) full.strat.binned.South <- ds(minke[minke$Region.Label==\"South\",],                      truncation=1.5, key=\"hr\", order=0, cutpoints=dist.bins)  ## model summaries model.sel.bin <- data.frame(name=c(\"Pooled f(0)\", \"Stratum covariate\",                                    \"Full stratification\"),                             aic=c(pooled.binned$ddf$criterion,                                   strat.covar.binned$ddf$criterion,                                   full.strat.binned.North$ddf$criterion+                                   full.strat.binned.South$ddf$criterion))  # Note model with stratum as covariate is most parsimonious print(model.sel.bin) }"},{"path":"/reference/gof_ds.html","id":null,"dir":"Reference","previous_headings":"","what":"Goodness of fit testing and quantile-quantile plots — gof_ds","title":"Goodness of fit testing and quantile-quantile plots — gof_ds","text":"Goodness fit testing detection function models. continuous distances Kolmogorov-Smirnov Cramer-von Mises tests can used, binned continuous distances used \\(\\chi^2\\) test can used.","code":""},{"path":"/reference/gof_ds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Goodness of fit testing and quantile-quantile plots — gof_ds","text":"","code":"gof_ds(   model,   plot = TRUE,   chisq = FALSE,   nboot = 100,   ks = FALSE,   nc = NULL,   breaks = NULL,   ... )"},{"path":"/reference/gof_ds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Goodness of fit testing and quantile-quantile plots — gof_ds","text":"model fitted detection function. plot TRUE Q-Q plot plotted chisq TRUE chi-squared statistic calculated even models use exact distances. Ignored models use binned distances nboot number replicates use calculate p-values Kolmogorov-Smirnov goodness fit test statistics ks perform Kolmogorov-Smirnov test (involves many bootstraps can take ) nc number evenly-spaced distance classes chi-squared test, chisq=TRUE breaks vector cutpoints use binning, chisq=TRUE ... arguments passed ddf.gof","code":""},{"path":"/reference/gof_ds.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Goodness of fit testing and quantile-quantile plots — gof_ds","text":"Kolmogorov-Smirnov Cramer-von Mises tests based looking quantile-quantile plot produced qqplot.ddf deviations line \\(x=y\\). Kolmogorov-Smirnov test asks question \"largest vertical distance point \\(y=x\\) line?\" uses distance statistic test null hypothesis samples (EDF CDF case) distribution (hence model fits well). deviation \\(y=x\\) line points large reject null hypothesis say model good fit. Rather looking single biggest difference y=x line points Q-Q plot, might prefer think differences line points, since may many smaller differences want take account rather looking one large deviation. null hypothesis , statistic uses sum deviations point line. chi-squared test also run chisq=TRUE. case binning distances required distance data continuous. can specified number equally-spaced bins (using argument nc=) cutpoints bins (using breaks=). test compares number observations given bin number predicted fitted detection function.","code":""},{"path":"/reference/gof_ds.html","id":"details-1","dir":"Reference","previous_headings":"","what":"Details","title":"Goodness of fit testing and quantile-quantile plots — gof_ds","text":"Note bootstrap procedure required Kolmogorov-Smirnov test ensure p-values procedure correct comparing cumulative distribution function (CDF) empirical distribution function (EDF) estimated parameters detection function. nboot parameter controls number bootstraps use. Set 0 avoid computing bootstraps (much faster Kolmogorov-Smirnov results, course).","code":""},{"path":"/reference/gof_ds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Goodness of fit testing and quantile-quantile plots — gof_ds","text":"","code":"if (FALSE) { # fit and test a simple model for the golf tee data library(Distance) data(book.tee.data) tee.data <- subset(book.tee.data$book.tee.dataframe, observer==1) ds.model <- ds(tee.data,4) # don't make plot gof_ds(ds.model, plot=FALSE) }"},{"path":"/reference/golftees.html","id":null,"dir":"Reference","previous_headings":"","what":"Golf tee data — golftees","title":"Golf tee data — golftees","text":"data independent surveys eight observers population 250 groups (760 individuals) golf tees.  tees, two colours, placed groups 1 8 survey region 1680 m^2, either exposed surrounding grass, least partially hidden . surveyed 1999 statistics honours class University St Andrews.","code":""},{"path":"/reference/golftees.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Golf tee data — golftees","text":"Data list 4 elements data.frame: book.tee.dataframe object object ID observer observer ID detected detected detected distance perpendicular distance size group size sex number tees group exposure tee height ground book.tee.region Region.Label stratum name Area stratum size book.tee.samples Sample.Label transect label Region.Label stratum name Effort transect length book.tee.obs object object ID Region.Label stratum detected Sample.Label transect detected","code":""},{"path":"/reference/golftees.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Golf tee data — golftees","text":"treat group golf tees single animal size equal number tees group; yellow tees male, green female; tees exposed surrounding grass classified exposed, others unexposed.  grateful Miguel Bernal making data available; collected part masters project.","code":""},{"path":"/reference/golftees.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Golf tee data — golftees","text":"Borchers, D. L., S.T. Buckland, W. Zucchini. 2002. Estimating Animal Abundance: Closed Populations. Statistics Biology Health. London: Springer-Verlag. https://link.springer.com/book/10.1007/978-1-4471-3708-5 Buckland, S.T., D.R. Anderson, K.P. Burnham, J.L. Laake, D.L. Borchers, L. Thomas. Advanced Distance Sampling: Estimating Abundance Biological Populations. Oxford University Press. Oxford, 2004.","code":""},{"path":"/reference/logLik.dsmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"log-likelihood value for a fitted detection function — logLik.dsmodel","title":"log-likelihood value for a fitted detection function — logLik.dsmodel","text":"Extract log-likelihood fitted detection function.","code":""},{"path":"/reference/logLik.dsmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"log-likelihood value for a fitted detection function — logLik.dsmodel","text":"","code":"# S3 method for dsmodel logLik(object, ...)"},{"path":"/reference/logLik.dsmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"log-likelihood value for a fitted detection function — logLik.dsmodel","text":"object fitted detection function model object ... included S3 completeness, ignored","code":""},{"path":"/reference/logLik.dsmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"log-likelihood value for a fitted detection function — logLik.dsmodel","text":"numeric value giving log-likelihood two attributes: \"df\" \"degrees freedom model (number parameters) \"nobs\" number observations used fit model","code":""},{"path":"/reference/logLik.dsmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"log-likelihood value for a fitted detection function — logLik.dsmodel","text":"David L Miller","code":""},{"path":"/reference/logLik.dsmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"log-likelihood value for a fitted detection function — logLik.dsmodel","text":"","code":"if (FALSE) { library(Distance) data(minke) model <- ds(minke, truncation=4) # extract the log likelihood logLik(model) }"},{"path":"/reference/LTExercise.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated line transect survey data — LTExercise","title":"Simulated line transect survey data — LTExercise","text":"Simulated line transect survey. Twelve transects, detection function half-normal.  True object density 79.8 animals per km^2.","code":""},{"path":"/reference/LTExercise.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated line transect survey data — LTExercise","text":"data.frame 106 rows 7 variables Region.Label strata names (single stratum) Area size study area (1 case, making abundance density equal) Sample.Label transect ID Effort length transects (km) object object ID distance perpendicular distance (m) Study.Area name study area","code":""},{"path":"/reference/LTExercise.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Simulated line transect survey data — LTExercise","text":"Simulated data, distance sampling introductory course, Centre Research Ecological & Environmental Modelling, University St Andrews.","code":""},{"path":"/reference/LTExercise.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Simulated line transect survey data — LTExercise","text":"unit object associated dataset","code":""},{"path":"/reference/make_activity_fn.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiplier bootstrap helper functions — make_activity_fn","title":"Multiplier bootstrap helper functions — make_activity_fn","text":"Helper use models specified using activity::fitact fit activity model generate single realisations bootstrapping bootdht.","code":""},{"path":"/reference/make_activity_fn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiplier bootstrap helper functions — make_activity_fn","text":"","code":"make_activity_fn(..., detector_daily_duration = 24)"},{"path":"/reference/make_activity_fn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiplier bootstrap helper functions — make_activity_fn","text":"... parameters specified activity::fitact detector_daily_duration default assume detectors able detect animals 24 hours, able proportion day (say daylight hours), adjust argument accordingly","code":""},{"path":"/reference/make_activity_fn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multiplier bootstrap helper functions — make_activity_fn","text":"function generates single bootstrap estimate availability","code":""},{"path":"/reference/make_activity_fn.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multiplier bootstrap helper functions — make_activity_fn","text":"Uses activity::fitact generate single possible availability estimates based bootstraps. function returns another function, can passed bootdht. recommended try function passing bootdht. See examples template use.","code":""},{"path":"/reference/make_activity_fn.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Multiplier bootstrap helper functions — make_activity_fn","text":"David L Miller","code":""},{"path":"/reference/minke.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated minke whale data — minke","title":"Simulated minke whale data — minke","text":"Data simulated models fitted 1992/1993 Southern Hemisphere minke whale data collected International Whaling Commission. See Branch Butterworth (2001) survey details (survey design shown figure 1(e)). Data simulated David Borchers.","code":""},{"path":"/reference/minke.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated minke whale data — minke","text":"data.frame 99 observations 5 variables: Region.Label stratum label (\"North\" \"South\") Area stratum area Sample.Label transect identifier Effort transect length distance observed distance object unique object ID","code":""},{"path":"/reference/minke.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Simulated minke whale data — minke","text":"Shipped Distance Windows.","code":""},{"path":"/reference/minke.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulated minke whale data — minke","text":"Data included R data Excel spreadsheet illustrate \"flat file\" input method. See flatfile load data example analysis.","code":""},{"path":"/reference/minke.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulated minke whale data — minke","text":"Branch, T.. D.S. Butterworth (2001) Southern Hemisphere minke whales: standardised abundance estimates 1978/79 1997/98 IDCR-SOWER surveys. Journal Cetacean Research Management 3(2): 143-174 Hedley, S.L., S.T. Buckland. Spatial Models Line Transect Sampling. Journal Agricultural, Biological, Environmental Statistics 9, . 2 (2004): 181-199. doi:10.1198/1085711043578 .","code":""},{"path":"/reference/minke.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated minke whale data — minke","text":"","code":"data(minke) head(minke) #>   Region.Label  Area Sample.Label Effort distance object #> 1        South 84734            1  86.75     0.10      1 #> 2        South 84734            1  86.75     0.22      2 #> 3        South 84734            1  86.75     0.16      3 #> 4        South 84734            1  86.75     0.78      4 #> 5        South 84734            1  86.75     0.21      5 #> 6        South 84734            1  86.75     0.95      6"},{"path":"/reference/plot.dsmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a fitted detection function — plot.dsmodel","title":"Plot a fitted detection function — plot.dsmodel","text":"just simple wrapper around plot.ds. See manual page function information.","code":""},{"path":"/reference/plot.dsmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a fitted detection function — plot.dsmodel","text":"","code":"# S3 method for dsmodel plot(x, pl.den = 0, ...)"},{"path":"/reference/plot.dsmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a fitted detection function — plot.dsmodel","text":"x object class dsmodel. pl.den shading density histogram (default 0, shading) ... extra arguments passed plot.ds.","code":""},{"path":"/reference/plot.dsmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a fitted detection function — plot.dsmodel","text":"NULL, just produces plot.","code":""},{"path":[]},{"path":"/reference/plot.dsmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot a fitted detection function — plot.dsmodel","text":"David L. Miller","code":""},{"path":"/reference/predict.dsmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictions from a fitted detection function — predict.dsmodel","title":"Predictions from a fitted detection function — predict.dsmodel","text":"Predict detection probabilities (effective strip widths/effective areas detection) fitted distance sampling model using either original data (.e., \"fitted\" values) using new data.","code":""},{"path":"/reference/predict.dsmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictions from a fitted detection function — predict.dsmodel","text":"","code":"# S3 method for dsmodel predict(   object,   newdata = NULL,   compute = FALSE,   esw = FALSE,   se.fit = FALSE,   ... )"},{"path":"/reference/predict.dsmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictions from a fitted detection function — predict.dsmodel","text":"object ds model object. newdata new data.frame prediction, must include column called \"distance\". compute TRUE compute values use fitted values stored model object. esw TRUE, returns effective strip half-width (effective area detection point transect models) integral 0 truncation distance (width) \\(p(y)dy\\); otherwise returns integral 0 truncation width \\(p(y)\\pi(y)\\) \\(\\pi(y)=1/w\\) lines \\(\\pi(y)=2r/w^2\\) points. se.fit standard errors predicted probabilities detection (ESW esw=TRUE) estimated? Stored se.fit element ... S3 consistency","code":""},{"path":"/reference/predict.dsmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predictions from a fitted detection function — predict.dsmodel","text":"list single element: fitted, vector average detection probabilities esw values observation original data ornewdata. se.fit=TRUE additional element $se.fit, contains standard errors probabilities detection ESW.","code":""},{"path":"/reference/predict.dsmodel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predictions from a fitted detection function — predict.dsmodel","text":"line transects, effective strip half-width (esw=TRUE) integral fitted detection function either 0 W specified int.range.  predicted detection probability average probability simply integral divided distance range. point transect models, esw=TRUE calculates effective area detection (commonly referred \"nu\", integral 2/width^2 * r * g(r). Fitted detection probabilities stored model object returned unless compute=TRUE newdata specified. compute=TRUE used estimate numerical derivatives use delta method approximations variance. Note ordering returned results new data supplied (\"fitted\" values) necessarily data supplied ddf, data (hence results predict) sorted object ID (object).","code":""},{"path":"/reference/predict.dsmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Predictions from a fitted detection function — predict.dsmodel","text":"David L Miller","code":""},{"path":"/reference/predict.fake_ddf.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction for fake detection functions — predict.fake_ddf","title":"Prediction for fake detection functions — predict.fake_ddf","text":"Prediction function dummy detection functions. function returns many 1s rows newdata. esw=TRUE strip width returned.","code":""},{"path":"/reference/predict.fake_ddf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction for fake detection functions — predict.fake_ddf","text":"","code":"# S3 method for fake_ddf predict(   object,   newdata = NULL,   compute = FALSE,   int.range = NULL,   esw = FALSE,   ... )"},{"path":"/reference/predict.fake_ddf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction for fake detection functions — predict.fake_ddf","text":"object model object newdata many 1s return? compute unused, compatibility mrds::predict int.range unused, compatibility mrds::predict esw strip width returned? ... S3 consistency","code":""},{"path":"/reference/predict.fake_ddf.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prediction for fake detection functions — predict.fake_ddf","text":"David L Miller","code":""},{"path":"/reference/print.dht_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Print abundance estimates — print.dht_result","title":"Print abundance estimates — print.dht_result","text":"See dht2 information printed column names.","code":""},{"path":"/reference/print.dht_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print abundance estimates — print.dht_result","text":"","code":"# S3 method for dht_result print(x, report = \"abundance\", groups = FALSE, ...)"},{"path":"/reference/print.dht_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print abundance estimates — print.dht_result","text":"x object class dht_result report \"abundance\", \"density\" \"\" reported? groups abundance/density groups produced? ... unused","code":""},{"path":"/reference/print.dsmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Simple pretty printer for distance sampling analyses — print.dsmodel","title":"Simple pretty printer for distance sampling analyses — print.dsmodel","text":"Simply prints brief description model fitted. detailed information use summary.","code":""},{"path":"/reference/print.dsmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simple pretty printer for distance sampling analyses — print.dsmodel","text":"","code":"# S3 method for dsmodel print(x, ...)"},{"path":"/reference/print.dsmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simple pretty printer for distance sampling analyses — print.dsmodel","text":"x distance sampling analysis (result calling ds). ... passed , just S3 compatibility.","code":""},{"path":"/reference/print.dsmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Simple pretty printer for distance sampling analyses — print.dsmodel","text":"David L. Miller","code":""},{"path":"/reference/print.summary.dsmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Print summary of distance detection function model object — print.summary.dsmodel","title":"Print summary of distance detection function model object — print.summary.dsmodel","text":"Provides brief summary distance sampling analysis. Including: detection function parameters, model selection criterion, optionally abundance covered (sampled) region standard error.","code":""},{"path":"/reference/print.summary.dsmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print summary of distance detection function model object — print.summary.dsmodel","text":"","code":"# S3 method for summary.dsmodel print(x, ...)"},{"path":"/reference/print.summary.dsmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print summary of distance detection function model object — print.summary.dsmodel","text":"x summary distance sampling analysis ... unspecified unused arguments S3 consistency","code":""},{"path":"/reference/print.summary.dsmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print summary of distance detection function model object — print.summary.dsmodel","text":"Nothing, just prints summary.","code":""},{"path":[]},{"path":"/reference/print.summary.dsmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print summary of distance detection function model object — print.summary.dsmodel","text":"David L. Miller Jeff Laake","code":""},{"path":"/reference/PTExercise.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated point transect survey data — PTExercise","title":"Simulated point transect survey data — PTExercise","text":"Simulated point transect survey. Thirty point transects, detection function half-normal.  True object density 79.6 animals per hectare.","code":""},{"path":"/reference/PTExercise.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated point transect survey data — PTExercise","text":"data.frame 144 rows 7 variables Region.Label strata names (single stratum) Area size study area (0 case) Sample.Label transect ID Effort number visits point object object ID distance radial distance (m) Study.Area name study area","code":""},{"path":"/reference/PTExercise.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Simulated point transect survey data — PTExercise","text":"Simulated data, distance sampling introductory course, Centre Research Ecological & Environmental Modelling, University St Andrews.","code":""},{"path":"/reference/p_dist_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Distribution of probabilities of detection — p_dist_table","title":"Distribution of probabilities of detection — p_dist_table","text":"Generate table frequencies probability detection detection function model. particularly useful employing covariates, can indicate detections small detection probabilities can unduly influential calculating abundance estimates.","code":""},{"path":"/reference/p_dist_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Distribution of probabilities of detection — p_dist_table","text":"object fitted detection function bins results binned proportion proportions returned well counts?","code":""},{"path":"/reference/p_dist_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Distribution of probabilities of detection — p_dist_table","text":"data.frame probability bins, counts (optionally) proportions. object attribute p_range contains range estimated detection probabilities","code":""},{"path":"/reference/p_dist_table.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Distribution of probabilities of detection — p_dist_table","text":"dht uses Horvitz-Thompson-like estimator, abundance estimates can sensitive errors estimated probabilities. estimator based \\(\\sum 1/ \\hat{P}_a(z_i)\\), means sensitivity greater smaller detection probabilities. rough guide, recommend method used say 5% \\(\\hat{P}_a(z_i)\\) less 0.2, less 0.1. conditions violated, truncation distance w can reduced. causes loss precision relative standard distance sampling without covariates.","code":""},{"path":"/reference/p_dist_table.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Distribution of probabilities of detection — p_dist_table","text":"function located mrds package documentation provided easy access.","code":""},{"path":"/reference/p_dist_table.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Distribution of probabilities of detection — p_dist_table","text":"Marques, F.F.C. S.T. Buckland. 2004. Covariate models detection function.   : Advanced Distance Sampling, eds. S.T. Buckland, D.R. Anderson, K.P.   Burnham, J.L. Laake, D.L. Borchers, L. Thomas. Oxford University   Press.","code":""},{"path":"/reference/p_dist_table.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Distribution of probabilities of detection — p_dist_table","text":"David L Miller","code":""},{"path":"/reference/p_dist_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Distribution of probabilities of detection — p_dist_table","text":"","code":"# example using a model for the minke data data(minke) # fit a model result <- ds(minke, formula=~Region.Label) #> Model contains covariate term(s): no adjustment terms will be included. #> Fitting half-normal key function #> AIC= 57.005 # print table p_dist_table(result) #>          p count #>    0 - 0.1     0 #>  0.1 - 0.2     0 #>  0.2 - 0.3     0 #>  0.3 - 0.4    39 #>  0.4 - 0.5     0 #>  0.5 - 0.6    51 #>  0.6 - 0.7     0 #>  0.7 - 0.8     0 #>  0.8 - 0.9     0 #>    0.9 - 1     0 #> Range of probabilities:  0.33 - 0.54  # with proportions p_dist_table(result, proportion=TRUE) #>          p count proportion #>    0 - 0.1     0       0.00 #>  0.1 - 0.2     0       0.00 #>  0.2 - 0.3     0       0.00 #>  0.3 - 0.4    39       0.43 #>  0.4 - 0.5     0       0.00 #>  0.5 - 0.6    51       0.57 #>  0.6 - 0.7     0       0.00 #>  0.7 - 0.8     0       0.00 #>  0.8 - 0.9     0       0.00 #>    0.9 - 1     0       0.00 #> Range of probabilities:  0.33 - 0.54"},{"path":"/reference/QAIC.html","id":null,"dir":"Reference","previous_headings":"","what":"Tools for model selection when distance sampling data are overdispersed — QAIC","title":"Tools for model selection when distance sampling data are overdispersed — QAIC","text":"Overdispersion causes AIC select overly-complex models, analysts specify number/order adjustment terms manually fitting distance sampling models data camera traps, rather allowing automated selection using AIC. Howe et al (2019) described two-step method selecting among models detection function face overdispersion.","code":""},{"path":"/reference/QAIC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tools for model selection when distance sampling data are overdispersed — QAIC","text":"","code":"QAIC(object, ..., chat = NULL, k = 2)  chi2_select(object, ...)"},{"path":"/reference/QAIC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tools for model selection when distance sampling data are overdispersed — QAIC","text":"object fitted detection function object ... additional fitted model objects. chat value \\(\\hat{c}\\) used QAIC calculation k penalty per parameter used; default 2","code":""},{"path":"/reference/QAIC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tools for model selection when distance sampling data are overdispersed — QAIC","text":"data.frame one row per model supplied, order given","code":""},{"path":"/reference/QAIC.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tools for model selection when distance sampling data are overdispersed — QAIC","text":"step 1, overdispersion factor (\\(\\hat{c}\\)) computed either (1) key function family, complex model family, chi-square goodness fit test statistic divided degrees freedom (\\(\\hat{c}_1\\)), (2) models candidate set, raw data (\\(\\hat{c}_1\\)). camera trap surveys solitary animals, \\(\\hat{c}_1\\) mean number distance observations recorded single pass animal front trap. surveys social animals employing human observers, \\(\\hat{c}_1\\) mean number detected animals per detected group, camera trap surveys social animals \\(\\hat{c}_1\\) mean number distance observations recorded encounter group animals CT.  step two, chi-square goodness fit statistic divided degrees freedom calculated QAIC-minimizing model within key function, model lowest value selected estimation. QAIC() function used select among models key function (step 1). QAIC() uses \\(\\hat{c}_1\\) default, computing model parameters. Alternatively, \\(\\hat{c}_1\\) can calculated raw data included call QAIC(). Users must identify QAIC-minimizing model within key functions resulting data.frame, provide models arguments ch2_select(). chi2_select() computes reports chi-square goodness fit statistic divided degrees freedom models. model lowest value recommended estimation.","code":""},{"path":"/reference/QAIC.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Tools for model selection when distance sampling data are overdispersed — QAIC","text":"Howe, E. J., Buckland, S. T., Després-Einspenner, M.-L., & Kühl, H. S. (2019). Model selection overdispersed distance sampling data. Methods Ecology Evolution, 10(1), 38–47. doi:10.1111/2041-210X.13082","code":""},{"path":"/reference/QAIC.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Tools for model selection when distance sampling data are overdispersed — QAIC","text":"David L Miller, based code Eric Rexstad explanation Eric Howe.","code":""},{"path":"/reference/QAIC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tools for model selection when distance sampling data are overdispersed — QAIC","text":"","code":"library(Distance) data(\"wren_cuecount\")  # fit hazard-rate key models w3.hr0 <- ds(wren_cuecount, transect=\"point\", key=\"hr\", adjustment=NULL,              truncation=92.5) #> Fitting hazard-rate key function #> AIC= 6621.473 #> No survey area information supplied, only estimating detection function. w3.hr1 <- ds(wren_cuecount, transect=\"point\", key=\"hr\", adjustment=\"cos\",              order=2, truncation=92.5) #> Fitting hazard-rate key function with cosine(2) adjustments #> AIC= 6623.473 #> No survey area information supplied, only estimating detection function. w3.hr2 <- ds(wren_cuecount, transect=\"point\", key=\"hr\", adjustment=\"cos\",              order=c(2, 4), truncation=92.5) #> Fitting hazard-rate key function with cosine(2,4) adjustments #> Warning: Detection function is not strictly monotonic! #> Warning: Detection function is not strictly monotonic! #> AIC= 6625.335 #> Warning: Detection function is not strictly monotonic! #> No survey area information supplied, only estimating detection function.  # fit unform key models w3.u1 <- ds(wren_cuecount, transect=\"point\", key=\"unif\", adjustment=\"cos\",             order=1, truncation=92.5) #> Fitting uniform key function with cosine(1) adjustments #> AIC= 6667.045 #> No survey area information supplied, only estimating detection function. w3.u2 <- ds(wren_cuecount, transect=\"point\", key=\"unif\", adjustment=\"cos\",             order=c(1,2), monotonicity=\"none\",  truncation=92.5) #> Fitting uniform key function with cosine(1,2) adjustments #> ** Warning: Maximum probability of detection is greater than one: invalid model fitted ** #> ** Warning: Maximum probability of detection is greater than one: invalid model fitted ** #> ** Warning: Maximum probability of detection is greater than one: invalid model fitted ** #> Warning: Detection function is not weakly monotonic! #> Warning: Detection function is not strictly monotonic! #> Warning: Detection function is greater than 1 at some distances #> Warning: Detection function is not weakly monotonic! #> Warning: Detection function is not strictly monotonic! #> Warning: Detection function is greater than 1 at some distances #> AIC= 6618.005 #> Warning: Detection function is not weakly monotonic! #> Warning: Detection function is not strictly monotonic! #> Warning: Detection function is greater than 1 at some distances #> No survey area information supplied, only estimating detection function. w3.u3 <- ds(wren_cuecount, transect=\"point\", key=\"unif\", adjustment=\"cos\",             order=c(1,2,3), monotonicity=\"none\", truncation=92.5) #> Fitting uniform key function with cosine(1,2,3) adjustments #> ** Warning: Maximum probability of detection is greater than one: invalid model fitted ** #> ** Warning: Maximum probability of detection is greater than one: invalid model fitted ** #> ** Warning: Maximum probability of detection is greater than one: invalid model fitted ** #> Warning: Detection function is not weakly monotonic! #> Warning: Detection function is not strictly monotonic! #> Warning: Detection function is greater than 1 at some distances #> Warning: Detection function is not weakly monotonic! #> Warning: Detection function is not strictly monotonic! #> Warning: Detection function is greater than 1 at some distances #> AIC= 6585.701 #> Warning: Detection function is not weakly monotonic! #> Warning: Detection function is not strictly monotonic! #> Warning: Detection function is greater than 1 at some distances #> No survey area information supplied, only estimating detection function.  # fit half-normal key functions w3.hn0 <- ds(wren_cuecount, transect=\"point\", key=\"hn\", adjustment=NULL,              truncation=92.5) #> Fitting half-normal key function #> AIC= 6657.954 #> No survey area information supplied, only estimating detection function. w3.hn1 <- ds(wren_cuecount, transect=\"point\", key=\"hn\", adjustment=\"herm\",              order=2, truncation=92.5) #> Fitting half-normal key function with Hermite(2) adjustments #> Error in adj.check.order(adj.series, adj.order, key) :  #>   Hermite polynomial adjustment terms of order < 4 selected #>  #>  #> All models failed to fit! #> Error: No models could be fitted.  # stage 1: calculate QAIC per model set QAIC(w3.hr0, w3.hr1, w3.hr2)  # no adjustments smallest #>        df     QAIC #> w3.hr0  2 241.6884 #> w3.hr1  3 243.6884 #> w3.hr2  4 245.6834 QAIC(w3.u1, w3.u2, w3.u3)     # 2 adjustment terms (by 0.07) #>       df     QAIC #> w3.u1  1 274.4930 #> w3.u2  2 274.4215 #> w3.u3  3 275.0294 QAIC(w3.hn0, w3.hn1)  # no adjustments smallest #> Error in eval(expr, envir, enclos): object 'w3.hn1' not found  # stage 2: select using chi^2/degrees of freedom between sets chi2_select(w3.hr0, w3.u2, w3.hn0) #>        criteria #> w3.hr0 25.86191 #> w3.u2  27.08399 #> w3.hn0 27.05415  # example using a pre-calculated chat chat <- attr(QAIC(w3.hr0, w3.hr1, w3.hr2), \"chat\") QAIC(w3.hr0, chat=chat) #>        df     QAIC #> w3.hr0  2 241.6884"},{"path":"/reference/Savannah_sparrow_1980.html","id":null,"dir":"Reference","previous_headings":"","what":"Savanna sparrow point transects — Savannah_sparrow_1980","title":"Savanna sparrow point transects — Savannah_sparrow_1980","text":"Point transect data collected Colorado 1980/81 examine effect agricultural practices upon avian community.","code":""},{"path":"/reference/Savannah_sparrow_1980.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Savanna sparrow point transects — Savannah_sparrow_1980","text":"data.frame 468 observations (1980) 448 observations (1981) 7 variables: Region.Label stratum label (pasture ID) Area stratum area (set 1 density reported) Sample.Label transect identifier Effort number visits object object ID distance radial distance (m) Study.Area name study area","code":""},{"path":"/reference/Savannah_sparrow_1980.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Savanna sparrow point transects — Savannah_sparrow_1980","text":"Design consisted point transects placed multiple pastures (3 1980 4 1981). many species observed, data Savannah sparrows (Passerculus sandwichensis) included . Data given different Distance Windows example project. individual sighting treated independent observation. corresponds analysis Buckland et al. (2001) Section 8.7.  Distance Windows project objects clusters individuals. affect results greatly clusters size 1, results obtained far .","code":""},{"path":"/reference/Savannah_sparrow_1980.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Savanna sparrow point transects — Savannah_sparrow_1980","text":"Knopf, F.L., J.. Sedgwick, R.W. Cannon. (1988) Guild structure riparian avifauna relative seasonal cattle grazing.  Journal Wildlife Management 52 (2): 280–290.  doi:10.2307/3801235","code":""},{"path":"/reference/sikadeer.html","id":null,"dir":"Reference","previous_headings":"","what":"Sika deer pellet data from southern Scotland — sikadeer","title":"Sika deer pellet data from southern Scotland — sikadeer","text":"sika deer spend time woodland areas, abundance estimates based pellet group counts.  Line transect methods applied estimate deer pellet group density geographic block.","code":""},{"path":"/reference/sikadeer.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sika deer pellet data from southern Scotland — sikadeer","text":"data.frame 1923 rows 11 variables. Region.Label stratum labels Area size (ha) stratum Sample.Label transect labels Defecation.rate rate dung production per individual per day Defecation.rate.SE variability defecation rate Decay.rate time (days) dung become undetectable Decay.rate.SE variability decay rate Effort transect length (km) object object ID distance perpendicular distance (cm) Study.Area study area name","code":""},{"path":"/reference/sikadeer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sika deer pellet data from southern Scotland — sikadeer","text":"Data presented Peebleshire portion study described Marques et al. (2001).","code":""},{"path":"/reference/sikadeer.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sika deer pellet data from southern Scotland — sikadeer","text":"Marques, F.F.C., S.T. Buckland, D. Goffin, C.E. Dixon, D.L.  Borchers, B.. Mayle, .J. Peace. (2001). Estimating deer abundance line transect surveys dung: sika deer southern Scotland. Journal Applied Ecology 38 (2): 349–363.  doi:10.1046/j.1365-2664.2001.00584.x","code":""},{"path":"/reference/Stratify_example.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated minke whale data — Stratify_example","title":"Simulated minke whale data — Stratify_example","text":"Data simulated models fitted 1992/1993 Southern Hemisphere minke whale data collected International Whaling Commission. See Branch Butterworth (2001) survey details (survey design shown figure 1(e)). Data simulated David Borchers.","code":""},{"path":"/reference/Stratify_example.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated minke whale data — Stratify_example","text":"data.frame 99 observations 7 variables: Region.Label stratum label (\"North\" \"South\") Area stratum area  (square nautical mile) Sample.Label transect identifier Effort transect length  (nautical mile) object object ID distance observed distance (nautical mile) Study.Area name study area","code":""},{"path":"/reference/Stratify_example.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulated minke whale data — Stratify_example","text":"Branch, T.. D.S. Butterworth. (2001) Southern Hemisphere minke whales: standardised abundance estimates 1978/79 1997/98 IDCR-SOWER surveys. Journal Cetacean Research Management 3(2): 143-174 Hedley, S.L., S.T. Buckland. (2004) Spatial models line transect sampling. Journal Agricultural, Biological, Environmental Statistics 9: 181-199. doi:10.1198/1085711043578 .","code":""},{"path":"/reference/summarize_ds_models.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a table of summary statistics for detection function models — summarize_ds_models","title":"Make a table of summary statistics for detection function models — summarize_ds_models","text":"Provide summary table useful information fitted detection functions. can useful paired knitr's kable function. default models sorted AIC therefore allow models different truncations distance binning.","code":""},{"path":"/reference/summarize_ds_models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a table of summary statistics for detection function models — summarize_ds_models","text":"","code":"summarize_ds_models(..., sort = \"AIC\", output = \"latex\", delta_only = TRUE)"},{"path":"/reference/summarize_ds_models.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make a table of summary statistics for detection function models — summarize_ds_models","text":"... models summarised sort column sort (default \"AIC\") output output given \"latex\" compatible format \"plain\" text? delta_only output AIC differences (default TRUE)","code":""},{"path":"/reference/summarize_ds_models.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make a table of summary statistics for detection function models — summarize_ds_models","text":"Note column names LaTeX format, plan manipulate resulting data.frame R, may wish rename columns ease access.","code":""},{"path":"/reference/summarize_ds_models.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Make a table of summary statistics for detection function models — summarize_ds_models","text":"David L Miller","code":""},{"path":"/reference/summarize_ds_models.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make a table of summary statistics for detection function models — summarize_ds_models","text":"","code":"if (FALSE) { # fit some models to the golf tee data library(Distance) data(book.tee.data) tee.data <- subset(book.tee.data$book.tee.dataframe, observer==1) model_hn <- ds(tee.data,4) model_hr <- ds(tee.data,4, key=\"hr\") summarize_ds_models(model_hr, model_hn, output=\"plain\") }"},{"path":"/reference/summary.dht_bootstrap.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize bootstrap abundance uncertainty estimate output — summary.dht_bootstrap","title":"Summarize bootstrap abundance uncertainty estimate output — summary.dht_bootstrap","text":"simple function calculate summaries bootstrap output generated bootdht.","code":""},{"path":"/reference/summary.dht_bootstrap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize bootstrap abundance uncertainty estimate output — summary.dht_bootstrap","text":"","code":"# S3 method for dht_bootstrap summary(object, alpha = 0.05, ...)"},{"path":"/reference/summary.dht_bootstrap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize bootstrap abundance uncertainty estimate output — summary.dht_bootstrap","text":"object output bootdht alpha value use confidence interval calculation (obtain alpha/2 1-alpha/2 intervals ... S3 compatibility, unused.","code":""},{"path":"/reference/summary.dht_bootstrap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize bootstrap abundance uncertainty estimate output — summary.dht_bootstrap","text":"data.frame summary statistics","code":""},{"path":"/reference/summary.dht_bootstrap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarize bootstrap abundance uncertainty estimate output — summary.dht_bootstrap","text":"Summaries made numeric outputs. median mean reported allow assessment bias. coefficient variation reported (column cv) based median calculated bootstraps.","code":""},{"path":"/reference/summary.dsmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of distance sampling analysis — summary.dsmodel","title":"Summary of distance sampling analysis — summary.dsmodel","text":"Provides brief summary distance sampling analysis. includes parameters, model selection criterion, optionally abundance covered (sampled) region standard error.","code":""},{"path":"/reference/summary.dsmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of distance sampling analysis — summary.dsmodel","text":"","code":"# S3 method for dsmodel summary(object, ...)"},{"path":"/reference/summary.dsmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of distance sampling analysis — summary.dsmodel","text":"object distance analysis ... unspecified unused arguments S3 consistency","code":""},{"path":"/reference/summary.dsmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary of distance sampling analysis — summary.dsmodel","text":"list extracted summarized objects","code":""},{"path":"/reference/summary.dsmodel.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Summary of distance sampling analysis — summary.dsmodel","text":"function just calls summary.ds dht, collates prints results nice way.","code":""},{"path":"/reference/summary.dsmodel.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summary of distance sampling analysis — summary.dsmodel","text":"David L. Miller","code":""},{"path":"/reference/Systematic_variance_1.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulation of encounter rate variance — Systematic_variance_1","title":"Simulation of encounter rate variance — Systematic_variance_1","text":"systematic_var_1 consists simulated line transect data large differences transect length. systematic_var_2 transect length gradient coupled strong animal gradient; exaggerating encounter rate variance transects.","code":""},{"path":"/reference/Systematic_variance_1.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulation of encounter rate variance — Systematic_variance_1","text":"data.frame 253 observations (systematic_var_1) 256 observations (systematic_var_2) 7 variables: Region.Label stratum label (default) Area stratum area (0.5 km^2) Sample.Label transect identifier Effort transect length (km) object object ID distance perpendicular distance (m) Study.Area name study area","code":""},{"path":"/reference/Systematic_variance_1.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulation of encounter rate variance — Systematic_variance_1","text":"True population size 1000 objects study area size 0.5 km^2; true density 2000 objects per km.","code":""},{"path":"/reference/Systematic_variance_1.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulation of encounter rate variance — Systematic_variance_1","text":"Fewster, R.M., S.T. Buckland, K.P. Burnham, D.L. Borchers, P.E. Jupp, J.L. Laake L. Thomas. (2009) Estimating encounter rate variance distance sampling. Biometrics 65 (1): 225–236. doi:10.1111/j.1541-0420.2008.01018.x","code":""},{"path":"/reference/unflatten.html","id":null,"dir":"Reference","previous_headings":"","what":"Unflatten flatfile data.frames — unflatten","title":"Unflatten flatfile data.frames — unflatten","text":"Sometimes data provided flatfile format, really want mrds format (, distance data, observation table, sample table region table format). function undoes flattening, assuming data correct columns.","code":""},{"path":"/reference/unflatten.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unflatten flatfile data.frames — unflatten","text":"","code":"unflatten(data)"},{"path":"/reference/unflatten.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unflatten flatfile data.frames — unflatten","text":"data data flatfile format (data.frame)","code":""},{"path":"/reference/unflatten.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unflatten flatfile data.frames — unflatten","text":"list four data.frames: distance data, observation table, sample table, region table.","code":""},{"path":"/reference/unflatten.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Unflatten flatfile data.frames — unflatten","text":"David L Miller","code":""},{"path":"/reference/unimak.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated line transect survey data with covariates — unimak","title":"Simulated line transect survey data with covariates — unimak","text":"Simulated line transect survey. eight line transects, detection function half-normal.","code":""},{"path":"/reference/unimak.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated line transect survey data with covariates — unimak","text":"data.frame 60 rows 9 variables Region.Label strata names (single stratum) Area size study area (mi^2) Sample.Label transect ID Effort transect length (mi) object object ID distance perpendicular distance (km) MSTDO time since medication taken observer (min) Hour time day sighting (hour) Study.Area name study area","code":""},{"path":"/reference/unimak.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Simulated line transect survey data with covariates — unimak","text":"Simulated data, distance sampling introductory course, Centre Research Ecological & Environmental Modelling, University St Andrews.","code":""},{"path":"/reference/unimak.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Simulated line transect survey data with covariates — unimak","text":"Hour covariate effect detection function, MSTDO affect detection function.  Examine ability model selection choose correct model.","code":""},{"path":"/reference/units_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate table of unit conversions — units_table","title":"Generate table of unit conversions — units_table","text":"Returns table conversions units used Distance Windows. extracted DistIni.mdb default database.","code":""},{"path":"/reference/units_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate table of unit conversions — units_table","text":"","code":"units_table()"},{"path":"/reference/units_table.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate table of unit conversions — units_table","text":"David L Miller","code":""},{"path":"/reference/wren.html","id":null,"dir":"Reference","previous_headings":"","what":"Steve Buckland's winter wren surveys — wren","title":"Steve Buckland's winter wren surveys — wren","text":"Observations winter wren (Troglodytes troglodytes L.) collected Steve Buckland woodland/parkland Montrave Estate near Leven, Fife, Scotland.","code":""},{"path":"/reference/wren.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Steve Buckland's winter wren surveys — wren","text":"Steve Buckland","code":""},{"path":"/reference/wren.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Steve Buckland's winter wren surveys — wren","text":"Four different surveys carried : wren_5min 5-minute point count wren_snapshot snapshot method wren_cuecount cue count wren_lt line transect survey","code":""},{"path":"/reference/wren.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Steve Buckland's winter wren surveys — wren","text":"wren_5min: 134 observations 8 variables Region.Label  stratum name (single stratum) Area  size (ha) Montrave study area Sample.Label  point label Effort  Number visits point object  Object ID distance  radial distance (m) direction  direction detection point Study.Area  Montrave Estate wren_snapshot: 119 observations 7 variables Region.Label  stratum name (single stratum) Area  size (ha) Montrave study area Sample.Label  point label Effort  Number visits point object  Object ID distance  radial distance (m) Study.Area  Montrave Estate wren_cuecount: 774 observations 9 variables Region.Label  stratum name (single stratum) Area  size (ha) Montrave study area Sample.Label  point label Cue.rate  Production rate (per min) cues Cue.rate.SE   SE cue production rate object  Object ID distance  radial distance (m) Search.time  Time (min) listening cues Study.Area  Montrave Estate wren_lt: 156 observations 8 variables Region.Label  stratum name (single stratum) Area  size (ha) Montrave study area Sample.Label  transect label Effort   transect length (km) object  Object ID distance  perpendicular distance (m) Study.Area  Montrave Estate","code":""},{"path":"/reference/wren.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Steve Buckland's winter wren surveys — wren","text":"Buckland, S. T. (2006) Point-transect surveys songbirds: robust methodologies. Auk 123 (2): 345–357.","code":""},{"path":"/news/index.html","id":"distance-109","dir":"Changelog","previous_headings":"","what":"Distance 1.0.9","title":"Distance 1.0.9","text":"CRAN release: 2023-12-21 Changed default encounter rate estimator point transect surveys P3 P2. (Issue #138) Fixed bug produced NA’s stratum names came ‘Total’ alphabet. (Issue #158) Added additional documentation explaining adjustment term options covariates model. (Issue #156) Fixed dht bootstrap work distbegin distend supplied distance. (Issue #147) Added warning dht bootstrap Sample.Label values unique across strata. (Issue #157) Distance 1.0.9 depends mrds >= 2.3.0 due re-named documentation page links.","code":""},{"path":"/news/index.html","id":"distance-108","dir":"Changelog","previous_headings":"","what":"Distance 1.0.8","title":"Distance 1.0.8","text":"CRAN release: 2023-07-17 Support using MCDS.exe Distance Windows run analyses. can now download MCDS.exe using mrds::download_MCDS_dot_exe run analyses using engine, rather (tandem ) usual R optimizers provided mrds. ds pick best (likelihood) return . See ?ds ?“mcds-dot-exe” details.","code":""},{"path":"/news/index.html","id":"distance-107","dir":"Changelog","previous_headings":"","what":"Distance 1.0.7","title":"Distance 1.0.7","text":"CRAN release: 2022-11-15 dht2 now requires object field flatfile formatted data. following vignette shows add object field data already one: https://examples.distancesampling.org/Distance-cameratraps/camera-distill.html Fix bugs uniform fitted adjustments Fixed error dht2 binned data used distend / distbegin","code":""},{"path":"/news/index.html","id":"distance-106","dir":"Changelog","previous_headings":"","what":"Distance 1.0.6","title":"Distance 1.0.6","text":"CRAN release: 2022-08-20 Fix bug auto binning data using flatfile (#116) convert.units bootdht() properly implemented previous release, fixed (#122) fix bug detection function variance estimation (#125) fix bug bootstrap columns needed character (thanks Nick Wilkinson finding ) fix bug covered area calculation dht2, fixes incorrect density estimate left truncation (#135) experimental support multiple detection functions dht2, joint work T.J. Clark-Wolf, funded Environment Canada. Note now object field required data supplied dht2.","code":""},{"path":"/news/index.html","id":"distance-105","dir":"Changelog","previous_headings":"","what":"Distance 1.0.5","title":"Distance 1.0.5","text":"CRAN release: 2022-03-17 create.bins() -> create_bins() convert.units -> convert_units dht.group -> dht_group region.table -> region_table sample.table -> sample_table obs.table -> obs_table convert.units -> convert_units er.var -> er_var debug.level -> debug_level initial.values -> initial_values max.adjustments -> max_adjustments fix bootdht issue cluster results requests (#103) improve flatfile documentation (thanks Maggie Blake pointing ) fixed bug cutpoint calculations create.bins (#108) order argument ds() now used specify order, fix given number adjustments use new argument nadj (see ?ds info) fix bug polynomial adjustments started wrong order (2 rather 4)","code":""},{"path":"/news/index.html","id":"distance-104","dir":"Changelog","previous_headings":"","what":"Distance 1.0.4","title":"Distance 1.0.4","text":"CRAN release: 2021-08-12 fix bootdht issue arguments ds() found bootdht_Nhat_summarize now reports stratum labels well abundance estimates ease use add function QAIC calculate QAIC overdispersed data, camera trap distance sampling bootdht now less verbose cores>1 bootdht now accepts multipliers bootdht multipliers can now specified using activity package, see ?make_activity_fun fix issue Hermite adjustment order calculation length(order)>1 set.seed can now used bootdht parallel obtain reproducible bootstrap results","code":""},{"path":"/news/index.html","id":"distance-103","dir":"Changelog","previous_headings":"","what":"Distance 1.0.3","title":"Distance 1.0.3","text":"CRAN release: 2021-07-01 fix bug dht2 warnings thrown object column flatfile (https://github.com/DistanceDevelopment/Distance/issues/83) removed silent=TRUE try() around model fitting enable users get error messages mrds fitting. Old behaviour can recovered using quiet=TRUE argument ds() better handling models fail converge AIC adjustment term selection documentation now rmarkdown format fix issue #85 species used detection function post-stratification. Thanks jason-airst reporting bug. fix dht2 bug stratification=“replicate” variance estimation 0 due order operations fix dht2 bug stratification=“effort_sum” encounter rate variance estimation, due incorrect grouping transects strata. Thanks Samantha Ball Jamie McKaughan reporting issue. bootdht can now run parallel via foreach/doParallel packages, see cores argument. multiple multipliers can now specified, example different creation/decay rates stratum new argument er.method ds(), allows refinement encounter rate variance calculation. Default 2 , use er.method=1 get results match Distance Windows. fix issues Satterthwaite degrees freedom calculations geographical stratification used clustered observations Sample fraction may now specified data.frame fractions different transect Fix various bugs dht2 stratification=“replicate”, thanks Sam Ball Jamie McKaughan reporting issues testing.","code":""},{"path":"/news/index.html","id":"distance-102","dir":"Changelog","previous_headings":"","what":"Distance 1.0.2","title":"Distance 1.0.2","text":"CRAN release: 2020-12-01 ds.gof now deprecated goodness--fit testing. gof_ds now preferred. add_df_covar_line (actually located mrds) can now plot probability density functioins point transects bootdht can now use progress package installed give estimated time remaining bootstraps (option progress_bar=“progress”). Alternatively progress bar can shown progress_bar=“none”.","code":""},{"path":"/news/index.html","id":"distance-101","dir":"Changelog","previous_headings":"","what":"Distance 1.0.1","title":"Distance 1.0.1","text":"CRAN release: 2020-07-31 fix bug dht2 object IDs specified flatfile formatted data fix bugs bootdht function crashed models failed fit hessian couldn’t computed better checking data$observer, thanks Martin Biuw pointing fix bug dht2 covered area calculated incorrectly left truncation used point transects add example data camera trap distance sampling, see ?DuikerCameraTrap information Stratum area column (Area) longer required ds(). omitted density estimates returned. Fix bug dht2 used pre-binned data. Thanks Delphine Ducros reporting bug. Fix dht2 bugs Innes et al estimator used encounter rate variance estimation fix bootdht issue convert.units argument handled properly","code":""},{"path":"/news/index.html","id":"distance-100","dir":"Changelog","previous_headings":"","what":"Distance 1.0.0","title":"Distance 1.0.0","text":"CRAN release: 2020-01-31 call now saved model object $call Added lots example data sets new abundance estimation via dht2! Handles complex situations. bootstrap variance estimation via bootdht examples see http://examples.distancesampling.org","code":""},{"path":"/news/index.html","id":"distance-098","dir":"Changelog","previous_headings":"","what":"Distance 0.9.8","title":"Distance 0.9.8","text":"CRAN release: 2019-05-01 Includes reference citation paper ‘Distance Sampling R’. AIC now works multiple models (model classes) thanks Tiago Marques Len Thomas suggestion. Added examples create.bins, ds.gof, gof_ds, summarize_ds_models, logLik.dsmodel AIC.dsmodel. Thanks reviewer Journal Statistical Software paper. Parameters previous fit used starting values next fit AIC used select adjustments distbegin distend specified data distance wasn’t, checkdata() threw error. checkdata() now generates distance column midpoint. Thanks Tom spotting . new argument ds(), max.adjustments gives maximum number adjustment terms add model AIC term selection. Thanks Oscar Dewhurst suggestion.","code":""},{"path":"/news/index.html","id":"distance-097","dir":"Changelog","previous_headings":"","what":"Distance 0.9.7","title":"Distance 0.9.7","text":"CRAN release: 2017-07-03 summarize_ds_models now compare models allowed AIC (binning truncation must ). Thanks Carolin Tröger Eric Rextad highlighting issue. numerical issues cause NAs Hessian, ds() try run dht() estimate abundance (fail), instead throws message returns detection function. Thanks Steve Ahlswede bringing attention.","code":""},{"path":"/news/index.html","id":"distance-096","dir":"Changelog","previous_headings":"","what":"Distance 0.9.6","title":"Distance 0.9.6","text":"CRAN release: 2016-08-10 Coefficients called coefficients (mixture coefficients parameters) summary() results Added gof_ds() easy access goodness fit testing q-q plotting Checking truncation distance checking via .double rather .numeric. Thanks Tiago Marques spotting ! Functions AIC() logLik() now exist quick extraction AIC log-likelihood values. Thanks Tiago Marques suggestion. Added amakihi (point transect) data add extra documentation objects obs.table, thanks Olivier Devineau spotting ","code":""},{"path":"/news/index.html","id":"distance-095","dir":"Changelog","previous_headings":"","what":"Distance 0.9.5","title":"Distance 0.9.5","text":"Truncation percentage now works missing distances (.e. using flatfile). Thanks Len Thomas pointing bug.","code":""},{"path":"/news/index.html","id":"distance-094","dir":"Changelog","previous_headings":"","what":"Distance 0.9.4","title":"Distance 0.9.4","text":"CRAN release: 2015-07-29 Object ID uniqueness stopped abundance estimation working (since NA IDs “unique”). Check areas consistently entered. problematic areas entered identically region, unique used extract region table. Thanks Katy Echave finding bug! Monotonicity constraints applied automated model selection. Thanks Tiago Marques spotting . AIC selection adjustment terms goes 5 terms default, DISTANCE. Thanks Eric Rexstad suggesting .","code":""},{"path":"/news/index.html","id":"distance-093","dir":"Changelog","previous_headings":"","what":"Distance 0.9.3","title":"Distance 0.9.3","text":"CRAN release: 2015-02-05 Updated tests work new unique object ID code. Liberally sprinkled tests suppressMessages()","code":""},{"path":"/news/index.html","id":"distance-092","dir":"Changelog","previous_headings":"","what":"Distance 0.9.2","title":"Distance 0.9.2","text":"CRAN release: 2014-09-16 Now warning columns correctly named correct case. Thanks Richard Borthwick reporting bug. Now checks object IDs unique. Thanks Ricardo Lima & Francisco Azevedo highlighting issue.","code":""},{"path":"/news/index.html","id":"distance-091","dir":"Changelog","previous_headings":"","what":"Distance 0.9.1","title":"Distance 0.9.1","text":"CRAN release: 2014-06-11 Models covariates adjustment terms can actually specified – fully implemented previous version. ds() now tells user models returned (rather previously fitted model) links mrds documentation optimisation issues","code":""},{"path":"/news/index.html","id":"distance-09","dir":"Changelog","previous_headings":"","what":"Distance 0.9","title":"Distance 0.9","text":"CRAN release: 2014-04-22 Flat file support example, see ?flatfile New data set: simulated minke whale data, see ?minke ?flatfile example analysis Models covariates adjustment terms can specified. Default left truncation now 0, default right truncation now largest observed distance furthest bin end.","code":""},{"path":"/news/index.html","id":"distance-081","dir":"Changelog","previous_headings":"","what":"Distance 0.8.1","title":"Distance 0.8.1","text":"another fix binning (redundant code/inconsistent definition docs code). (Thanks Jason Roberts finding .) binning fail NA distances, might occur using simplified data tables check implemented ensure samples consistent (.e. ) effort (Eric Rexstad found bug) clarification stratification occurs abundance/density estimation stage (dht), rather detection function modelling stage (thanks Filipe Dias suggestion) Setting order=0 equivalent adjustment=NULL specify detection function without adjustments. (Eric Rexstad brought attention.)","code":""},{"path":"/news/index.html","id":"distance-080","dir":"Changelog","previous_headings":"","what":"Distance 0.8.0","title":"Distance 0.8.0","text":"CRAN release: 2014-01-09 new simplified table data format (see ?ds) bug binning cutpoints (thanks Colin Beale finding ) removed percentage truncation binned data, doesn’t really make sense","code":""},{"path":"/news/index.html","id":"distance-074","dir":"Changelog","previous_headings":"","what":"Distance 0.7.4","title":"Distance 0.7.4","text":"new initial values argument","code":""},{"path":"/news/index.html","id":"distance-073","dir":"Changelog","previous_headings":"","what":"Distance 0.7.3","title":"Distance 0.7.3","text":"CRAN release: 2013-08-19 remove annoying crash mrds failed fit model NB optimiser underlying mrds (optimx) changed, update packages avoid issues.","code":""},{"path":"/news/index.html","id":"distance-072","dir":"Changelog","previous_headings":"","what":"Distance 0.7.2","title":"Distance 0.7.2","text":"CRAN release: 2013-07-04 message tells user model selected","code":""},{"path":"/news/index.html","id":"distance-071","dir":"Changelog","previous_headings":"","what":"Distance 0.7.1","title":"Distance 0.7.1","text":"CRAN release: 2012-11-08 debugging options bug fixes (see github details) automatic generation adjustments generate poly/herm.","code":""},{"path":"/news/index.html","id":"distance-07","dir":"Changelog","previous_headings":"","what":"Distance 0.7","title":"Distance 0.7","text":"“width” now default scaling","code":""}]
